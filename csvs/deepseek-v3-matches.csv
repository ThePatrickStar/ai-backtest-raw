ai_index,ai_title,ai_abstract,ai_conference,ai_domain,ai_model,match_found,human_index,human_title,human_abstract,human_venue,human_overall_score,human_accepted,similarity_score,ai_processed_text,human_processed_text,generated_at
0,"*""Disentangling Latent Causal Mechanisms for Robust Representation Learning""*","Modern representation learning often relies on correlations in data, which can lead to brittle models sensitive to distribution shifts. We propose a framework for learning representations that disentangle latent causal mechanisms, enabling models to generalize more robustly across environments. Our approach combines variational autoencoders with causal inference techniques, explicitly modeling latent variables as causal factors. We introduce a novel objective that encourages independence between mechanisms while preserving their predictive utility. Theoretical analysis shows our method recovers true causal factors under identifiable conditions. Empirical results on synthetic and real-world datasets demonstrate significant improvements in out-of-distribution generalization (up to 30% higher accuracy) compared to existing disentanglement methods. The learned representations exhibit interpretable structure aligned with ground-truth generative factors. This work bridges causal inference and representation learning, offering a principled path toward more reliable machine learning systems.   ---",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,6476,Turning Challenges into Opportunities: How Distribution Shifts Enhance Identifiability in Causal Representation Learning,"Causal representation learning seeks to uncover latent causal variables and their relationships from observed, unstructured data, a task complicated by identifiability challenges. While distribution shifts, viewed as natural interventions on latent causal variables, often present difficulties in traditional machine learning tasks, they also create valuable opportunities for identifiability by introducing variability in latent variables. In this paper, we study a non-parametric condition characterizing the types of distribution shifts that contribute to identifiability within the context of latent additive noise models. We also present partial identifiability results when only a portion of distribution shifts meets the condition. Furthermore, we extend our findings to latent post-nonlinear causal models. Building on our theoretical results, we propose a practical algorithm facilitating the acquisition of reliable latent causal representations. Our algorithm, guided by our underlying theory, has demonstrated outstanding performance across a diverse range of synthetic and real-world datasets. The empirical observations closely align with the theoretical findings, affirming the robustness and effectiveness of our proposed approach.",ICLR.cc/2025/Conference,5.25,False,0.8820,modern representation learning often relies correlations data which can lead brittle models sensitive distribution shifts for learning representations that disentangle latent causal mechanisms enabling models generalize more robustly across environments this bridges causal inference and representation learning offering principled path toward more reliable machine learning systems,causal representation learning seeks uncover latent causal variables and their relationships from observed unstructured data task complicated identifiability challenges while distribution shifts viewed natural interventions latent causal variables often difficulties traditional machine learning tasks they also create valuable opportunities for identifiability introducing variability latent variables the empirical observations closely align the theoretical affirming the robustness and effectiveness our proposed,2025-08-26T00:59:30.191605
1,"*""Multi-View Contrastive Learning with Equivariant Representations""*","Contrastive learning has shown promise in self-supervised representation learning, but it often struggles with multi-view data where transformations are not purely geometric. We present a novel framework for multi-view contrastive learning that leverages group-equivariant architectures to capture intrinsic symmetries in data. Our method enforces equivariance constraints during contrastive training, ensuring representations transform predictably under view changes. Key contributions include a symmetry-aware data augmentation strategy and a provably invariant loss function. Experiments on 3D molecular datasets and multi-camera systems show our approach outperforms standard contrastive baselines by 15-25% in downstream tasks, particularly when test distributions exhibit unseen viewpoints. Theoretical guarantees ensure our learned embeddings are provably stable to group actions, addressing a critical limitation of existing methods. This work advances the understanding of geometric priors in self-supervised learning.   ---",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,10471,What to align in multimodal contrastive learning?,"Humans perceive the world through multisensory integration, blending the information of different modalities to adapt their behavior.
Contrastive learning offers an appealing solution for multimodal self-supervised learning. Indeed, by considering each modality as a different view of the same entity, it learns to align features of different modalities in a shared representation space. However, this approach is intrinsically limited as it only learns shared or redundant information between modalities, while multimodal interactions can arise in other ways. In this work, we introduce CoMM, a Contrastive Multimodal learning strategy that enables the communication between modalities in a single multimodal space. Instead of imposing cross- or intra- modality constraints, we propose to align multimodal representations by maximizing the mutual information between augmented versions of these multimodal features. Our theoretical analysis shows that shared, synergistic and unique terms of information naturally emerge from this formulation, allowing us to estimate multimodal interactions beyond redundancy. We test CoMM both in a controlled and in a series of real-world settings: in the former, we demonstrate that CoMM effectively captures redundant, unique and synergistic information between modalities. In the latter, CoMM learns complex multimodal interactions and achieves state-of-the-art results on seven multimodal tasks.",ICLR.cc/2025/Conference,6.25,True,0.8484,contrastive learning has shown promise self supervised representation learning but often struggles multi view data where transformations are not purely geometric for multi view contrastive learning that leverages group equivariant architectures capture intrinsic symmetries data this advances the understanding geometric priors self supervised learning,contrastive learning offers appealing solution for multimodal self supervised learning indeed considering each modality different view the same entity learns align features different modalities shared representation space this comm contrastive multimodal learning strategy that enables the communication between modalities single multimodal space,2025-08-26T00:59:30.191633
2,"*""Sparse Neural Coding for Compositional Representation Learning""*","Human cognition excels at composing new concepts from sparse primitives, yet most neural networks use dense, entangled representations. We propose a sparse neural coding framework that learns discrete, compositional representations through a biologically motivated competitive activation mechanism. Our model employs a gated sparsity objective combined with an information-theoretic diversity term, encouraging units to activate sparsely while covering the data manifold. Results on image and text data show our method achieves 8-12% better compositional generalization than dense baselines while reducing computational costs by 30%. Learned representations exhibit interpretable ""concept neurons"" that fire selectively for semantic features. We prove our objective induces a combinatorial code that grows sublinearly with task complexity, unlike conventional networks. This work provides a neural architecture closer to human-like compositional reasoning.   ---",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,6347,GeoCon: Compositional Generalization Through Geometric Constraints on Representation Structure,"Compositional generalization, referring to the capacity to generalize novel combinations of fundamental and essential concepts, is thought to be the mechanism underlying a human’s remarkable ability of rapid generalization to new knowledge and tasks. Recent research on brain neural activation space has found that the geometric structure of neural representations is highly related to human compositional generalization capability.
In this paper, we extend the above observations from neuroscience to deep neural networks to validate the potential relationship between the geometric structure of representations and compositional generalization capability. In particular, we first construct a new compositional generalization benchmark from the existent datasets, which aims to discriminate multiple concepts simultaneously through a powerful representation. Meanwhile, for the aforementioned geometric constraint, the parallelism score is formally defined for deep neural networks.
Subsequently, we decompose the deep neural network into two parts: the featurizer and the classifier, to investigate the relationship between compositional generalization capability and parallelism score separately. Our proposed method, Geometric Constraint (GeoCon), involves distance variance minimization on the classifier and parallelism score maximization on the featurizer.
Experiments on synthetic and real-world datasets demonstrate significant improvement of our approach, verifying the effectiveness of our neuroscience-inspired GeoCon approach towards human-like superior generalization ability.",ICLR.cc/2025/Conference,6.333333333333333,nan,0.8576,human cognition excels composing concepts from sparse primitives yet most neural networks use dense entangled representations sparse neural coding that learns discrete compositional representations biologically motivated competitive activation mechanism learned representations exhibit interpretable concept neurons that fire selectively for semantic features this provides neural closer human like compositional reasoning,compositional generalization referring the capacity generalize combinations fundamental and essential concepts thought the mechanism underlying human remarkable ability rapid generalization knowledge and tasks recent brain neural activation space has found that the geometric structure neural representations highly related human compositional generalization capability this extend the above observations from neuroscience deep neural networks the potential relationship between the geometric structure representations and compositional generalization capability particular first construct compositional generalization from the existent datasets which aims discriminate multiple concepts simultaneously powerful representation meanwhile for the aforementioned geometric constraint the parallelism formally defined for deep neural networks subsequently decompose the deep neural network into two parts the featurizer and the classifier the relationship between compositional generalization capability and parallelism separately,2025-08-26T00:59:30.191654
3,"*""Hyperbolic Prototype Networks for Few-Shot Hierarchical Learning""*","Few-shot learning remains challenging when data exhibits hierarchical structure, as standard Euclidean embeddings fail to capture taxonomies. We introduce hyperbolic prototype networks, where prototypes live in hyperbolic space to naturally represent hierarchical relationships. Our framework includes a novel curvature-adaptive projection layer and a Riemannian metric learning objective. Key insights are that hyperbolic distances between prototypes mirror tree-like taxonomies and that curvature can adapt to dataset properties. Experiments on biological sequences and language tasks demonstrate 20-35% improvements in few-shot accuracy compared to Euclidean counterparts, with particularly strong gains on deep hierarchies. Theoretical analysis reveals our method's superior sample efficiency for hierarchical data. This work unifies geometric deep learning with few-shot paradigms, opening new directions for representation learning in structured domains.   ---",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,3887,Geometry-aware Distance Measure for Diverse Hierarchical Structures in Hyperbolic Spaces,"Learning in hyperbolic spaces has gained increasing attention due to the superior capability of modeling hierarchical structures. Existing hyperbolic learning methods use a fixed distance measure that assumes a uniform hierarchical structure across all data points. However, this assumption does not always hold in real-world scenarios, considering the diversity of the hierarchical structures of data. This work proposes to learn geometry aware distance measures that dynamically adjust to accommodate diverse hierarchical structures in hyperbolic spaces. We derive geometry aware distance measures by generating projections and curvatures for each pair of samples, which maps each pair to a suitable hyperbolic space. We introduce a revised low-rank decomposition scheme and a hard-pair mining mechanism to reduce the computational cost incurred by the pairwise generation without compromising accuracy. Moreover, we derive an upper bound of the low-rank approximation error via Talagrand concentration inequality to guarantee the effectiveness of our low-rank decomposition scheme. Theoretical analysis and experiments on standard image classification and few-shot learning tasks affirm the effectiveness of our method in refining hyperbolic learning through our geometry aware distance measures.",ICLR.cc/2025/Conference,4.75,nan,0.8389,few shot learning remains challenging when data exhibits hierarchical structure standard euclidean embeddings fail capture taxonomies our includes curvature adaptive projection layer and riemannian learning objective experiments biological sequences and language tasks improvements few shot compared euclidean counterparts strong gains deep hierarchies this unifies geometric deep learning few shot paradigms opening directions for representation learning structured domains,learning hyperbolic spaces has gained increasing attention due the superior capability modeling hierarchical structures existing hyperbolic learning methods use fixed distance measure that assumes uniform hierarchical structure across all data points revised low rank decomposition scheme and hard pair mining mechanism reduce the computational cost incurred the pairwise generation compromising theoretical analysis and experiments standard image classification and few shot learning tasks affirm the effectiveness our refining hyperbolic learning our geometry aware distance measures,2025-08-26T00:59:30.191664
4,"*""Flow-Based Representation Learning with Exact Likelihoods""*","Normalizing flows offer exact likelihood computation but struggle with high-dimensional representation learning due to invertibility constraints. We present a novel flow architecture that combines the expressiveness of arbitrary neural networks with exact density estimation. Our key innovation is a stochastic bridging mechanism that allows partial invertibility while preserving the flow's mathematical guarantees. The model achieves state-of-the-art log-likelihoods on image datasets while learning semantically meaningful latent codes. Compared to VAEs and GANs, our method provides 40% better anomaly detection performance due to precise density modeling. Theoretical contributions include conditions under which our stochastic flows remain tractable and a new interpretation of the manifold learning tradeoff. This work enables flow models to compete in representation learning while retaining their probabilistic rigor.   ---",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,5314,Normalizing Flow Based Evaluation Metrics for Image Generation,"We propose two new evaluation metrics to assess realness of generated images based on normalizing flows: a simpler and efficient flow-based likelihood distance (FLD) and a more exact dual-flow based likelihood distance (D-FLD). Because normalizing flows can be used to compute the exact likelihood, the proposed metrics assess how closely generated images align with the distribution of real images from a given domain. This property gives the proposed metrics a few advantages over the widely used Fréchet inception distance (FID) and other recent metrics. Firstly, the proposed metrics need only a few hundred images to stabilize (converge in mean), as opposed to tens of thousands needed for FID, and at least a few thousand for the other metrics. This allows confident evaluation of even small sets of generated images, such as validation batches inside training loops. Secondly, the network used to compute the proposed metric has over an order of magnitude fewer parameters compared to Inception-V3 used to compute FID, making it computationally more efficient. For assessing the realness of generated images in new domains (e.g., x-ray images), ideally these networks should be retrained on real images to model their distinct distributions. Thus, our smaller network will be even more advantageous for new domains. Extensive experiments show that the proposed metrics have the desired monotonic relationships with the extent of image degradation of various kinds.",ICLR.cc/2025/Conference,3.75,False,0.8496,normalizing flows offer exact likelihood computation but struggle high dimensional representation learning due invertibility constraints flow that combines the expressiveness arbitrary neural networks exact density estimation the achieves state the art log likelihoods image datasets while learning semantically meaningful latent codes compared vaes and gans our provides better anomaly detection due precise density modeling theoretical contributions include conditions under which our stochastic flows remain tractable and interpretation the manifold learning tradeoff this enables flow models compete representation learning while retaining their probabilistic rigor,because normalizing flows can used compute the exact likelihood the proposed metrics assess how closely generated images align the distribution real images from given domain secondly the network used compute the proposed has over order magnitude fewer parameters compared inception used compute fid making computationally more efficient thus our smaller network will even more advantageous for domains,2025-08-26T00:59:30.191672
5,"*""Temporal Discrepancy Learning for Video Representation""*","Video representation learning typically relies on hand-designed pretext tasks like frame ordering, which may not capture meaningful temporal structure. We propose temporal discrepancy learning (TDL), a self-supervised approach that discovers salient temporal variations automatically. TDL employs a siamese architecture with a novel discrepancy prediction head that learns to anticipate feature changes over time. Crucially, our objective encourages the model to ignore irrelevant variations while focusing on semantically meaningful temporal dynamics. Experiments across 6 video benchmarks show TDL outperforms previous methods by 5-10% in action recognition and video retrieval. The learned representations exhibit strong compositionality across timescales, from short-term actions to long-term events. This work provides a principled framework for temporal representation learning without predefined pretext tasks.   ---",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,888,Grounding is All You Need? Dual Temporal Grounding for Video Dialog,"In the realm of video dialog response generation, the understanding of video content and the temporal nuances of conversation history are paramount. While a segment of current research leans heavily on large-scale pretrained visual-language models and often overlooks temporal dynamics, another delves deep into spatial-temporal relationships within videos but demands intricate object trajectory pre-extractions and sidelines dialog temporal dynamics. 
This paper introduces the Dual Temporal Grounding-enhanced Video Dialog model (DTGVD), strategically designed to merge the strengths of both dominant approaches.
It emphasizes dual temporal relationships by predicting dialog turn-specific temporal regions, filtering video content accordingly, and grounding responses in both video and dialog contexts. 
One standout feature of DTGVD is its heightened attention to chronological interplay. By recognizing and acting upon the dependencies between different dialog turns, it captures more nuanced conversational dynamics. 
To further bolster the alignment between video and dialog temporal dynamics, we've implemented a list-wise contrastive learning strategy. Within this framework, accurately grounded turn-clip pairings are designated as positive samples, while less precise pairings are categorized as negative. This refined classification is then funneled into our holistic end-to-end response generation mechanism. Evaluations using AVSD@DSTC-7 and AVSD@DSTC-8 datasets underscore the superiority of our methodology.",ICLR.cc/2025/Conference,4.0,nan,0.8378,video representation learning relies hand designed pretext tasks like frame ordering which may not capture meaningful temporal structure temporal discrepancy learning tdl self supervised that discovers salient temporal variations automatically tdl employs siamese discrepancy prediction head that learns anticipate feature changes over time experiments across video benchmarks tdl outperforms previous methods action recognition and video retrieval this provides principled for temporal representation learning predefined pretext tasks,while segment current leans heavily large scale pretrained visual language models and often overlooks temporal dynamics another delves deep into spatial temporal relationships within videos but demands intricate object trajectory pre extractions and sidelines dialog temporal dynamics one standout feature dtgvd its heightened attention chronological interplay further bolster the alignment between video and dialog temporal dynamics implemented list wise contrastive learning strategy this refined classification then funneled into our holistic end end response generation mechanism,2025-08-26T00:59:30.191680
6,"*""Representation Learning via Differentiable Topological Invariants""*","Topological properties of data manifolds—such as connected components or holes—often contain essential structural information overlooked by current methods. We introduce a differentiable topological invariant (DTI) module that can be integrated into neural networks to learn topology-aware representations. Our approach computes persistent homology through a differentiable approximation of simplex operations, enabling end-to-end training. Theoretical results establish conditions under which DTIs provide invariant information. Empirical studies on graphs and medical images demonstrate that models with DTIs discover clinically relevant structural features missed by conventional networks, achieving 17% higher accuracy in classification tasks with limited data. This work pioneers the integration of algebraic topology tools into deep learning, preserving structural information that is crucial for scientific domains.   ---",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,642,Topological Blindspots: Understanding and Extending Topological Deep Learning Through the Lens of Expressivity,"Topological deep learning (TDL) is a rapidly growing field that seeks to leverage topological structure in data and facilitate learning from data supported on topological objects, ranging from molecules to 3D shapes. Most TDL architectures can be unified under the framework of higher-order message-passing (HOMP), which generalizes graph message-passing to higher-order domains. In the first part of the paper, we explore HOMP's expressive power from a topological perspective, demonstrating the framework's inability to capture fundamental topological and metric invariants such as diameter, orientability, planarity, and homology. In addition, we demonstrate HOMP's limitations in fully leveraging lifting and pooling methods on graphs. To the best of our knowledge, this is the first work to study the expressivity of TDL from a topological perspective. In the second part of the paper, we develop two new classes of architectures -- multi-cellular networks (MCN) and scalable MCN (SMCN) -- which draw inspiration from expressive GNNs. MCN can reach full expressivity, but scaling it to large data objects can be computationally expansive. Designed as a more scalable alternative, SMCN still mitigates many of HOMP's expressivity limitations. Finally, we design new benchmarks for evaluating models based on their ability to learn topological properties of complexes. We then evaluate SMCN on these benchmarks as well as on real-world graph datasets, demonstrating improvements over both HOMP baselines and expressive graph methods, highlighting the value of expressively leveraging topological information.",ICLR.cc/2025/Conference,8.0,True,0.8510,differentiable topological invariant dti module that can integrated into neural networks learn topology aware representations empirical studies graphs and medical images that models dtis discover clinically relevant structural features missed conventional networks achieving higher classification tasks limited data this pioneers the integration algebraic topology tools into deep learning preserving structural information that crucial for scientific domains,topological deep learning tdl rapidly growing field that seeks leverage topological structure data and facilitate learning from data supported topological objects ranging from molecules shapes,2025-08-26T00:59:30.191687
7,"*""Contrastive Learning with Adversarial Robust Representations""*","Contrastive learning produces representations that capture semantic information but may remain vulnerable to adversarial perturbations. We develop a framework for learning representations that are both semantically meaningful and adversarially robust through a novel min-max contrastive objective. Our method alternates between maximizing contrastive loss for adversarial examples and minimizing loss for clean samples, yielding representations with certified robustness guarantees. Experiments on CIFAR-10 and ImageNet show our approach matches standard contrastive methods on clean data while providing 4× robustness improvement against ℓ∞ attacks. Theoretically, we prove bounds relating representation space geometry to robustness. This work establishes that self-supervised learning need not sacrifice robustness for semantic quality, with implications for security-critical applications.   ---   Each paper addresses distinct technical challenges in representation learning while meeting ICLR's rigor requirements, spanning theoretical innovations, novel architectures, and practical applications. The diversity ranges from geometric methods (hyperbolic, topological) to robustness (adversarial, causal) and novel learning paradigms (sparse, temporal).",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,4573,Cluster-Driven Adversarial Perturbations for Robust Contrastive Learning,"Adversarial contrastive learning aims to learn a representation space robust to adversarial inputs using only unlabeled data. Existing methods typically generate adversarial perturbations by maximizing the contrastive loss during adversarial training. However, we find that the effectiveness of this approach is influenced by the composition of positive and negative examples in a minibatch, which is not explicitly controllable. To address this limitation, we propose a novel approach to adversarial contrastive learning, where adversarial perturbations are generated based on the clustering structure of the representation space learned through contrastive learning. Our method is motivated by the observation that contrastive learning produces a well-separated representation space, where similar data points cluster together in space, while dissimilar ones are positioned farther apart. We hypothesize that perturbations directed toward neighboring (the second nearest to be specific) clusters are likely to cross the decision boundary of a downstream classifier built upon contrastive learning, effectively acting as adversarial examples. A key challenge in our approach is to determine a sufficiently large number of clusters, for which the number of classes in the downstream task would serve the purpose but is typically unknown during adversarial contrastive learning. Therefore, we employ the silhouette score to identify the optimal number of clusters, ensuring high-quality clustering in the representation space. Compared to the existing approaches, our method achieved up to $2.25$\% and $5.05$\% improvements in robust accuracy against PGD and Auto-Attack, respectively, showing slight improvement in standard accuracy as well in most cases.",ICLR.cc/2025/Conference,5.5,False,0.8762,contrastive learning produces representations that capture semantic information but may remain vulnerable adversarial perturbations for learning representations that are both semantically meaningful and adversarially robust min max contrastive objective our alternates between maximizing contrastive loss for adversarial examples and minimizing loss for clean samples yielding representations certified robustness guarantees experiments cifar and imagenet our matches standard contrastive methods clean data while providing robustness improvement against attacks theoretically bounds relating representation space geometry robustness this establishes that self supervised learning need not sacrifice robustness for semantic quality implications for security critical applications each addresses distinct technical challenges representation learning while meeting iclr rigor requirements spanning theoretical innovations architectures and practical applications the diversity ranges from geometric methods hyperbolic topological robustness adversarial causal and learning paradigms sparse temporal,adversarial contrastive learning aims learn representation space robust adversarial inputs only unlabeled data address this limitation adversarial contrastive learning where adversarial perturbations are generated the clustering structure the representation space learned contrastive learning our motivated the observation that contrastive learning produces well separated representation space where similar data points cluster together space while dissimilar ones are positioned farther apart key challenge our determine sufficiently large number clusters for which the number classes the downstream task would serve the purpose but unknown during adversarial contrastive learning therefore employ the silhouette identify the optimal number clusters ensuring high quality clustering the representation space,2025-08-26T00:59:30.191703
8,"*""Learned Equivariant Representations for Symmetry-Aware Generalization""*","Modern neural networks often fail to leverage inherent symmetries in data, leading to poor generalization under transformations. We present a framework for learning representations that explicitly encode symmetry structure through a novel combination of group-equivariant architectures and meta-learning. Our approach introduces symmetry-aware inductive biases during training while maintaining flexibility to learn unknown symmetries from data. The key innovation is a disentangled representation space where equivariant transformations are explicitly modeled as separate sub-manifolds. Theoretical analysis shows our method provides tighter generalization bounds under group transformations. Empirical evaluation on 3D molecular data and cosmological simulations demonstrates 20-35% improvement in generalization to unseen symmetries compared to standard equivariant networks. Notably, our model discovers physically meaningful symmetry groups in cosmology without supervision. This work bridges symmetry principles with data-driven representation learning, offering a principled approach for structured generalization.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,6839,Symmetric Space Learning for Combinatorial Generalization,"Symmetries on representations within generative models have shown essential roles in predicting unobserved combinations of semantic changes, known as combinatorial generalization tasks. However, these efforts have primarily focused on learning symmetries from only training data, and thus, the extension of trained symmetries to unseen samples remains uncontrolled. A potential approach for generalizing the symmetries is leveraging geometric information on manifolds that contain functional semantic structures for unseen data, but it still falls short of supporting symmetry learning. In this paper, we address this $\textit{symmetry generalization}$ by forcing $\textit{symmetric space}$ on latent space for utilizing semantic structures from symmetry and manifold perspectives. We clarify an equivariance-based constraint that restricts symmetry generalization, and prove that: 1) enforcing the homogeneous space property of symmetric space onto the data manifold eliminates this constraint, 2) a homogeneous latent manifold induces the data manifold through diffeomorphic data-to-latent mapping, and 3) the isometry property of symmetric space extends neighbor symmetries of a point to another within the space. For practical implementation, we propose a method to align sampled points from symmetric space with their explicitly trained geodesic. We verify the method in a detailed analysis on a toy dataset and enhance combinatorial generalization on common benchmarks. This work represents the first effective effort to align symmetries with manifolds for combinatorial generalization.",ICLR.cc/2025/Conference,4.75,False,0.8847,modern neural networks often fail leverage inherent symmetries data leading poor generalization under transformations for learning representations that explicitly encode symmetry structure combination group equivariant architectures and meta learning the key innovation disentangled representation space where equivariant transformations are explicitly modeled separate sub manifolds this bridges symmetry principles data driven representation learning offering principled for structured generalization,symmetries representations within generative models have shown essential roles predicting unobserved combinations semantic changes known combinatorial generalization tasks however these efforts have primarily focused learning symmetries from only training data and thus the extension trained symmetries unseen samples remains uncontrolled potential for generalizing the symmetries leveraging geometric information manifolds that contain functional semantic structures for unseen data but still falls short supporting symmetry learning this address this textit symmetry generalization forcing textit symmetric space latent space for utilizing semantic structures from symmetry and manifold perspectives,2025-08-26T00:59:30.191711
9,"*""Self-Supervised Representation Learning with Dynamic Concept Formation""*",Current self-supervised methods learn fixed representations that struggle with evolving concepts over time. We propose a dynamic representation learning framework where embeddings continuously adapt through self-organizing concept formation. Our approach combines contrastive learning with a novel dynamic memory module that incrementally clusters and refines concepts as new data arrives. The memory structure maintains plasticity-stability balance through a theoretically-grounded forgetting mechanism. Experiments on continual learning benchmarks show 15-20% higher accuracy in adapting to concept drift compared to static representations. Visualization reveals our model automatically discovers hierarchical concept relationships that evolve with new data. This work provides foundations for lifelong representation learning systems that adapt like biological intelligence.,ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,9753,Dynamic Alignment of Representations for Enhanced Chain-of-Thought Reasoning in Large Language Models,"Representations encode rich semantic information, implying that editing them could serve as a effective tool (i.e., DAS, REFT) for parameter-efficient finetuning (PEFT). However, existing approaches typically focus on general categories of representations or selecting an appropriate number of continuous representations for each datasets, which limits their adaptability and performance. In contrast, our method dynamically selects representations requiring intervention at the instance level, referred to as misaligned representations, which are characterized by a lack of semantic information or appropriate attention. Identifying these misaligned representations poses challenging, as they serve different roles in varying contexts. It is evident that crucial representations, which are those that primarily receive information flow from themselves or significantly influence other representations, are likely to encompass misaligned representations. Consequently, we simplify the task by pivot our focus to crucial representations and aim to accurately locate them. We adaptively update crucial representation amidst uncertainty, freezing the base model while learning an updated direction for each layer. Involving both identification and updating of representations, we present a PEFT method, termed Dynamic Alignment of Representations (DAR). We validate the effectiveness of our method on eight diverse datasets across two scenarios, arithmetic and commonsense, and three base models: LLaMA-2-7B, LLaMA-2-13B, and LLaMA-3-8B. Notably, our method yields improvements of 17.47% and 3.11% over LLaMA-2-7B and ReFT on the GSM8K dataset, respectively. Additionally, it requires only 51 times fewer parameters than LoRA, demonstrating significant parameter efficiency. Furthermore, our method can be easily extended to few-shot learning.",ICLR.cc/2025/Conference,4.0,nan,0.8428,dynamic representation learning where embeddings continuously adapt self organizing concept formation our combines contrastive learning dynamic memory module that incrementally clusters and refines concepts data arrives experiments continual learning benchmarks higher adapting concept drift compared static representations this provides foundations for lifelong representation learning systems that adapt like biological intelligence,representations encode rich semantic information implying that editing them could serve effective tool contrast our dynamically selects representations requiring intervention the instance level referred misaligned representations which are characterized lack semantic information appropriate attention adaptively update crucial representation amidst uncertainty freezing the base while learning updated direction for each layer furthermore our can easily extended few shot learning,2025-08-26T00:59:30.191718
10,"*""Energy-Based Representations for Compositional Out-of-Distribution Generalization""*","Dense representations often fail to generalize compositionally beyond their training distribution. We develop an energy-based representation framework where semantic composition is modeled through explicit energy interactions between concept units. Our architecture learns sparse concept embeddings whose nonlinear interactions define a tractable energy landscape. Theoretically, we prove this formulation enables out-of-distribution generalization via energy preservation of distantly related concepts. On compositional generalization benchmarks, our model achieves 25-30% higher accuracy than transformer baselines on unseen concept combinations while maintaining interpretable concept representations. This work establishes energy-based modeling as a principled approach for compositional AI systems.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,2235,Interaction Asymmetry: A General Principle for Learning Composable Abstractions,"Learning disentangled representations of concepts and re-composing them in unseen ways is crucial for generalizing to out-of-domain situations. However, the underlying properties of concepts that enable such disentanglement and compositional generalization remain poorly understood. In this work, we propose the principle of interaction asymmetry which states: ""Parts of the same concept have more complex interactions than parts of different concepts"". We formalize this via block diagonality conditions on the $(n+1)$th order derivatives of the generator mapping concepts to observed data, where different orders of ""complexity"" correspond to different $n$. Using this formalism, we prove that interaction asymmetry enables both disentanglement and compositional generalization. Our results unify recent theoretical results for learning concepts of objects, which we show are recovered as special cases with $n=0$ or $1$. We provide results for up to $n=2$, thus extending these prior works to more flexible generator functions, and conjecture that the same proof strategies generalize to larger $n$. Practically, our theory suggests that, to disentangle concepts, an autoencoder should penalize its latent capacity and the interactions between concepts during decoding. We propose an implementation of these criteria using a flexible Transformer-based VAE, with a novel regularizer on the attention weights of the decoder. On synthetic image datasets consisting of objects, we provide evidence that this model can achieve comparable object disentanglement to existing models that use more explicit object-centric priors.",ICLR.cc/2025/Conference,7.0,True,0.8071,energy based representation where semantic composition modeled explicit energy interactions between concept units compositional generalization benchmarks our achieves higher than transformer baselines unseen concept combinations while maintaining interpretable concept representations,learning disentangled representations concepts and composing them unseen ways crucial for generalizing out domain situations our unify recent theoretical for learning concepts objects which are recovered special cases implementation these criteria flexible transformer based vae regularizer the attention weights the decoder,2025-08-26T00:59:30.191729
11,"*""Topological Representation Learning with Persistent Homology Regularization""*","The topological structure of latent spaces profoundly impacts model generalization but remains challenging to control. We introduce a novel persistent homology regularization framework that explicitly shapes the topological properties of learned representations. Our key insight is to formulate topological constraints as differentiable objectives on the Vietoris-Rips filtration, enabling gradient-based optimization of topological features. Experiments on medical imaging and molecular property prediction demonstrate our method achieves 10-15% improvement in low-data regimes by preserving medically relevant topology. Theoretical analysis connects topological complexity to downstream task performance, providing new insights into representation topology.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,642,Topological Blindspots: Understanding and Extending Topological Deep Learning Through the Lens of Expressivity,"Topological deep learning (TDL) is a rapidly growing field that seeks to leverage topological structure in data and facilitate learning from data supported on topological objects, ranging from molecules to 3D shapes. Most TDL architectures can be unified under the framework of higher-order message-passing (HOMP), which generalizes graph message-passing to higher-order domains. In the first part of the paper, we explore HOMP's expressive power from a topological perspective, demonstrating the framework's inability to capture fundamental topological and metric invariants such as diameter, orientability, planarity, and homology. In addition, we demonstrate HOMP's limitations in fully leveraging lifting and pooling methods on graphs. To the best of our knowledge, this is the first work to study the expressivity of TDL from a topological perspective. In the second part of the paper, we develop two new classes of architectures -- multi-cellular networks (MCN) and scalable MCN (SMCN) -- which draw inspiration from expressive GNNs. MCN can reach full expressivity, but scaling it to large data objects can be computationally expansive. Designed as a more scalable alternative, SMCN still mitigates many of HOMP's expressivity limitations. Finally, we design new benchmarks for evaluating models based on their ability to learn topological properties of complexes. We then evaluate SMCN on these benchmarks as well as on real-world graph datasets, demonstrating improvements over both HOMP baselines and expressive graph methods, highlighting the value of expressively leveraging topological information.",ICLR.cc/2025/Conference,8.0,True,0.8087,our key insight formulate topological constraints differentiable objectives the vietoris rips filtration enabling gradient based optimization topological features experiments medical imaging and molecular property prediction our achieves improvement low data regimes preserving medically relevant topology theoretical analysis connects topological complexity downstream task providing insights into representation topology,topological deep learning tdl rapidly growing field that seeks leverage topological structure data and facilitate learning from data supported topological objects ranging from molecules shapes,2025-08-26T00:59:30.191730
12,"*""Communicative Representation Learning for Multi-Agent Systems""*","Standard representation learning lacks mechanisms for multi-agent coordination through learned representations. We develop a communicative paradigm where agents co-evolve representations through a novel combination of representation learning and emergent communication protocols. Our framework features three innovations: gradient-based messaging, consensus-constrained representation spaces, and decentralized optimization of communicative utility. In agent coordination tasks, our approach achieves near-centralized performance while using 50% fewer parameters than conventional multi-agent systems. Analysis reveals emergent properties including compositionality and context-sensitivity in the learned communication protocol.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,8189,Exponential Topology-enabled Scalable Communication in Multi-agent Reinforcement Learning,"In cooperative multi-agent reinforcement learning (MARL), well-designed communication protocols can effectively facilitate consensus among agents, thereby enhancing task performance. Moreover, in large-scale multi-agent systems commonly found in real-world applications, effective communication plays an even more critical role due to the escalated challenge of partial observability compared to smaller-scale setups. In this work, we endeavor to develop a scalable communication protocol for MARL. Unlike previous methods that focus on selecting optimal pairwise communication links—a task that becomes increasingly complex as the number of agents grows—we adopt a global perspective on communication topology design. Specifically, we propose utilizing the exponential topology to enable rapid information dissemination among agents by leveraging its small-diameter and small-size properties. This approach leads to a scalable communication protocol, named ExpoComm. To fully unlock the potential of exponential graphs as communication topologies, we employ memory-based message processors and auxiliary tasks to ground messages, ensuring that they reflect global information and benefit decision-making. Extensive experiments on large-scale cooperative benchmarks, including MAgent and Infrastructure Management Planning, demonstrate the superior performance and robust zero-shot transferability of ExpoComm compared to existing communication strategies. The
code is publicly available at [https://github.com/LXXXXR/ExpoComm](https://github.com/LXXXXR/ExpoComm).",ICLR.cc/2025/Conference,6.25,True,0.8388,standard representation learning lacks mechanisms for multi agent coordination learned representations communicative paradigm where agents evolve representations combination representation learning and emergent communication protocols our features three innovations gradient based messaging consensus constrained representation spaces and decentralized optimization communicative utility,cooperative multi agent reinforcement learning marl well designed communication protocols can facilitate consensus among agents thereby enhancing task extensive experiments large scale cooperative benchmarks including magent and infrastructure management planning the superior and robust zero shot transferability expocomm compared existing communication strategies,2025-08-26T00:59:30.191737
13,"*""Counterfactual-Guided Representation Learning for Causal Robustness""*","Traditional representation learning often captures spurious statistical patterns rather than causal structure. We present a counterfactual-guided framework that learns causally-grounded representations through intervention-aware objectives. Our approach combines causal discovery with deep representation learning to estimate and utilize counterfactual distributions during training. Theoretical analysis establishes identifiability conditions under which our method recovers causal representations. Empirical evaluation shows 40-50% reduction in spurious correlation reliance across fairness, robustness, and domain generalization benchmarks.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,6476,Turning Challenges into Opportunities: How Distribution Shifts Enhance Identifiability in Causal Representation Learning,"Causal representation learning seeks to uncover latent causal variables and their relationships from observed, unstructured data, a task complicated by identifiability challenges. While distribution shifts, viewed as natural interventions on latent causal variables, often present difficulties in traditional machine learning tasks, they also create valuable opportunities for identifiability by introducing variability in latent variables. In this paper, we study a non-parametric condition characterizing the types of distribution shifts that contribute to identifiability within the context of latent additive noise models. We also present partial identifiability results when only a portion of distribution shifts meets the condition. Furthermore, we extend our findings to latent post-nonlinear causal models. Building on our theoretical results, we propose a practical algorithm facilitating the acquisition of reliable latent causal representations. Our algorithm, guided by our underlying theory, has demonstrated outstanding performance across a diverse range of synthetic and real-world datasets. The empirical observations closely align with the theoretical findings, affirming the robustness and effectiveness of our proposed approach.",ICLR.cc/2025/Conference,5.25,False,0.8512,traditional representation learning often captures spurious statistical patterns rather than causal structure our combines causal discovery deep representation learning estimate and utilize counterfactual distributions during training empirical evaluation shows reduction spurious correlation reliance across fairness robustness and domain generalization benchmarks,causal representation learning seeks uncover latent causal variables and their relationships from observed unstructured data task complicated identifiability challenges while distribution shifts viewed natural interventions latent causal variables often difficulties traditional machine learning tasks they also create valuable opportunities for identifiability introducing variability latent variables the empirical observations closely align the theoretical affirming the robustness and effectiveness our proposed,2025-08-26T00:59:30.191739
14,"*""Hyperbolic Prototype Networks for Hierarchical Few-Shot Learning""*","Euclidean embedding spaces struggle to represent hierarchical relationships common in few-shot learning scenarios. We introduce hyperbolic prototype networks that exploit the exponential representational capacity of hyperbolic spaces for hierarchical learning. Our key innovation is a curvature-adaptive prototype projection layer that automatically adjusts space curvature to match dataset hierarchy. On hierarchical few-shot benchmarks, our model achieves 30-40% accuracy gains over Euclidean counterparts, with particularly strong improvements (up to 2×) on deep taxonomic hierarchies.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,3887,Geometry-aware Distance Measure for Diverse Hierarchical Structures in Hyperbolic Spaces,"Learning in hyperbolic spaces has gained increasing attention due to the superior capability of modeling hierarchical structures. Existing hyperbolic learning methods use a fixed distance measure that assumes a uniform hierarchical structure across all data points. However, this assumption does not always hold in real-world scenarios, considering the diversity of the hierarchical structures of data. This work proposes to learn geometry aware distance measures that dynamically adjust to accommodate diverse hierarchical structures in hyperbolic spaces. We derive geometry aware distance measures by generating projections and curvatures for each pair of samples, which maps each pair to a suitable hyperbolic space. We introduce a revised low-rank decomposition scheme and a hard-pair mining mechanism to reduce the computational cost incurred by the pairwise generation without compromising accuracy. Moreover, we derive an upper bound of the low-rank approximation error via Talagrand concentration inequality to guarantee the effectiveness of our low-rank decomposition scheme. Theoretical analysis and experiments on standard image classification and few-shot learning tasks affirm the effectiveness of our method in refining hyperbolic learning through our geometry aware distance measures.",ICLR.cc/2025/Conference,4.75,nan,0.8807,euclidean embedding spaces struggle represent hierarchical relationships common few shot learning scenarios hyperbolic prototype networks that exploit the exponential representational capacity hyperbolic spaces for hierarchical learning hierarchical few shot benchmarks our achieves gains over euclidean counterparts strong improvements deep taxonomic hierarchies,learning hyperbolic spaces has gained increasing attention due the superior capability modeling hierarchical structures existing hyperbolic learning methods use fixed distance measure that assumes uniform hierarchical structure across all data points revised low rank decomposition scheme and hard pair mining mechanism reduce the computational cost incurred the pairwise generation compromising theoretical analysis and experiments standard image classification and few shot learning tasks affirm the effectiveness our refining hyperbolic learning our geometry aware distance measures,2025-08-26T00:59:30.191741
15,"*""Neuro-Symbolic Representation Learning with Differentiable Logic Constraints""*",Bridging connectionist and symbolic paradigms remains challenging due to their incompatible representation spaces. We propose a neuro-symbolic representation framework that grounds symbolic logic in learned embeddings through differentiable satisfiability constraints. Our approach features a novel semantic loss formulation that enforces first-order logic constraints during deep representation learning. Experiments on relational reasoning tasks show our method achieves symbolic-level precision (95%+) while maintaining neural flexibility. Theoretical analysis reveals our embeddings satisfy a completeness property - they can exactly represent any finite logic theory. This work establishes new foundations for principled neuro-symbolic integration.,ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,4994,MMD-NSL: Mixed Multinomial Distribution-based Neuro-Symbolic Learning,"Neuro-symbolic learning (NSL) aims to integrate neural networks with symbolic reasoning approaches to enhance the interpretability of machine learning models. Existing methods mostly focus on the long dependency problem of symbolic learning. The important challenge of complex categorization is largely overlooked. To bridge this gap, we propose the Mixed Multinomial Distribution-based NSL MMD-NSL framework. It seamlessly integrates the handling of long dependency chains and complex semantic categorization within Knowledge Graphs (KGs). By introducing a continuous Mixed Multinomial Logic Semantic Distribution, we extend traditional Markov Logic Networks (MLN) to incorporate context-aware semantic embeddings. Our theoretical innovations, including a bijective mapping between MLNs and continuous multinomial distributions, enable the capture of intricate dependencies and varied contexts crucial for NSL tasks.
The framework leverages a bilevel optimization strategy, where a transformer-based upper level dynamically learns mixing coefficients akin to attention mechanisms, while the lower level optimizes rule weights for learning both context and rule patterns. Extensive experiments on the DWIE benchmarking datasets demonstrate significant advantages of MMD-NSL over four state-of-the-art approaches. It achieves 10.47% higher F1-scores on average than the best-performing baseline across 23 sub-datasets. It advances continuous probabilistic models for neuro-symbolic reasoning and complex relational tasks.",ICLR.cc/2025/Conference,4.4,False,0.8524,bridging connectionist and symbolic paradigms remains challenging due their incompatible representation spaces neuro symbolic representation that grounds symbolic logic learned embeddings differentiable satisfiability constraints our features semantic loss formulation that enforces first order logic constraints during deep representation learning experiments relational reasoning tasks our achieves symbolic level while maintaining neural flexibility,neuro symbolic learning nsl aims integrate neural networks symbolic reasoning approaches enhance the interpretability machine learning models existing methods mostly focus the long dependency problem symbolic learning seamlessly integrates the handling long dependency chains and complex semantic categorization within knowledge graphs kgs introducing continuous mixed multinomial logic semantic distribution extend traditional markov logic networks mln incorporate context aware semantic embeddings the leverages bilevel optimization strategy where transformer based upper level dynamically learns mixing coefficients akin attention mechanisms while the lower level optimizes rule weights for learning both context and rule patterns advances continuous probabilistic models for neuro symbolic reasoning and complex relational tasks,2025-08-26T00:59:30.191747
16,"""Causal Representation Learning via Intervention-aware Invariant Regularization""","Learning representations that capture causal relationships rather than superficial correlations is crucial for robust machine learning. We propose a novel framework combining causal discovery with deep representation learning through an intervention-aware invariant regularization objective. Our key insight is to leverage both observational and interventional data to identify stable causal features while suppressing spurious correlations. The method introduces a differentiable regularizer that measures representation stability across environments, enabling end-to-end training of causal-aware representations. Theoretical analysis demonstrates identifiability of causal factors under our regularization scheme. Experiments on image classification and genomics datasets show 25-40% improvement in out-of-distribution generalization compared to standard invariance approaches. Notably, the learned representations exhibit interpretable disentanglement of causal mechanisms. This work bridges causal inference and deep representation learning, providing a practical approach for building more reliable AI systems.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,6796,Unifying Causal Representation Learning with the Invariance Principle,"Causal representation learning (CRL) aims at recovering latent causal variables from high-dimensional observations to solve causal downstream tasks, such as predicting the effect of new interventions or more robust classification. 
  A plethora of methods have been developed, each tackling carefully crafted problem settings that lead to different types of identifiability. 
  These different settings are widely assumed to be important because they are often linked to different rungs of Pearl's causal hierarchy, even though this correspondence is not always exact.
    This work shows that instead of strictly conforming to this hierarchical mapping, *many causal representation learning approaches methodologically align their representations with inherent data symmetries.*
  Identification of causal variables is guided by invariance principles that are not necessarily causal. 
  This result allows us to unify many existing approaches in a single method that can mix and match different assumptions, including non-causal ones, based on the invariance relevant to the problem at hand. 
  It also significantly benefits applicability, which we demonstrate by improving treatment effect estimation on real-world high-dimensional ecological data. Overall, this paper clarifies the role of causal assumptions in the discovery of causal variables and shifts the focus to preserving data symmetries.",ICLR.cc/2025/Conference,7.0,True,0.8627,learning representations that capture causal relationships rather than superficial correlations crucial for robust machine learning combining causal discovery deep representation learning intervention aware invariant regularization objective the introduces differentiable regularizer that measures representation stability across environments enabling end end training causal aware representations experiments image classification and genomics datasets improvement out distribution generalization compared standard invariance approaches this bridges causal inference and deep representation learning providing practical for building more reliable systems,causal representation learning crl aims recovering latent causal variables from high dimensional observations solve causal downstream tasks such predicting the effect interventions more robust classification this shows that instead strictly conforming this hierarchical mapping many causal representation learning approaches methodologically align their representations inherent data symmetries,2025-08-26T00:59:30.191755
17,"""Dynamic Graph Representation Learning with Continuous-Time Attention""","Existing graph representation learning methods often overlook the continuous-time nature of real-world relational data. We present a continuous-time graph attention framework that learns dynamic node representations evolving smoothly over time. Our approach combines neural ordinary differential equations with attention mechanisms to model both structural and temporal dependencies simultaneously. The model employs a novel memory mechanism that dynamically adjusts attention weights based on temporal proximity, enabling efficient processing of long-term dependencies. Experiments on temporal link prediction and dynamic node classification tasks demonstrate 15-30% improvement over discrete-time baselines while maintaining computational efficiency. Theoretical analysis reveals our method's superior approximation properties for continuous-time dynamic systems. This work establishes new foundations for temporal graph representation learning with applications in social networks, financial systems, and biomolecular interactions.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,6234,DyGMamba: Efficiently Modeling Long-Term Temporal Dependency on Continuous-Time Dynamic Graphs with State Space Models,"Learning useful representations for continuous-time dynamic graphs (CTDGs) is challenging, due to the concurrent need to span long node interaction histories and grasp nuanced temporal details. In particular, two problems emerge: (1) Encoding longer histories requires more computational resources, making it crucial for CTDG models to maintain low computational complexity to ensure efficiency; (2) Meanwhile, more powerful models are needed to identify and select the most critical temporal information within the extended context provided by longer histories. To address these problems, we propose a CTDG representation learning model named DyGMamba, originating from the popular Mamba state space model (SSM). DyGMamba first leverages a node-level SSM to encode the sequence of historical node interactions. Another time-level SSM is then employed to exploit the temporal patterns hidden in the historical graph, where its output is used to dynamically select the critical information from the interaction history. We validate DyGMamba experimentally on the dynamic link prediction task. The results show that our model achieves state-of-the-art in most cases. DyGMamba also maintains high efficiency in terms of computational resources, making it possible to capture long temporal dependencies with a limited computation budget.",ICLR.cc/2025/Conference,4.0,False,0.8690,existing graph representation learning methods often overlook the continuous time nature real world relational data continuous time graph attention that learns dynamic node representations evolving smoothly over time our combines neural ordinary differential equations attention mechanisms both structural and temporal dependencies simultaneously the employs memory mechanism that dynamically adjusts attention weights temporal proximity enabling efficient processing long term dependencies experiments temporal link prediction and dynamic node classification tasks improvement over discrete time baselines while maintaining computational efficiency this establishes foundations for temporal graph representation learning applications social networks financial systems and biomolecular interactions,learning useful representations for continuous time dynamic graphs ctdgs challenging due the concurrent need span long node interaction histories and grasp nuanced temporal details address these problems ctdg representation learning named dygmamba originating from the popular mamba state space ssm dygmamba experimentally the dynamic link prediction task,2025-08-26T00:59:30.191759
18,"""Self-Supervised Representation Learning via Physical Symmetry Discovery""","Physical systems often exhibit underlying symmetries that are unknown a priori but crucial for generalization. We introduce a symmetry-discovery framework that learns representations respecting physical laws through self-supervised learning. The method automatically identifies relevant symmetries by analyzing gradient invariance patterns during training, without requiring domain knowledge. Our approach combines equivariant architectures with a novel symmetry identification loss that promotes sparse symmetry discovery. Experiments on physics-inspired tasks show the model discovers classical symmetry groups (e.g., Lorentz, Galilean) automatically while achieving 20-35% better prediction accuracy than supervised baselines. Theoretical guarantees ensure consistent symmetry identification under mild conditions. This work advances the integration of physics principles into machine learning through data-driven symmetry discovery, enabling more physically plausible AI systems.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,8735,Lie Algebra Canonicalization: Equivariant Neural Operators under arbitrary Lie Groups,"The quest for robust and generalizable machine learning models has driven recent interest in exploiting symmetries through equivariant neural networks. In the context of PDE solvers, recent works have shown that Lie point symmetries can be a useful inductive bias for Physics-Informed Neural Networks (PINNs) through data and loss augmentation. Despite this, directly enforcing equivariance within the model architecture for these problems remains elusive. This is because many PDEs admit non-compact symmetry groups, oftentimes not studied beyond their infinitesimal generators, making them incompatible with most existing equivariant architectures. In this work, we propose Lie aLgebrA Canonicalization (LieLAC), a novel approach that exploits only the action of infinitesimal generators of the symmetry group, circumventing the need for knowledge of the full group structure. To achieve this, we address existing theoretical issues in the canonicalization literature, establishing connections with frame averaging in the case of continuous non-compact groups. Operating within the framework of canonicalization, LieLAC can easily be integrated with unconstrained pre-trained models, transforming inputs to a canonical form before feeding them into the existing model, effectively aligning the input for model inference according to allowed symmetries. LieLAC utilizes standard Lie group descent schemes, achieving equivariance in pre-trained models. Finally, we showcase LieLAC's efficacy on tasks of invariant image classification and Lie point symmetry equivariant neural PDE solvers using pre-trained models.",ICLR.cc/2025/Conference,6.5,True,0.8511,symmetry discovery that learns representations respecting physical laws self supervised learning the automatically identifies relevant symmetries analyzing gradient invariance patterns during training requiring domain knowledge lorentz galilean automatically while achieving better prediction than supervised baselines this advances the integration physics principles into machine learning data driven symmetry discovery enabling more physically plausible systems,the quest for robust and generalizable machine learning models has driven recent interest exploiting symmetries equivariant neural networks the context pde solvers recent works have shown that lie point symmetries can useful inductive bias for physics informed neural networks pinns data and loss augmentation this lie algebra canonicalization lielac that exploits only the action infinitesimal generators the symmetry group circumventing the need for knowledge the full group structure finally showcase lielac efficacy tasks invariant image classification and lie point symmetry equivariant neural pde solvers pre trained models,2025-08-26T00:59:30.191766
19,"""Hyperbolic Contrastive Learning for Hierarchical Representations""",Contrastive learning in Euclidean space struggles to capture hierarchical relationships prevalent in real-world data. We propose a hyperbolic contrastive learning framework that leverages the exponential representational capacity of hyperbolic spaces for hierarchical representation learning. Our approach introduces a hyperbolic projection head and a novel curvilinear contrastive loss that respects hyperbolic geometry. Key innovations include hyperbolic batch normalization and momentum-based hyperbolic prototype updates. Experiments on hierarchical datasets demonstrate 30-50% improvement in downstream clustering quality compared to Euclidean contrastive learning. Theoretical analysis reveals improved generalization bounds through hyperbolic space properties. This work opens new directions for incorporating geometric priors into self-supervised learning.,ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,3887,Geometry-aware Distance Measure for Diverse Hierarchical Structures in Hyperbolic Spaces,"Learning in hyperbolic spaces has gained increasing attention due to the superior capability of modeling hierarchical structures. Existing hyperbolic learning methods use a fixed distance measure that assumes a uniform hierarchical structure across all data points. However, this assumption does not always hold in real-world scenarios, considering the diversity of the hierarchical structures of data. This work proposes to learn geometry aware distance measures that dynamically adjust to accommodate diverse hierarchical structures in hyperbolic spaces. We derive geometry aware distance measures by generating projections and curvatures for each pair of samples, which maps each pair to a suitable hyperbolic space. We introduce a revised low-rank decomposition scheme and a hard-pair mining mechanism to reduce the computational cost incurred by the pairwise generation without compromising accuracy. Moreover, we derive an upper bound of the low-rank approximation error via Talagrand concentration inequality to guarantee the effectiveness of our low-rank decomposition scheme. Theoretical analysis and experiments on standard image classification and few-shot learning tasks affirm the effectiveness of our method in refining hyperbolic learning through our geometry aware distance measures.",ICLR.cc/2025/Conference,4.75,nan,0.8826,contrastive learning euclidean space struggles capture hierarchical relationships prevalent real world data hyperbolic contrastive learning that leverages the exponential representational capacity hyperbolic spaces for hierarchical representation learning experiments hierarchical datasets improvement downstream clustering quality compared euclidean contrastive learning this opens directions for incorporating geometric priors into self supervised learning,learning hyperbolic spaces has gained increasing attention due the superior capability modeling hierarchical structures existing hyperbolic learning methods use fixed distance measure that assumes uniform hierarchical structure across all data points revised low rank decomposition scheme and hard pair mining mechanism reduce the computational cost incurred the pairwise generation compromising theoretical analysis and experiments standard image classification and few shot learning tasks affirm the effectiveness our refining hyperbolic learning our geometry aware distance measures,2025-08-26T00:59:30.191767
20,"""Disentangled Representation Learning via Causal Mechanism Sparsity""","Existing disentanglement methods often fail to recover truly causal factors due to reliance on statistical independence assumptions. We propose a causal mechanism sparsity framework that learns properly disentangled representations through sparse mechanism modeling. The approach combines structural causal models with a novel sparsity-inducing regularizer that promotes independent causal mechanisms. Theoretical analysis establishes identifiability guarantees under this sparsity prior. Experiments on image and medical datasets show our method identifies true generative factors with higher fidelity than existing approaches (20-35% better alignment scores). Notably, the learned representations enable novel causal interventions and transfer across domains. This work provides new foundations for causal-aware disentanglement with applications in interpretable AI.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,6965,Optimal Causal Representations and the Causal Information Bottleneck,"To effectively study complex causal systems, it is often useful to construct representations that simplify parts of the system by discarding irrelevant details while preserving key features.
The Information Bottleneck (IB) method is a widely used approach in representation learning that compresses random variables while retaining information about a target variable.
Traditional methods like IB are purely statistical and ignore underlying causal structures, making them ill-suited for causal tasks.
We propose the Causal Information Bottleneck (CIB), a causal extension of the IB, which compresses a set of chosen variables while maintaining causal control over a target variable.
This method produces representations which are causally interpretable, and which can be used when reasoning about interventions.
We present experimental results demonstrating that the learned representations accurately capture causality as intended.",ICLR.cc/2025/Conference,6.0,False,0.8286,notably the learned representations enable causal interventions and transfer across domains,the information bottleneck used representation learning that compresses random variables while retaining information about target variable this produces representations which are causally interpretable and which can used when reasoning about interventions,2025-08-26T00:59:30.191776
21,"""Neural Differential Topology for Representation Learning""","The topological structure of latent spaces profoundly impacts representation quality but remains underexplored. We introduce neural differential topology, a framework that explicitly controls topological properties of learned representations through differentiable topological computations. Our key innovation is a persistent homology-based regularizer that operates directly on high-dimensional representations, allowing precise control over topological features. Experiments on molecular property prediction and single-cell analysis demonstrate 15-25% improvement in low-data regimes by preserving biologically meaningful topology. Theoretical contributions include differential topology operators backpropagatable through neural networks. This work establishes topological structure as a first-class citizen in representation learning.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,642,Topological Blindspots: Understanding and Extending Topological Deep Learning Through the Lens of Expressivity,"Topological deep learning (TDL) is a rapidly growing field that seeks to leverage topological structure in data and facilitate learning from data supported on topological objects, ranging from molecules to 3D shapes. Most TDL architectures can be unified under the framework of higher-order message-passing (HOMP), which generalizes graph message-passing to higher-order domains. In the first part of the paper, we explore HOMP's expressive power from a topological perspective, demonstrating the framework's inability to capture fundamental topological and metric invariants such as diameter, orientability, planarity, and homology. In addition, we demonstrate HOMP's limitations in fully leveraging lifting and pooling methods on graphs. To the best of our knowledge, this is the first work to study the expressivity of TDL from a topological perspective. In the second part of the paper, we develop two new classes of architectures -- multi-cellular networks (MCN) and scalable MCN (SMCN) -- which draw inspiration from expressive GNNs. MCN can reach full expressivity, but scaling it to large data objects can be computationally expansive. Designed as a more scalable alternative, SMCN still mitigates many of HOMP's expressivity limitations. Finally, we design new benchmarks for evaluating models based on their ability to learn topological properties of complexes. We then evaluate SMCN on these benchmarks as well as on real-world graph datasets, demonstrating improvements over both HOMP baselines and expressive graph methods, highlighting the value of expressively leveraging topological information.",ICLR.cc/2025/Conference,8.0,True,0.8473,the topological structure latent spaces profoundly impacts representation quality but remains underexplored neural differential topology that explicitly controls topological properties learned representations differentiable topological computations experiments molecular property prediction and single cell analysis improvement low data regimes preserving biologically meaningful topology theoretical contributions include differential topology operators backpropagatable neural networks this establishes topological structure first class citizen representation learning,topological deep learning tdl rapidly growing field that seeks leverage topological structure data and facilitate learning from data supported topological objects ranging from molecules shapes,2025-08-26T00:59:30.191777
22,"""Temporal Abstraction in Reinforcement Learning via Symbolic Representation Learning""","Current RL agents struggle with temporal abstraction in long-horizon tasks due to flat representation spaces. We present a symbolic representation learning framework that automatically discovers temporally extended skills through differentiable symbolic program induction. The approach combines neural networks with symbolic program synthesis to learn interpretable temporal abstractions. Our key contribution is a temporal abstraction objective that jointly optimizes for policy optimality and program simplicity. Experiments on robotics and strategy games demonstrate our agent automatically discovers meaningful skills that transfer across tasks, achieving 2-3x faster learning in novel environments. Theoretical analysis connects representation quality to performance bounds in hierarchical RL. This work bridges deep learning and symbolic AI for temporal decision-making.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,6756,Discrete Latent Plans via Semantic Skill Abstractions,"Skill learning from language instructions is a critical challenge in developing intelligent agents that can generalize across diverse tasks and follow complex human instructions. Hierarchical methods address this by decomposing the learning problem into multiple levels, where the high-level and low-level policies are mediated through a latent plan space. Effective modeling and learning of this latent plan space are key to enabling robust and interpretable skill learning. In this paper, we introduce LADS, a hierarchical approach that learns language-conditioned discrete latent plans through semantic skill abstractions. Our method decouples the learning of the latent plan space from the language-conditioned high-level policy to improve training stability. First, we incorporate a trajectory encoder to learn a discrete latent space with the low-level policy, regularized by language instructions. Next, we model the high-level policy as a categorical distribution over these discrete latent plans to capture the multi-modality of the dataset. Through experiments in simulated control environments, we demonstrate that LADS outperforms state-of-the-art methods in both skill learning and compositional generalization.",ICLR.cc/2025/Conference,7.0,True,0.8308,current agents struggle temporal ion long horizon tasks due flat representation spaces symbolic representation learning that automatically discovers temporally extended skills differentiable symbolic program induction the combines neural networks symbolic program synthesis learn interpretable temporal ions experiments robotics and strategy games our agent automatically discovers meaningful skills that transfer across tasks achieving faster learning environments theoretical analysis connects representation quality bounds hierarchical this bridges deep learning and symbolic for temporal decision making,skill learning from language instructions critical challenge developing intelligent agents that can generalize across diverse tasks and follow complex human instructions hierarchical methods address this decomposing the learning problem into multiple levels where the high level and low level policies are mediated latent plan space effective modeling and learning this latent plan space are key enabling robust and interpretable skill learning this lads hierarchical that learns language conditioned discrete latent plans semantic skill ions our decouples the learning the latent plan space from the language conditioned high level policy improve training stability first incorporate trajectory encoder learn discrete latent space the low level policy regularized language instructions experiments simulated control environments that lads outperforms state the art methods both skill learning and compositional generalization,2025-08-26T00:59:30.191781
23,"""Information-Theoretic Representation Learning for Multi-Task Generalization""",Standard representation learning often fails to capture transferable features for diverse downstream tasks. We propose an information-theoretic framework that learns maximally transferable representations through simultaneous stochastic coding of multiple tasks. The approach introduces a novel variational upper bound on multi-task mutual information that enables efficient optimization. Our key innovation is a task-agnostic representation space that preserves only information relevant across tasks while suppressing task-specific details. Experiments on multi-domain benchmarks demonstrate 15-30% improvement in cross-task generalization compared to state-of-the-art meta-learning approaches. Theoretical analysis reveals connections to minimal sufficient statistics and information bottleneck principles. This work provides principled foundations for learning truly general-purpose representations.,ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,1510,PROVABLY EFFICIENT FEDERATED ACTIVE MULTI-TASK REPRESENTATION LEARNING,"Multi-task representation learning is an emerging machine learning paradigm that integrates data from multiple sources, harnessing task similarities to enhance overall model performance. The application of multi-task learning to real-world settings is hindered due to data scarcity, along with challenges related to scalability and computational resources. To address these challenges, we develop a fast and sample-efficient approach for multi-task active learning  with linear representation when the amount of data from source tasks and target tasks is limited.  By leveraging the techniques from active learning, we propose an adaptive sampling-based alternating projected gradient descent (GD) and minimization algorithm that iteratively estimates the relevance of each source task to the target task and samples from each source task based on the estimated relevance. We present the convergence guarantees and the sample and time complexities of our algorithm.  We evaluated the effectiveness of our algorithm using numerical experiments and compared it against four benchmark algorithms using synthetic and real MNIST-C datasets.",ICLR.cc/2025/Conference,5.666666666666667,False,0.8490,standard representation learning often fails capture transferable features for diverse downstream tasks the introduces variational upper bound multi task mutual information that enables efficient optimization our key innovation task agnostic representation space that preserves only information relevant across tasks while suppressing task specific details this provides principled foundations for learning truly general purpose representations,multi task representation learning emerging machine learning paradigm that integrates data from multiple sources harnessing task similarities enhance overall the application multi task learning real world settings hindered due data scarcity along challenges related scalability and computational resources address these challenges fast and sample efficient for multi task active learning linear representation when the amount data from source tasks and target tasks limited,2025-08-26T00:59:30.191787
24,"""Contrastive Learning with Non-Stationary Memory Banks""","Current contrastive learning methods often assume stationary data distributions, limiting their applicability to real-world non-stationary scenarios. We propose a framework that dynamically adjusts memory bank distributions to reflect changing data statistics. Our approach employs an online Bayesian mechanism to track distribution shifts, combined with an adaptive weighting scheme that balances old and new information. Theoretical analysis shows our method provides tighter generalization bounds under distribution drift compared to standard contrastive approaches. Experiments on streaming video and incremental learning benchmarks demonstrate 15-25% improvements in accuracy under non-stationary conditions. The adaptive memory mechanism also provides interpretable insights into distribution shifts occurring during training. This work bridges the gap between contrastive learning and non-stationary learning theory.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,10629,CLIP model is an Efficient Online Continual Learner,"Online continual learning addresses the challenge of learning from continuous, non-stationary data streams. Existing online continual learning frameworks are classification-based and assume a pre-defined number of classes. In this study, we propose that vision-language models (VLMs) are more suitable candidates for online continual learning. Compared to traditional classification-based frameworks, VLM such as CLIP model is not limited by the maximum number of classes or constrained by rigid model architectures, enabling it to generalize across both known and emerging classes. However, we find that naively tuning the CLIP for online continual learning results in asymmetric image-text matching. This asymmetric matching will consistently poses negative suppression on the previously learned classes, leading to catestrophic forgetting. To address this issue, we propose a simple yet effective method, the symmetric image-text (SIT) tuning strategy, which mitigates the adverse impact of negative samples by excluding asymmetric text during online learning. Additionally, we introduce a more challenging online continual learning setting with blurred boundary, namely MiD-Blurry, which mixes multiple data distributions to simulate real-world scenarios. We conduct extensive experiments on several continual learning benchmarks as well as the MiD-Blurry setting, evaluating both inference-at-any-time performance and generalization to future data. Our results demonstrate that the SIT strategy effectively preserves memory stability while maintaining learning plasticity.",ICLR.cc/2025/Conference,3.8,False,0.8331,current contrastive learning methods often assume stationary data distributions limiting their applicability real world non stationary scenarios experiments streaming video and incremental learning benchmarks improvements under non stationary conditions this bridges the gap between contrastive learning and non stationary learning theory,online continual learning addresses the challenge learning from continuous non stationary data streams existing online continual learning frameworks are classification based and assume pre defined number classes this that vision language models vlms are more suitable candidates for online continual learning however find that naively tuning the clip for online continual learning asymmetric image text matching address this issue simple yet effective the symmetric image text sit tuning strategy which mitigates the adverse impact negative samples excluding asymmetric text during online learning additionally more challenging online continual learning setting blurred boundary namely mid blurry which mixes multiple data distributions simulate real world scenarios conduct extensive experiments several continual learning benchmarks well the mid blurry setting evaluating both inference any time and generalization future data our that the sit strategy preserves memory stability while maintaining learning plasticity,2025-08-26T00:59:30.191790
25,"""Hyperbolic Word Embeddings with Poincaré Attention""","Standard word embeddings fail to capture hierarchical semantic relationships encoded in hyperbolic space. We introduce Poincaré attention networks that compute attention scores based on hyperbolic distances, preserving hierarchical structure throughout transformer architectures. Our key contribution is a novel hyperbolic attention layer that maintains gradients stable in the presence of large curvatures. Experiments on word similarity and sentence completion show our method improves hierarchical relationship modeling by 20-30% compared to Euclidean baselines, while maintaining competitive performance on standard NLP benchmarks. Theoretical analysis demonstrates our attention mechanism preserves universal approximation properties in hyperbolic space. This work enables transformers to better capture linguistic hierarchies without sacrificing performance on non-hierarchical tasks.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,199,HVT: A Comprehensive Vision Framework for Learning in Non-Euclidean Space,"Data representation in non-Euclidean spaces has proven effective for capturing hierarchical and complex relationships in real-world datasets. Hyperbolic spaces, in particular, provide efficient embeddings for hierarchical structures. This paper introduces the Hyperbolic Vision Transformer (HVT), a novel extension of the Vision Transformer (ViT) that integrates hyperbolic geometry. While traditional ViTs operate in Euclidean space, our method enhances the self-attention mechanism by leveraging hyperbolic distance and Möbius transformations. This enables more effective modeling of hierarchical and relational dependencies in image data. We present rigorous mathematical formulations, showing how hyperbolic geometry can be incorporated into attention layers, feed-forward networks, and optimization. We offer improved performance for image classification using the ImageNet dataset.",ICLR.cc/2025/Conference,3.4,nan,0.8393,standard word embeddings fail capture hierarchical semantic relationships encoded hyperbolic space poincaré attention networks that compute attention scores hyperbolic distances preserving hierarchical structure throughout transformer architectures our key hyperbolic attention layer that maintains gradients stable the presence large curvatures theoretical analysis demonstrates our attention mechanism preserves universal approximation properties hyperbolic space,data representation non euclidean spaces has proven effective for capturing hierarchical and complex relationships real world datasets this introduces the hyperbolic vision transformer hvt extension the vision transformer vit that integrates hyperbolic geometry rigorous mathematical formulations showing how hyperbolic geometry can incorporated into attention layers feed forward networks and optimization offer improved for image classification the imagenet,2025-08-26T00:59:30.191795
26,"""Dynamic Sparse Coding via Differentiable Topology""","Sparse coding traditionally struggles with dynamic data distributions due to fixed dictionaries. We present a dynamic sparse coding framework where the dictionary structure evolves according to differentiable topological optimization. Our method represents the dictionary as a learnable neural network with topology-aware regularization, allowing continuous adaptation to changing data manifolds. Theoretical guarantees ensure convergence in dynamic environments while maintaining reconstruction fidelity. Experiments on video sequences and sensor networks show 30% better reconstruction accuracy compared to static approaches, with interpretable topological evolution patterns. The differentiable topology approach opens new possibilities for adaptive signal processing architectures.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,642,Topological Blindspots: Understanding and Extending Topological Deep Learning Through the Lens of Expressivity,"Topological deep learning (TDL) is a rapidly growing field that seeks to leverage topological structure in data and facilitate learning from data supported on topological objects, ranging from molecules to 3D shapes. Most TDL architectures can be unified under the framework of higher-order message-passing (HOMP), which generalizes graph message-passing to higher-order domains. In the first part of the paper, we explore HOMP's expressive power from a topological perspective, demonstrating the framework's inability to capture fundamental topological and metric invariants such as diameter, orientability, planarity, and homology. In addition, we demonstrate HOMP's limitations in fully leveraging lifting and pooling methods on graphs. To the best of our knowledge, this is the first work to study the expressivity of TDL from a topological perspective. In the second part of the paper, we develop two new classes of architectures -- multi-cellular networks (MCN) and scalable MCN (SMCN) -- which draw inspiration from expressive GNNs. MCN can reach full expressivity, but scaling it to large data objects can be computationally expansive. Designed as a more scalable alternative, SMCN still mitigates many of HOMP's expressivity limitations. Finally, we design new benchmarks for evaluating models based on their ability to learn topological properties of complexes. We then evaluate SMCN on these benchmarks as well as on real-world graph datasets, demonstrating improvements over both HOMP baselines and expressive graph methods, highlighting the value of expressively leveraging topological information.",ICLR.cc/2025/Conference,8.0,True,0.8024,dynamic sparse coding where the dictionary structure evolves according differentiable topological optimization our represents the dictionary learnable neural network topology aware regularization allowing continuous adaptation changing data manifolds the differentiable topology opens possibilities for adaptive signal processing architectures,topological deep learning tdl rapidly growing field that seeks leverage topological structure data and facilitate learning from data supported topological objects ranging from molecules shapes,2025-08-26T00:59:30.191796
27,"""Causal Representation Transfer for Domain Generalization""","Domain generalization methods often fail to distinguish causal from non-causal features. We develop a causal representation transfer framework that identifies stable causal features through counterfactual data augmentation. Our approach combines causal discovery with adversarial feature alignment, enforcing invariance across both observed and synthesized counterfactual domains. Theoretical analysis proves identifiability of causal representations under our framework. Experiments on medical imaging and satellite data benchmarks demonstrate 25-40% improvement in unseen domain generalization compared to existing methods. Notably, our approach requires no additional domain labels during training. This work establishes causal representation learning as a principled foundation for domain generalization.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,5536,Multimodal Unsupervised Domain Generalization by Retrieving Across the Modality Gap,"Domain generalization (DG) is an important problem that learns a model which generalizes to unseen test domains leveraging one or more source domains, under the assumption of shared label spaces. However, most DG methods assume access to abundant source data in the target label space, a requirement that proves overly stringent for numerous real-world applications, where acquiring the same label space as the target task is prohibitively expensive. For this setting, we tackle the multimodal version of the unsupervised domain generalization (MUDG) problem, which uses a large task-agnostic unlabeled source dataset during finetuning. Our framework does not explicitly assume any relationship between the source dataset and target task. Instead, it relies only on the premise that the source dataset can be accurately and efficiently searched in a joint vision-language space. We make three contributions in the MUDG setting. Firstly, we show theoretically that cross-modal approximate nearest neighbor search suffers from low recall due to the large distance between text queries and the image centroids used for coarse quantization. Accordingly, we propose paired k-means, a simple clustering algorithm that improves nearest neighbor recall by storing centroids in query space instead of image space. Secondly, we propose an adaptive text augmentation scheme for target labels designed to improve zero-shot accuracy and diversify retrieved image data. Lastly, we present two simple but effective components to further improve downstream target accuracy. We compare against state-of-the-art name-only transfer, source-free DG and zero-shot (ZS) methods on their respective benchmarks and show consistent improvement in accuracy on 20 diverse datasets. Code is available: https://github.com/Chris210634/mudg",ICLR.cc/2025/Conference,7.0,True,0.8437,domain generalization methods often fail distinguish causal from non causal features causal representation transfer that identifies stable causal features counterfactual data augmentation our combines causal discovery adversarial feature alignment enforcing invariance across both observed and synthesized counterfactual domains experiments medical imaging and satellite data benchmarks improvement unseen domain generalization compared existing methods notably our requires additional domain labels during training this establishes causal representation learning principled foundation for domain generalization,domain generalization important problem that learns which generalizes unseen domains leveraging one more source domains under the assumption shared label spaces for this setting tackle the multimodal version the unsupervised domain generalization mudg problem which uses large task agnostic unlabeled source during finetuning accordingly paired means simple clustering that improves nearest neighbor storing centroids query space instead image space secondly adaptive text augmentation scheme for target labels designed improve zero shot and diversify retrieved image data against state the art name only transfer source free and zero shot methods their respective benchmarks and consistent improvement diverse datasets,2025-08-26T00:59:30.191803
28,"""Neural Differential Geometry for Manifold-aware Representations""","Current representation learning methods often ignore the differential geometric structure of data manifolds. We propose a neural differential geometry framework that explicitly models manifold properties through learned connections and curvature tensors. Our architecture implements learnable parallel transport operators and Ricci curvature estimation layers, enabling faithful manifold reconstruction from sparse samples. Experiments on molecular property prediction and robotics state estimation show 20-35% improvement over Euclidean baselines while maintaining mathematical consistency. Theoretical contributions include stability guarantees for neural curvature estimation. This work provides a geometric foundation for principled manifold learning in deep networks.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,1005,Optimizing Learning for Robust Hyperbolic Deep Learning in Computer Vision,"Hyperbolic deep learning has become a growing research direction in computer vision for the unique properties afforded by the alternate embedding space. The negative curvature and exponentially growing distance metric provide a natural framework for capturing hierarchical relationships between datapoints and allowing for finer separability between their embeddings. However, these methods are still computationally expensive and prone to instability, especially when attempting to learn the negative curvature that best suits the task and the  data. Current Riemannian optimizers do not account for changes in the manifold which greatly harms performance and forces lower learning rates to minimize projection errors. Our paper focuses on improving stability for curvature learning by introducing an improved schema for popular learning algorithms and providing a novel normalization approach to constrain embeddings within the variable representative radius of the manifold. Additionally, we introduce a novel formulation for Riemannian AdamW, and alternative hybrid encoder techniques and foundational formulations for current convolutional hyperbolic operations, greatly reducing the computational penalty of the hyperbolic embedding space. Our approach demonstrates consistent performance improvements across direct classification, generation, and hierarchical metric learning tasks while allowing for larger hyperbolic models.",ICLR.cc/2025/Conference,4.4,False,0.8261,current representation learning methods often ignore the differential geometric structure data manifolds neural differential geometry that explicitly models manifold properties learned connections and curvature tensors experiments molecular property prediction and robotics state estimation improvement over euclidean baselines while maintaining mathematical consistency theoretical contributions include stability guarantees for neural curvature estimation this provides geometric foundation for principled manifold learning deep networks,hyperbolic deep learning has become growing direction computer vision for the unique properties afforded the alternate embedding space current riemannian optimizers not account for changes the manifold which greatly harms and forces lower learning rates minimize projection errors our focuses improving stability for curvature learning introducing improved schema for popular learning algorithms and providing normalization constrain embeddings within the variable representative radius the manifold additionally formulation for riemannian adamw and alternative hybrid encoder techniques and foundational formulations for current convolutional hyperbolic operations greatly reducing the computational penalty the hyperbolic embedding space our demonstrates consistent improvements across direct classification generation and hierarchical learning tasks while allowing for larger hyperbolic models,2025-08-26T00:59:30.191808
29,"""Temporal Disentanglement via Latent ODE Adversaries""","Existing disentanglement methods struggle with temporal sequences where factors evolve at different timescales. We introduce a temporal disentanglement framework that uses competing latent ODEs to separate factors by their characteristic frequencies. Our architecture features multiple adversarial ODE systems with frequency-aware regularization, forcing separation of temporal scales. Theoretical analysis connects our adversarial objective to identifiable factor disentanglement. Experiments on video and physiological signals demonstrate superior separation of temporal factors (40-50% improvement in factor purity) while maintaining predictive performance. This approach enables interpretable analysis of dynamical systems with applications in medical time series and robotics.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,False,,Neural Electrostatics: A 3D Physics-Informed Boundary Element Poisson Equation Solver,"Electrostatics solvers relate an imposed voltage to a
corresponding charge density. Current classical methods require fine
discretization and scale poorly due to the construction of a large linear system
of equations. We recast the problem using neural networks and introduce
neural electrostatics, a hybrid 3D boundary element method (BEM). By using the
boundary element form, we are able to overcome many shortcomings of previous
neural solvers, such as learning trivial solutions and balancing loss terms
between the domain and boundary, at the cost of introducing a large integral
containing a singular kernel. We handle this singularity by locally
transforming the integral into polar coordinates and applying a numerical
quadrature. We also show that previous neural solver sampling methods are unable
to minimize the PDE residual, and propose a variational adaptive sampling
method. This technique is able to reduce mean absolute error by 5 times, while
keeping training time constant. Extensive scaling and ablation studies are
performed to justify our method. Results show that our method learns a charge
distribution within 1.2 $pC/m^2$ of mean absolute error from a classical BEM
solver, while using 25 times fewer rectangular elements.",ICLR.cc/2025/Conference,4.0,False,0.0000,,recast the problem neural networks and neural electrostatics hybrid boundary element bem the boundary element form are able overcome many shortcomings previous neural solvers such learning trivial solutions and balancing loss terms between the domain and boundary the cost introducing large integral containing singular kernel also that previous neural solver sampling methods are unable minimize the pde residual and variational adaptive sampling,2025-08-26T00:59:30.191810
30,"""Equivariant Representation Learning for Unknown Symmetries""","Handling unknown or partial symmetries remains challenging for equivariant architectures. We present a symmetry-discovery framework that simultaneously learns representations and identifies underlying symmetries through gradient-based symmetry detection. Our approach combines equivariant networks with a symmetry estimation subnetwork, enabling adaptation to novel symmetry groups. Theoretical guarantees ensure consistent symmetry detection under mild conditions. Experiments on crystallography and particle physics data show competitive performance with supervised symmetry information while automatically discovering physically meaningful symmetry groups. This work eliminates the need for domain-specific symmetry knowledge in equivariant learning systems.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,7162,Consistent Symmetry Representation over Latent Factors of Variation,"Recent symmetry-based methods on variational autoencoders have advanced disentanglement learning and combinatorial generalization, yet the appropriate symmetry representation for both tasks is under-clarified. We identify that existing methods struggle with maintaining the $\textit{consistent symmetries}$ when representing identical changes of latent factors of variation, and they cause issues in achieving equivari-
ance. We theoretically prove the limitations of three frequently used group settings: matrix multiplication with General Lie Groups, defining group action with set of vectors and vector addition, and cyclic groups modeled through surjective functions. To overcome these issues, we introduce a novel method of $\textit{conformal mapping}$ of latent vectors into a complex number space, ensuring consistent symmetries
and cyclic semantics. Through empirical validation with ground truth of factors variation for transparent analysis, this study fills two significant gaps in the literature: 1) the inductive bias to enhance disentanglement learning and combinatorial generalization simultaneously, and 2) well-represented symmetries ensure significantly high disentanglement performance without a trade-off in reconstruction error, compared to current unsupervised methods. Additionally, we introduce less guidance-dependent validation results, extending our findings to more practical use. Our research highlights the significant impact of verifying consistent symmetry and suggests required future research for advancing combinatorial generalization and disentanglement learning.",ICLR.cc/2025/Conference,4.5,nan,0.8550,symmetry discovery that simultaneously learns representations and identifies underlying symmetries gradient based symmetry detection our combines equivariant networks symmetry estimation subnetwork enabling adaptation symmetry groups theoretical guarantees ensure consistent symmetry detection under mild conditions experiments crystallography and particle physics data competitive supervised symmetry information while automatically discovering physically meaningful symmetry groups this eliminates the need for domain specific symmetry knowledge equivariant learning systems,recent symmetry based methods variational autoencoders have advanced disentanglement learning and combinatorial generalization yet the appropriate symmetry representation for both tasks under clarified empirical validation ground truth factors variation for transparent analysis this fills two significant gaps the literature the inductive bias enhance disentanglement learning and combinatorial generalization simultaneously and well represented symmetries ensure high disentanglement trade off reconstruction error compared current unsupervised methods our highlights the significant impact verifying consistent symmetry and suggests required future for advancing combinatorial generalization and disentanglement learning,2025-08-26T00:59:30.191815
31,"""Topological Regularization for Robust Representation Learning""",Standard regularization techniques often fail to preserve topological structure crucial for generalization. We develop a topological regularization framework based on persistent homology gradients that explicitly maintains desired topological features during training. Our method introduces differentiable topological loss terms that operate directly on high-dimensional representations without requiring dimensionality reduction. Experimental results across vision and graph learning tasks demonstrate 15-25% improvements in adversarial robustness and domain transfer compared to standard regularization approaches. Theoretical analysis connects topological persistence to generalization bounds. This work establishes topological structure as a new regularization paradigm for deep learning.,ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,8286,Towards Scalable Topological Regularizers,"Latent space matching, which consists of matching distributions of features in latent space, is a crucial component for tasks such as adversarial attacks and defenses, domain adaptation, and generative modelling.
    Metrics for probability measures, such as Wasserstein and maximum mean discrepancy, are commonly used to quantify the differences between such distributions.
    However, these are often costly to compute, or do not appropriately take the geometric and topological features of the distributions into consideration.
    Persistent homology is a tool from topological data analysis which quantifies the multi-scale topological structure of point clouds, and has recently been used as a topological regularizer in learning tasks.
    However, computation costs preclude larger scale computations, and discontinuities in the gradient lead to unstable training behavior such as in adversarial tasks. 
    We propose the use of principal persistence measures, based on computing the persistent homology of a large number of small subsamples, as a topological regularizer.
    We provide a parallelized GPU implementation of this regularizer, and prove that gradients are continuous for smooth densities.
    Furthermore, we demonstrate the efficacy of this regularizer on shape matching, image generation, and semi-supervised learning tasks, opening the door towards a scalable regularizer for topological features.",ICLR.cc/2025/Conference,7.0,True,0.8324,experimental across vision and graph learning tasks improvements adversarial robustness and domain transfer compared standard regularization approaches this establishes topological structure regularization paradigm for deep learning,latent space matching which consists matching distributions features latent space crucial component for tasks such adversarial attacks and defenses domain adaptation and generative modelling persistent homology tool from topological data analysis which quantifies the multi scale topological structure point clouds and has recently been used topological regularizer learning tasks furthermore the efficacy this regularizer shape matching image generation and semi supervised learning tasks opening the door towards scalable regularizer for topological features,2025-08-26T00:59:30.191820
32,"""Multi-Scale Diffusion Embeddings for Hierarchical Representation Learning""","Learning representations that simultaneously capture fine-grained and coarse-grained structure remains a fundamental challenge. We propose a novel hierarchical embedding framework based on diffusion processes across multiple scales. Our approach constructs a pyramid of diffusion operators that progressively coarsen the data geometry while preserving local-to-global relationships. The key innovation is a spectral alignment procedure that ensures consistency across scales, enabling seamless combination of features at different resolutions. Theoretical analysis shows our method preserves topological invariants while learning semantically meaningful representations. Experiments on molecular property prediction and image classification demonstrate 15-25% improvement over single-scale approaches, particularly on tasks requiring hierarchical reasoning. This work provides a principled geometric foundation for multi-scale representation learning with applications across scientific domains.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,6868,Unified Deep Discrete Representation Learning Framework,"Recent years have seen significant success of deep discrete representation learning across a broad range of domains. Existing frameworks typically operate on flat latents, overlooking the hierarchical structure within discrete latent spaces, which if effectively exploited could yield richer and more expressive representations. This work contributes a novel hierarchical discrete representation learning framework that flexibly generalizes to a variety of tasks and demonstrates effectiveness across diverse applications. We provide a theoretical analysis on sample complexity and additionally study the effect of codebook utilization on task performance. We offer practical insights into how these factors interplay in different learning scenarios.",ICLR.cc/2025/Conference,2.0,nan,0.8222,learning representations that simultaneously capture fine grained and coarse grained structure remains fundamental challenge hierarchical embedding diffusion processes across multiple scales theoretical analysis shows our preserves topological invariants while learning semantically meaningful representations experiments molecular property prediction and image classification improvement over single scale approaches tasks requiring hierarchical reasoning this provides principled geometric foundation for multi scale representation learning applications across scientific domains,recent years have seen significant success deep discrete representation learning across broad range domains this contributes hierarchical discrete representation learning that flexibly generalizes variety tasks and demonstrates effectiveness across diverse applications offer practical insights into how these factors interplay different learning scenarios,2025-08-26T00:59:30.191821
33,"""Learnable Physical Priors for Scientific Representation Learning""","Traditional representation learning often ignores domain-specific physical constraints critical for scientific applications. We develop a framework that incorporates learnable physical priors through differentiable physics simulators embedded in the representation learning pipeline. Our architecture alternates between neural embedding updates and physics-constrained optimization steps, gradually adapting the physical parameters to match observed data while learning representations. Results in computational chemistry and fluid dynamics show 30-40% improvement in prediction accuracy compared to purely data-driven approaches, while maintaining physically plausible behavior. The learned representations exhibit interpretable physical meaning, enabling new scientific insights. This work bridges the gap between machine learning and scientific computing through dual learning of representations and physics models.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,4768,Derivatives Are All You Need For Learning Physical Models,"Physics-Informed Neural Networks (PINNs) explicitly incorporate Partial Differential Equations (PDEs) into the loss function, thus learning representations that are inherently consistent with the physical system. 
We claim that it is possible to learn physically consistent models without explicit knowledge about the underlying equations. We propose Derivative Learning (DERL) to model a physical system by learning its partial derivatives, as they contain all the necessary information to determine the system's dynamics. Like in PINNs, we also train the learning model on the initial and boundary conditions of the system. 
We provide theoretical guarantees that our approach learns the true solution and is consistent with the underlying physical laws, even when using empirical derivatives. DERL outperforms PINNs and other state-of-the-art approaches in tasks ranging from simple dynamical systems to PDEs. Finally, we show that distilling the derivatives enables the transfer of physical information from one model to another. Distillation of higher-order derivatives improves physical consistency. Ultimately, learning and distilling the derivatives of physical systems turns out to be a powerful tool to learn physical models.",ICLR.cc/2025/Conference,2.5,False,0.8286,traditional representation learning often ignores domain specific physical constraints critical for scientific applications that incorporates learnable physical priors differentiable physics simulators embedded the representation learning pipeline our alternates between neural embedding updates and physics constrained optimization steps gradually adapting the physical parameters match observed data while learning representations computational chemistry and fluid dynamics improvement prediction compared purely data driven approaches while maintaining physically plausible behavior this bridges the gap between machine learning and scientific computing dual learning representations and physics models,physics informed neural networks pinns explicitly incorporate partial differential equations pdes into the loss function thus learning representations that are inherently consistent the physical claim that possible learn physically consistent models explicit knowledge about the underlying equations derivative learning derl physical learning its partial derivatives they contain all the necessary information determine the system dynamics like pinns also train the learning the initial and boundary conditions the finally that distilling the derivatives enables the transfer physical information from one another ultimately learning and distilling the derivatives physical systems turns out powerful tool learn physical models,2025-08-26T00:59:30.191825
34,"""Dynamic Graph Representation Learning with Continuous-Time Neural Processes""","Most graph representation learning methods treat graphs as static structures, ignoring their continuous temporal evolution. We propose a continuous-time neural process framework that models graph dynamics through learned stochastic processes on graphs. Our approach combines neural differential equations with graph attention mechanisms to capture both structural changes and node feature evolution. Theoretical contributions include stability guarantees for the learned dynamics and sample complexity bounds. Experiments on dynamic molecular graphs and social networks demonstrate superior performance (20-35% improvement) in forecasting tasks compared to discrete-time approaches. The method also generates plausible future graph states, enabling simulation and counterfactual reasoning about system evolution.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,9139,Towards Dynamic Graph Neural Networks with Provably High-Order Expressive Power,"Dynamic Graph Neural Networks (DyGNNs) have garnered increasing research attention for learning representations on evolving graphs. 
Despite their effectiveness, the limited expressive power of existing DyGNNs hinders them from capturing important evolving patterns of dynamic graphs. 
Although some works attempt to enhance expressive capability with heuristic features, there remains a lack of DyGNN frameworks with provable and quantifiable high-order expressive power.
To address this research gap, we firstly propose the k-dimensional Dynamic WL tests (k-DWL) as the referencing algorithms to quantify the expressive power of DyGNNs. We demonstrate that the expressive power of existing DyGNNs is bounded by the 1-DWL test. 
To enhance the expressive power, we propose Dynamic Graph Neural Network with High-order expressive power (HopeDGN), which updates the representation of central node pair by aggregating the interaction history with neighbor node pairs. 
Our theoretical results demonstrate that HopeDGN can achieve expressive power equivalent to the 2-DWL test. 
We then present a Transformer-based implementation for the local variant of \model.
Experimental results show that HopeDGN achieved  performance improvement up to 3.12\% on seven datasets, demonstrating the effectiveness of HopeDGN.",ICLR.cc/2025/Conference,4.8,nan,0.8494,most graph representation learning methods treat graphs static structures ignoring their continuous temporal evolution continuous time neural process that models graph dynamics learned stochastic processes graphs our combines neural differential equations graph attention mechanisms capture both structural changes and node feature evolution the also generates plausible future graph states enabling simulation and counterfactual reasoning about evolution,dynamic graph neural networks dygnns have garnered increasing attention for learning representations evolving graphs enhance the expressive power dynamic graph neural network high order expressive power hopedgn which updates the representation central node pair aggregating the interaction history neighbor node pairs,2025-08-26T00:59:30.191832
35,"""Causal Representation Reinforcement Learning""","Standard reinforcement learning struggles with credit assignment in environments where observations correlate with but don't cause rewards. We introduce causal representation reinforcement learning (CRRL), which jointly learns causal world models and policy representations optimized for causal credit assignment. CRRL employs a novel intervention-aware policy gradient that distinguishes between correlation and causation in reward attribution. Theoretical results show faster convergence in environments with confounding variables compared to standard RL. Experiments in robotics and economic simulation environments demonstrate 2-3x speedup in learning complex tasks requiring causal reasoning. This work establishes causal representation learning as a foundation for sample-efficient RL in structured environments.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,9021,Causal Information Prioritization for Efficient Reinforcement Learning,"Current Reinforcement Learning (RL) methods often suffer from sample-inefficiency, resulting from blind exploration strategies that neglect causal relationships among states, actions, and rewards. Although recent causal approaches aim to address this problem, they lack grounded modeling of reward-guided causal understanding of states and actions for goal-orientation, thus impairing learning efficiency. To tackle this issue, we propose a novel method named Causal Information Prioritization (CIP) that improves sample efficiency by leveraging factored MDPs to infer causal relationships between different dimensions of states and actions with respect to rewards, enabling the prioritization of causal information. Specifically, CIP identifies and leverages causal relationships between states and rewards to execute counterfactual data augmentation to prioritize high-impact state features under the causal understanding of the environments. Moreover, CIP integrates a causality-aware empowerment learning objective, which significantly enhances the agent's execution of reward-guided actions for more efficient exploration in complex environments. 
To fully assess the effectiveness of CIP, we conduct extensive experiments across $39$ tasks in $5$ diverse continuous control environments, encompassing both locomotion and manipulation skills learning with pixel-based and sparse reward settings. Experimental results demonstrate that CIP consistently outperforms existing RL methods across a wide range of scenarios.",ICLR.cc/2025/Conference,6.333333333333333,True,0.8766,standard reinforcement learning struggles credit assignment environments where observations correlate but don cause rewards causal representation reinforcement learning crrl which jointly learns causal world models and policy representations optimized for causal credit assignment experiments robotics and economic simulation environments speedup learning complex tasks requiring causal reasoning this establishes causal representation learning foundation for sample efficient structured environments,current reinforcement learning methods often suffer from sample inefficiency resulting from blind exploration strategies that neglect causal relationships among states actions and rewards although recent causal approaches aim address this problem they lack grounded modeling reward guided causal understanding states and actions for goal orientation thus impairing learning efficiency moreover cip integrates causality aware empowerment learning objective which enhances the agent execution reward guided actions for more efficient exploration complex environments fully assess the effectiveness cip conduct extensive experiments across tasks diverse continuous control environments encompassing both locomotion and manipulation skills learning pixel based and sparse reward settings,2025-08-26T00:59:30.191836
36,"""Quantized Manifold Learning with Hyperbolic Error Correction""",Discrete representation learning often suffers from quantization distortion in high-dimensional spaces. We present a quantization framework that leverages hyperbolic space properties for preserving manifold structure under discretization. The key innovation is a hyperbolic error correction code that mitigates quantization artifacts through curvature-aware nearest neighbor decoding. Theoretical analysis shows our approach maintains exponentially better fidelity compared to Euclidean quantization for hierarchical data. Applications in biological sequence modeling achieve 20-30% improvement in downstream task performance while enabling efficient discrete representations for large-scale similarity search. This work demonstrates how intelligent use of geometric properties can overcome fundamental limitations in discrete representation learning.,ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,7604,Disentangled Representation Learning with the Gromov-Monge Gap,"Learning disentangled representations from unlabelled data is a fundamental challenge in machine learning. Solving it may unlock other problems, such as generalization, interpretability, or fairness. Although remarkably challenging to solve in theory, disentanglement is often achieved in practice through prior matching. Furthermore, recent works have shown that prior matching approaches can be enhanced by leveraging geometrical considerations, e.g., by learning representations that preserve geometric features of the data, such as distances or angles between points. However, matching the prior while preserving geometric features is challenging, as a mapping that *fully* preserves these features while aligning the data distribution with the prior does not exist in general. To address these challenges, we introduce a novel approach to disentangled representation learning based on quadratic optimal transport. We formulate the problem using Gromov-Monge maps that transport one distribution onto another with minimal distortion of predefined geometric features, preserving them *as much as can be achieved*. To compute such maps, we propose the Gromov-Monge-Gap (GMG), a regularizer quantifying whether a map moves a reference distribution with minimal geometry distortion. We demonstrate the effectiveness of our approach for disentanglement across four standard benchmarks, outperforming other methods leveraging geometric considerations.",ICLR.cc/2025/Conference,5.5,True,0.8355,discrete representation learning often suffers from quantization distortion high dimensional spaces this demonstrates how intelligent use geometric properties can overcome fundamental limitations discrete representation learning,learning disentangled representations from unlabelled data fundamental challenge machine learning solving may unlock other problems such generalization interpretability fairness learning representations that preserve geometric features the data such distances angles between points address these challenges disentangled representation learning quadratic optimal transport,2025-08-26T00:59:30.191842
37,"""Task-Symmetric Representation Learning for Bidirectional Transfer""","Current transfer learning approaches typically assume a directional relationship between source and target tasks. We propose task-symmetric representation learning, which optimizes representations for bidirectional transfer between arbitrary task pairs. Our architecture employs symmetry-enforcing constraints through a novel commutative operator design that prevents representations from becoming overly specialized. Theoretical analysis reveals connections to mutual information maximization across tasks. Experiments on multi-task NLP and vision benchmarks demonstrate consistently strong bidirectional transfer performance, outperforming specialized approaches by 15-20% in both directions. This work establishes a new paradigm for learning universally transferable representations without requiring task hierarchies.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,1510,PROVABLY EFFICIENT FEDERATED ACTIVE MULTI-TASK REPRESENTATION LEARNING,"Multi-task representation learning is an emerging machine learning paradigm that integrates data from multiple sources, harnessing task similarities to enhance overall model performance. The application of multi-task learning to real-world settings is hindered due to data scarcity, along with challenges related to scalability and computational resources. To address these challenges, we develop a fast and sample-efficient approach for multi-task active learning  with linear representation when the amount of data from source tasks and target tasks is limited.  By leveraging the techniques from active learning, we propose an adaptive sampling-based alternating projected gradient descent (GD) and minimization algorithm that iteratively estimates the relevance of each source task to the target task and samples from each source task based on the estimated relevance. We present the convergence guarantees and the sample and time complexities of our algorithm.  We evaluated the effectiveness of our algorithm using numerical experiments and compared it against four benchmark algorithms using synthetic and real MNIST-C datasets.",ICLR.cc/2025/Conference,5.666666666666667,False,0.8362,current transfer learning approaches assume directional relationship between source and target tasks task symmetric representation learning which optimizes representations for bidirectional transfer between arbitrary task pairs experiments multi task nlp and vision benchmarks consistently strong bidirectional transfer outperforming specialized approaches both directions this establishes paradigm for learning universally transferable representations requiring task hierarchies,multi task representation learning emerging machine learning paradigm that integrates data from multiple sources harnessing task similarities enhance overall the application multi task learning real world settings hindered due data scarcity along challenges related scalability and computational resources address these challenges fast and sample efficient for multi task active learning linear representation when the amount data from source tasks and target tasks limited,2025-08-26T00:59:30.191843
38,"""Neuromorphic Representation Learning with Spiking Distance Metrics""","Traditional representation learning relies on artificial neural activations that differ fundamentally from biological computation. We develop a spiking neural framework that learns representations through spike-timing-dependent similarity measures. Our approach introduces three key innovations: spike-based distance metrics, temporally precise learning rules, and sparse coding via population spiking patterns. Neuromorphic simulations demonstrate energy efficiency improvements of 10-100x compared to conventional approaches while maintaining competitive accuracy. More importantly, the learned representations exhibit biologically plausible features including robustness to noise and temporal processing capabilities. This work advances the development of brain-inspired learning systems that bridge the gap between machine learning and neuroscience.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,8266,P-SPIKESSM: HARNESSING PROBABILISTIC SPIKING STATE SPACE MODELS FOR LONG-RANGE DEPENDENCY TASKS,"Spiking neural networks (SNNs) are posited as a computationally efficient and biologically plausible alternative to conventional neural architectures, with their core computational framework primarily using the leaky integrate-and-fire (LIF) neuron model. However, the limited hidden state representation of LIF neurons, characterized by a scalar membrane potential, and sequential spike generation process, poses challenges for effectively developing scalable spiking models to address long-range dependencies in sequence learning tasks. In this study, we  develop a scalable probabilistic spiking learning framework for long-range dependency tasks leveraging the fundamentals of state space models. Unlike LIF neurons that rely on the deterministic Heaviside function for a sequential process of spike generation, we introduce a SpikeSampler layer that samples spikes stochastically based on an SSM-based neuronal model while allowing parallel computations. To address non-differentiability of the spiking operation and enable effective training, we also propose a surrogate function tailored for the stochastic nature of the SpikeSampler layer. To enhance inter-neuron communication, we introduce the SpikeMixer block, which integrates spikes from neuron populations in each layer. This is followed by a ClampFuse layer, incorporating a residual connection to capture complex dependencies, enabling scalability of the model. Our models attain state-of-the-art performance among SNN models across diverse long-range dependency tasks, encompassing the Long Range Arena benchmark, permuted sequential MNIST, and the Speech Command dataset and demonstrate sparse spiking pattern highlighting its computational efficiency.",ICLR.cc/2025/Conference,6.75,True,0.8338,traditional representation learning relies artificial neural activations that differ fundamentally from biological computation spiking neural that learns representations spike timing dependent similarity measures our introduces three key innovations spike based distance metrics temporally precise learning rules and sparse coding population spiking patterns more importantly the learned representations exhibit biologically plausible features including robustness noise and temporal processing capabilities this advances the development brain inspired learning systems that bridge the gap between machine learning and neuroscience,spiking neural networks snns are posited computationally efficient and biologically plausible alternative conventional neural architectures their core computational primarily the leaky integrate and fire lif neuron however the limited hidden state representation lif neurons characterized scalar membrane potential and sequential spike generation process poses challenges for developing scalable spiking models address long range dependencies sequence learning tasks this scalable probabilistic spiking learning for long range dependency tasks leveraging the fundamentals state space models,2025-08-26T00:59:30.191846
39,"""Temporal Contrastive Learning with Dynamical System Embeddings""","Standard contrastive learning treats sequential data as unordered sets of features. We propose dynamical system embeddings (DSE), which represent sequences as points in a space of dynamical systems. Our framework combines contrastive learning with system identification techniques to learn embeddings that capture dynamic invariants of time series. Key contributions include stability-preserving projection operators and geometric-aware similarity metrics for dynamical systems. Applications to sensor networks and financial time series demonstrate 25-40% improvement in retrieval and forecasting tasks compared to static representation approaches. The method also enables novel dynamical system interpolation and synthesis capabilities, suggesting applications in control and simulation.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,2872,FreRA: A Frequency-Refined Augmentation for Contrastive Learning on Time Series Classification,"Contrastive learning has emerged as a competent approach for unsupervised representation learning. However, the design of an optimal augmentation strategy, although crucial for contrastive learning, is less explored for time series classification tasks. Existing predefined time-domain augmentation methods are primarily adopted from vision and are not specific to time series data. Consequently, this cross-modality incompatibility may distort the global semantics of time series by introducing mismatched patterns into the data. To address this limitation, we present a novel perspective from the frequency domain and identify three advantages for downstream classification: 1) the frequency component naturally encodes global features, 2) the orthogonal nature of the Fourier basis allows easier isolation and independent modifications of critical and unimportant information, and 3) a compact set of frequency components can preserve semantic integrity. To fully utilize the three properties, we propose the lightweight yet effective Frequency-Refined Augmentation (FreRA) tailored for time series contrastive learning on classification tasks, which can be seamlessly integrated with contrastive learning frameworks in a plug-and-play manner. Specifically, FreRA automatically separates critical and unimportant frequency components. Accordingly, we propose Identity Modification and Self-adaptive Modification to protect global semantics in the critical frequency components and infuse variance to the unimportant ones respectively. 
Theoretically, we prove that FreRA generates semantic-preserving views. Empirically, we conduct extensive experiments on two benchmark datasets including UCR and UEA archives, as well as 5 large-scale datasets on diverse applications. FreRA consistently outperforms 10 leading baselines on time series classification, anomaly detection, and transfer learning tasks, demonstrating superior capabilities in contrastive representation learning and generalization in transfer learning scenarios across diverse datasets.",ICLR.cc/2025/Conference,5.25,False,0.8543,standard contrastive learning treats sequential data unordered sets features our combines contrastive learning identification techniques learn embeddings that capture dynamic invariants time series applications sensor networks and financial time series improvement retrieval and forecasting tasks compared static representation approaches,contrastive learning has emerged competent for unsupervised representation learning however the optimal augmentation strategy although crucial for contrastive learning less explored for time series classification tasks existing predefined time domain augmentation methods are primarily adopted from vision and are not specific time series data address this limitation perspective from the frequency domain and identify three advantages for downstream classification the frequency component naturally encodes global features the orthogonal nature the fourier basis allows easier isolation and independent modifications critical and unimportant information and compact set frequency components can preserve semantic integrity fully utilize the three properties the lightweight yet effective frequency refined augmentation frera tailored for time series contrastive learning classification tasks which can seamlessly integrated contrastive learning frameworks plug and play manner frera consistently outperforms leading baselines time series classification anomaly detection and transfer learning tasks demonstrating superior capabilities contrastive representation learning and generalization transfer learning scenarios across diverse datasets,2025-08-26T00:59:30.191853
40,"""Symmetry-Aware Representation Learning via Differentiable Group Discovery""","Current approaches to equivariant representation learning require explicit knowledge of symmetry groups a priori, limiting their applicability to novel domains. We propose a framework that simultaneously learns group-equivariant representations while discovering relevant symmetry groups directly from data. Our method constructs a learnable group structure space where candidate symmetry operations are evaluated through their effect on representation utility. Theoretical analysis shows our approach recovers known symmetry groups in analytically tractable cases while scaling to complex real-world scenarios. Experiments across molecular property prediction and robotic manipulation tasks demonstrate 15-30% improvements in sample efficiency compared to fixed-symmetry baselines. Notably, the discovered symmetries align well with known physical properties in validation studies. This work establishes a foundation for automated symmetry discovery in representation learning systems.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,6839,Symmetric Space Learning for Combinatorial Generalization,"Symmetries on representations within generative models have shown essential roles in predicting unobserved combinations of semantic changes, known as combinatorial generalization tasks. However, these efforts have primarily focused on learning symmetries from only training data, and thus, the extension of trained symmetries to unseen samples remains uncontrolled. A potential approach for generalizing the symmetries is leveraging geometric information on manifolds that contain functional semantic structures for unseen data, but it still falls short of supporting symmetry learning. In this paper, we address this $\textit{symmetry generalization}$ by forcing $\textit{symmetric space}$ on latent space for utilizing semantic structures from symmetry and manifold perspectives. We clarify an equivariance-based constraint that restricts symmetry generalization, and prove that: 1) enforcing the homogeneous space property of symmetric space onto the data manifold eliminates this constraint, 2) a homogeneous latent manifold induces the data manifold through diffeomorphic data-to-latent mapping, and 3) the isometry property of symmetric space extends neighbor symmetries of a point to another within the space. For practical implementation, we propose a method to align sampled points from symmetric space with their explicitly trained geodesic. We verify the method in a detailed analysis on a toy dataset and enhance combinatorial generalization on common benchmarks. This work represents the first effective effort to align symmetries with manifolds for combinatorial generalization.",ICLR.cc/2025/Conference,4.75,False,0.8672,current approaches equivariant representation learning require explicit knowledge symmetry groups priori limiting their applicability domains our constructs learnable group structure space where candidate symmetry operations are evaluated their effect representation utility experiments across molecular property prediction and robotic manipulation tasks improvements sample efficiency compared fixed symmetry baselines this establishes foundation for automated symmetry discovery representation learning systems,symmetries representations within generative models have shown essential roles predicting unobserved combinations semantic changes known combinatorial generalization tasks however these efforts have primarily focused learning symmetries from only training data and thus the extension trained symmetries unseen samples remains uncontrolled potential for generalizing the symmetries leveraging geometric information manifolds that contain functional semantic structures for unseen data but still falls short supporting symmetry learning this address this textit symmetry generalization forcing textit symmetric space latent space for utilizing semantic structures from symmetry and manifold perspectives,2025-08-26T00:59:30.191855
41,"""Hyperbolic Prototypical Networks for Few-Shot Hierarchical Learning""","Few-shot learning methods often struggle when data exhibits inherent hierarchical structure, as Euclidean embeddings cannot efficiently represent such relationships. We introduce hyperbolic prototypical networks that leverage the exponential representational capacity of hyperbolic spaces for hierarchical few-shot learning. Our approach combines three key innovations: curvature-adaptive prototype computation, hierarchical attention mechanisms, and hyperbolic metric learning objectives. Theoretical analysis demonstrates improved sample complexity bounds for hierarchical classification in hyperbolic space. Empirical evaluation on biological taxonomy and product catalog datasets shows 25-40% accuracy gains over Euclidean counterparts, particularly for deep hierarchical structures. This work bridges geometric deep learning with few-shot paradigms through principled application of hyperbolic geometry.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,3887,Geometry-aware Distance Measure for Diverse Hierarchical Structures in Hyperbolic Spaces,"Learning in hyperbolic spaces has gained increasing attention due to the superior capability of modeling hierarchical structures. Existing hyperbolic learning methods use a fixed distance measure that assumes a uniform hierarchical structure across all data points. However, this assumption does not always hold in real-world scenarios, considering the diversity of the hierarchical structures of data. This work proposes to learn geometry aware distance measures that dynamically adjust to accommodate diverse hierarchical structures in hyperbolic spaces. We derive geometry aware distance measures by generating projections and curvatures for each pair of samples, which maps each pair to a suitable hyperbolic space. We introduce a revised low-rank decomposition scheme and a hard-pair mining mechanism to reduce the computational cost incurred by the pairwise generation without compromising accuracy. Moreover, we derive an upper bound of the low-rank approximation error via Talagrand concentration inequality to guarantee the effectiveness of our low-rank decomposition scheme. Theoretical analysis and experiments on standard image classification and few-shot learning tasks affirm the effectiveness of our method in refining hyperbolic learning through our geometry aware distance measures.",ICLR.cc/2025/Conference,4.75,nan,0.8866,few shot learning methods often struggle when data exhibits inherent hierarchical structure euclidean embeddings cannot represent such relationships hyperbolic prototypical networks that leverage the exponential representational capacity hyperbolic spaces for hierarchical few shot learning our combines three key innovations curvature adaptive prototype computation hierarchical attention mechanisms and hyperbolic learning objectives theoretical analysis demonstrates improved sample complexity bounds for hierarchical classification hyperbolic space empirical evaluation biological taxonomy and product catalog datasets shows gains over euclidean counterparts for deep hierarchical structures this bridges geometric deep learning few shot paradigms principled application hyperbolic geometry,learning hyperbolic spaces has gained increasing attention due the superior capability modeling hierarchical structures existing hyperbolic learning methods use fixed distance measure that assumes uniform hierarchical structure across all data points revised low rank decomposition scheme and hard pair mining mechanism reduce the computational cost incurred the pairwise generation compromising theoretical analysis and experiments standard image classification and few shot learning tasks affirm the effectiveness our refining hyperbolic learning our geometry aware distance measures,2025-08-26T00:59:30.191856
42,"""Contrastive Learning with Differentiable Topological Invariants""","Traditional contrastive learning objectives often ignore the underlying topological structure of data manifolds. We present a framework that integrates persistent homology computations directly into contrastive learning through differentiable topological invariants. Our method introduces novel topological similarity measures that capture both local and global manifold structure, enabling representations that preserve connectivity patterns critical for downstream tasks. Theoretical guarantees establish the stability of our topological features under noise. Experiments on single-cell genomics and medical imaging demonstrate 20-35% improvement in clustering quality metrics compared to standard contrastive approaches. The learned representations reveal interpretable topological features that align with domain knowledge in validation studies.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,8041,GRADIENT-OPTIMIZED CONTRASTIVE LEARNING,"Contrastive learning is a crucial technique in representation learning, producing robust embeddings by distinguishing between similar and dissimilar pairs. In this paper, we introduce a novel framework, Gradient-Optimized Contrastive Learning (GOAL), which enhances network training by optimizing gradient updates during backpropagation as a bilevel optimization problem. Our approach offers three key insights that set it apart from existing methods: (1) Contrastive learning can be seen as an approximation of a one-class support vector machine (OC-SVM) using multiple neural tangent kernels (NTKs) in the network’s parameter space; (2) Hard triplet samples are vital for defining support vectors and outliers in OC-SVMs within NTK spaces, with their difficulty measured using Lagrangian multipliers; (3) Contrastive losses like InfoNCE provide efficient yet dense approximations of sparse Lagrangian multipliers by implicitly leveraging gradients. To address the computational complexity of GOAL, we propose a novel contrastive loss function, Sparse InfoNCE (SINCE), which improves the Lagrangian multiplier approximation by incorporating hard triplet sampling into InfoNCE. Our experimental results demonstrate the effectiveness and efficiency of SINCE in tasks such as image classification and point cloud completion. Demo code is attached in the supplementary file.",ICLR.cc/2025/Conference,5.8,False,0.8405,traditional contrastive learning objectives often ignore the underlying topological structure data manifolds that integrates persistent homology computations directly into contrastive learning differentiable topological invariants experiments single cell genomics and medical imaging improvement clustering quality metrics compared standard contrastive approaches the learned representations reveal interpretable topological features that align domain knowledge validation studies,contrastive learning crucial representation learning producing robust embeddings distinguishing between similar and dissimilar pairs this gradient optimized contrastive learning goal which enhances network training optimizing gradient updates during backpropagation bilevel optimization problem our offers three key insights that set apart from existing methods contrastive learning can seen approximation one class support vector machine svm multiple neural tangent kernels ntks the network parameter space hard triplet samples are vital for defining support vectors and outliers svms within ntk spaces their difficulty measured lagrangian multipliers contrastive losses like infonce provide efficient yet dense approximations sparse lagrangian multipliers implicitly leveraging gradients our experimental the effectiveness and efficiency since tasks such image classification and point cloud completion,2025-08-26T00:59:30.191862
43,"""Dynamic Sparse Coding via Learned Manifold Geometry""","Traditional sparse coding methods employ fixed dictionaries that cannot adapt to non-stationary data distributions. We introduce a dynamic sparse coding framework where dictionary elements evolve according to learned manifold geometry. Our approach combines neural manifold embedding with sparse coding through alternating optimization, enabling local adaptation to data distribution shifts. Theoretical contributions include convergence guarantees under weak distributional assumptions. Applications to video processing and sensor networks demonstrate 30-50% improvements in reconstruction fidelity compared to static methods, while maintaining computational efficiency. The learned manifolds provide interpretable visualizations of non-stationary patterns in evolving datasets.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,19,SCFormer: Spatial Coordination for Efficient and Robust Vision Transformers,"We investigate the design of visual backbones with a focus on optimizing both efficiency and robustness. While recent advancements in hybrid Vision Transformers (ViTs) have significantly enhanced efficiency, achieving state-of-the-art performance with fewer parameters, their robustness against domain-shifted and corrupted inputs remains a critical challenge. This trade-off is particularly difficult to balance in lightweight models, where robustness often relies on wider channels to capture diverse spatial features. In this paper, we present SCFormer, a novel hybrid ViT architecture designed to address these limitations. SCFormer introduces Spatial Coordination Attention (SCA), a mechanism that coordinates cross-spatial pixel interactions by deconstructing and reassembling spatial conditions with diverse connectivity patterns. This approach broadens the representation boundary, allowing SCFormer to efficiently capture more diverse spatial dependencies even with fewer channels, thereby improving robustness without sacrificing efficiency. Additionally, we incorporate an Inceptional Local Representation (ILR) block to flexibly enrich local token representations before self-attention, enhancing both locality and feature diversity. Through extensive experiments, SCFormer demonstrates superior performance across multiple benchmarks. On ImageNet-1K, SCFormer-XS achieves 2.5\% higher top-1 accuracy and 10\% faster GPU inference speed compared to FastViT-T8. On ImageNet-A, SCFormer-L (30.1M) surpasses RVT-B (91.8M) in robustness accuracy by 5.6\% while using 3$\times$ fewer parameters. These results underscore the effectiveness of our design in achieving a new state-of-the-art balance between efficiency and robustness.",ICLR.cc/2025/Conference,4.4,nan,0.8260,our combines neural manifold embedding sparse coding alternating optimization enabling local adaptation data distribution shifts applications video processing and sensor networks improvements reconstruction fidelity compared static methods while maintaining computational efficiency,the visual backbones focus optimizing both efficiency and robustness while recent advancements hybrid vision transformers vits have enhanced efficiency achieving state the art fewer parameters their robustness against domain shifted and corrupted inputs remains critical challenge this trade off difficult balance lightweight models where robustness often relies wider channels capture diverse spatial features scformer introduces spatial coordination attention sca mechanism that coordinates cross spatial pixel interactions deconstructing and reassembling spatial conditions diverse connectivity patterns this broadens the representation boundary allowing scformer capture more diverse spatial dependencies even fewer channels thereby improving robustness sacrificing efficiency additionally incorporate inceptional local representation ilr block flexibly enrich local token representations before self attention enhancing both locality and feature diversity imagenet scformer surpasses rvt robustness while times fewer parameters these underscore the effectiveness our achieving state the art balance between efficiency and robustness,2025-08-26T00:59:30.191865
44,"""Temporal Disentanglement via Neural Ordinary Differential Operators""","Disentangling temporal factors in sequential data remains challenging due to complex inter-dependencies across timescales. We propose a framework based on neural ordinary differential operators that explicitly model factor-specific temporal dynamics. Our architecture employs independent ODE systems with learned stiffness parameters to separate factors by their characteristic timescales. Theoretical analysis shows identifiable disentanglement under mild assumptions about temporal separability. Evaluation on physiological signals and robotics state estimation demonstrates superior factor separation (35-50% improvement) while maintaining predictive accuracy. The learned temporal factors align well with known physiological processes in validation studies, suggesting applications in interpretable time-series modeling.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,3827,Global Convergence in Neural ODEs: Impact of Activation Functions,"Neural Ordinary Differential Equations (ODEs) have been successful in various applications due to their continuous nature and parameter-sharing efficiency. However, these unique characteristics also introduce challenges in training, particularly with respect to gradient computation accuracy and convergence analysis. In this paper, we address these challenges by investigating the impact of activation functions. We demonstrate that the properties of activation functions—specifically smoothness and nonlinearity—are critical to the training dynamics. Smooth activation functions guarantee globally unique solutions for both forward and backward ODEs, while sufficient nonlinearity is essential for maintaining the spectral properties of the Neural Tangent Kernel (NTK) during training. Together, these properties enable us to establish the global convergence of Neural ODEs under gradient descent in overparameterized regimes. Our theoretical findings are validated by numerical experiments, which not only support our analysis but also provide practical guidelines for scaling Neural ODEs, potentially leading to faster training and improved performance in real-world applications.",ICLR.cc/2025/Conference,8.0,True,0.8063,neural ordinary differential operators that explicitly factor specific temporal dynamics,neural ordinary differential equations odes have been successful various applications due their continuous nature and parameter sharing efficiency smooth activation functions guarantee globally unique solutions for both forward and backward odes while sufficient nonlinearity essential for maintaining the spectral properties the neural tangent kernel ntk during training together these properties enable establish the global convergence neural odes under gradient descent overparameterized regimes our theoretical are validated numerical experiments which not only support our analysis but also provide practical guidelines for scaling neural odes potentially leading faster training and improved real world applications,2025-08-26T00:59:30.191870
45,"""Geometric Self-Supervised Learning via Neural Riemannian Geometry""","Traditional self-supervised methods often ignore the intrinsic geometric structure of data manifolds. We develop a framework that learns representations respecting the underlying Riemannian geometry through neural estimation of metric tensors. Our approach introduces differentiable exponential and logarithmic map operations that enable geometrically consistent transformations of learned representations. Theoretical contributions include stability guarantees for neural metric learning and curvature regularization schemes. Applications to molecular property prediction and robotics state estimation demonstrate 20-40% improvements in sample efficiency compared to Euclidean approaches. The learned geometric structure enables meaningful interpolation and extrapolation in representation space, with applications in simulation and data augmentation.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,5052,Score-based pullback Riemannian geometry,"Data-driven Riemannian geometry has emerged as a powerful tool for interpretable representation learning, offering improved efficiency in downstream tasks. Moving forward, it is crucial to balance cheap manifold mappings with efficient training algorithms. In this work, we integrate concepts from pullback Riemannian geometry and generative models to propose a framework for data-driven Riemannian geometry that is scalable in both geometry and learning: score-based pullback Riemannian geometry. Focusing on unimodal distributions as a first step, we propose a score-based Riemannian structure with closed-form geodesics that pass through the data probability density. With this structure, we construct a Riemannian autoencoder (RAE) with error bounds for discovering the correct data manifold dimension. This framework can naturally be used with anisotropic normalizing flows by adopting isometry regularization during training. Through numerical experiments on various datasets, we demonstrate that our framework not only produces high-quality geodesics through the data support, but also reliably estimates the intrinsic dimension of the data manifold and provides a global chart of the manifold, even in high-dimensional ambient spaces.",ICLR.cc/2025/Conference,5.25,False,0.8634,that learns representations respecting the underlying riemannian geometry neural estimation tensors theoretical contributions include stability guarantees for neural learning and curvature regularization schemes applications molecular property prediction and robotics state estimation improvements sample efficiency compared euclidean approaches the learned geometric structure enables meaningful interpolation and extrapolation representation space applications simulation and data augmentation,data driven riemannian geometry has emerged powerful tool for interpretable representation learning offering improved efficiency downstream tasks,2025-08-26T00:59:30.191874
46,"""Causal Representation Transfer via Intervention Matching""","Domain adaptation methods often fail when domains differ due to underlying causal interventions. We present a framework that learns transferable representations by matching intervention distributions across domains. Our approach combines causal discovery with adversarial representation learning, enforcing invariance to identified interventions while preserving causal structure. Theoretical analysis establishes identifiability conditions for causal representations under intervention matching. Empirical evaluation on medical imaging and climate modeling tasks shows 30-50% improvement in cross-domain generalization compared to existing methods. The approach requires no domain labels during training, instead leveraging implicit intervention information from data structure.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,1523,Taming Continuous Spurious Shift in Domain Adaptation,"Recent advances in domain adaptation have shown promise in transferring knowledge across domains characterized by a continuous value or vector, such as varying patient ages, where ""age'' serves as a continuous index. However, these approaches often fail when spurious features shift continuously along with the domain index. This paper introduces the first method designed to withstand the continuous shifting of spurious features during domain adaptation. Our method enhances domain adaptation performance by aligning causally transportable encodings across continuously indexed domains. Theoretical analysis demonstrates that our approach more effectively ensures causal transportability across different domains. Empirical results, from both semi-synthetic and real-world medical datasets, indicate that our method outperforms state-of-the-art domain adaptation methods.",ICLR.cc/2025/Conference,3.75,nan,0.8200,domain adaptation methods often fail when domains differ due underlying causal interventions our combines causal discovery adversarial representation learning enforcing invariance identified interventions while preserving causal structure the requires domain labels during training instead leveraging implicit intervention information from data structure,recent advances domain adaptation have shown promise transferring knowledge across domains characterized continuous value vector such varying patient ages where age serves continuous index however these approaches often fail when spurious features shift continuously along the domain index this introduces the first designed withstand the continuous shifting spurious features during domain adaptation our enhances domain adaptation aligning causally transportable encodings across continuously indexed domains empirical from both semi synthetic and real world medical datasets indicate that our outperforms state the art domain adaptation methods,2025-08-26T00:59:30.191878
47,"""Neural Differential Forms for Robust Representation Learning""","Traditional representation learning methods often fail to capture invariant features across data deformations. We propose a framework based on neural differential forms that learn deformation-invariant features through integration against learned differential operators. Our approach combines concepts from differential geometry with deep learning, constructing representation spaces where integrals along paths remain invariant under learned equivalence classes of deformations. Theoretical contributions include stability analysis for neural differential operators and invariance guarantees. Applications in medical imaging and computational physics demonstrate superior robustness to known deformations (40-60% improvements in invariant recognition). The framework suggests new connections between geometric analysis and deep learning for constructing provably robust representations.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,4452,ToRL: Topology-preserving Representation Learning Of Object Deformations From Images,"Representation learning of object deformations from images has been a long-standing challenge in various image or video analysis tasks. Existing deep neural networks typically focus on visual features (e.g., intensity and texture), but they often fail to capture the underlying geometric and topological structures of objects. This limitation becomes especially critical in areas, such as medical imaging and 3D modeling, where maintaining the structural integrity of objects is essential for accuracy and generalization across diverse datasets. In this paper, we introduce ToRL, a novel *Topology-preserving Representation Learning* model that, for the first time, offers an explicit mechanism for modeling intricate object topology in the latent feature space. We develop a comprehensive learning framework that captures object deformations via learned transformation groups in the latent space. Each layer of our network's decoder is carefully designed with an integrated smooth composition module, ensuring that topological properties are preserved throughout the learning process. Moreover, in contrast to a few related works that rely on a reference image to predict object deformations during inference, our approach eliminates this impractical requirement. To validate ToRL's effectiveness, we conduct extensive multi-class classification experiments across a wide range of datasets, including synthetic 2D images, real 3D brain magnetic resonance imaging (MRI) scans, real 3D adrenal computed tomography (CT) shapes, and \textcolor{blue}{real 2D facial expression images}. Experimental results demonstrate that ToRL outperforms state-of-the-art methods, setting a new way to enforce topological consistency in representation learning. Our code is available at - https://anonymous.4open.science/r/ToRL-44BF/",ICLR.cc/2025/Conference,5.5,False,0.8385,traditional representation learning methods often fail capture invariant features across data deformations neural differential forms that learn deformation invariant features integration against learned differential operators our combines concepts from differential geometry deep learning constructing representation spaces where integrals along paths remain invariant under learned equivalence classes deformations theoretical contributions include stability analysis for neural differential operators and invariance guarantees applications medical imaging and computational physics superior robustness known deformations improvements invariant recognition the suggests connections between geometric analysis and deep learning for constructing provably robust representations,representation learning object deformations from images has been long standing challenge various image video analysis tasks existing deep neural networks focus visual features this torl topology preserving representation learning that for the first time offers explicit mechanism for modeling intricate object topology the latent feature space comprehensive learning that captures object deformations learned transformation groups the latent space each layer our network decoder carefully designed integrated smooth composition module ensuring that topological properties are preserved throughout the learning process torl effectiveness conduct extensive multi class classification experiments across wide range datasets including synthetic images real brain magnetic resonance imaging mri scans real adrenal computed tomography shapes and textcolor blue real facial expression images experimental that torl outperforms state the art methods setting way enforce topological consistency representation learning,2025-08-26T00:59:30.191885
48,"*""Latent Causal Mechanisms for Robust Representation Learning""*","Current representation learning approaches often rely on spurious correlations that fail under distribution shifts. We introduce a framework for learning representations that explicitly disentangle latent causal mechanisms through adversarial intervention training. Our method combines variational inference with targeted counterfactual generation to isolate stable causal features from spurious patterns. Theoretical analysis shows our approach recovers identifiable causal factors under relaxed conditions compared to existing disentanglement methods. Experiments on medical imaging and autonomous driving benchmarks demonstrate 25-40% higher robustness to distribution shifts compared to invariance-based approaches. Notably, our model generates interpretable counterfactual explanations while maintaining state-of-the-art predictive performance. This work bridges causal inference with deep representation learning, providing a practical path toward trustworthy AI systems.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,6476,Turning Challenges into Opportunities: How Distribution Shifts Enhance Identifiability in Causal Representation Learning,"Causal representation learning seeks to uncover latent causal variables and their relationships from observed, unstructured data, a task complicated by identifiability challenges. While distribution shifts, viewed as natural interventions on latent causal variables, often present difficulties in traditional machine learning tasks, they also create valuable opportunities for identifiability by introducing variability in latent variables. In this paper, we study a non-parametric condition characterizing the types of distribution shifts that contribute to identifiability within the context of latent additive noise models. We also present partial identifiability results when only a portion of distribution shifts meets the condition. Furthermore, we extend our findings to latent post-nonlinear causal models. Building on our theoretical results, we propose a practical algorithm facilitating the acquisition of reliable latent causal representations. Our algorithm, guided by our underlying theory, has demonstrated outstanding performance across a diverse range of synthetic and real-world datasets. The empirical observations closely align with the theoretical findings, affirming the robustness and effectiveness of our proposed approach.",ICLR.cc/2025/Conference,5.25,False,0.8845,current representation learning approaches often rely spurious correlations that fail under distribution shifts for learning representations that explicitly disentangle latent causal mechanisms adversarial intervention training our combines variational inference targeted counterfactual generation isolate stable causal features from spurious patterns experiments medical imaging and autonomous driving benchmarks higher robustness distribution shifts compared invariance based approaches this bridges causal inference deep representation learning providing practical path toward trustworthy systems,causal representation learning seeks uncover latent causal variables and their relationships from observed unstructured data task complicated identifiability challenges while distribution shifts viewed natural interventions latent causal variables often difficulties traditional machine learning tasks they also create valuable opportunities for identifiability introducing variability latent variables the empirical observations closely align the theoretical affirming the robustness and effectiveness our proposed,2025-08-26T00:59:30.191886
49,"*""Topological Contrastive Learning on Manifolds""*","Traditional contrastive learning treats data as discrete points, ignoring underlying manifold structure. We present a topological contrastive framework that preserves essential connectivity patterns through persistent homology regularization. Our approach constructs a Vietoris-Rips complex on embeddings and optimizes for topological similarity between augmented views. The key innovation is a differentiable topological loss that operates directly in high-dimensional space. Theoretical guarantees ensure preservation of manifold structure under projection. Experiments on single-cell RNA sequencing and 3D shape analysis show 15-30% improvement in clustering metrics and robustness to noise. The method naturally captures hierarchical relationships in data without explicit supervision, suggesting applications in scientific discovery.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,1370,Preventing Collapse in Contrastive Learning with Orthonormal Prototypes (CLOP),"Contrastive learning has emerged as a powerful method in deep learning, excelling at learning effective representations through contrasting samples from different distributions. However, dimensional collapse, where embeddings converge into a lower-dimensional space, poses a significant challenge, especially in semi-supervised and self-supervised setups. In this paper, we first theoretically analyze the effect of large learning rates on contrastive losses that solely rely on the cosine similarity metric, and derive a theoretical bound to mitigate this collapse. Building on these insights, we propose CLOP, a novel semi-supervised loss function designed to prevent dimensional collapse by promoting the formation of orthogonal linear subspaces among class embeddings. Unlike prior approaches that enforce a simplex ETF structure, CLOP focuses on subspace separation, leading to more distinguishable embeddings. Through extensive experiments on real and synthetic datasets, we demonstrate that CLOP enhances performance, providing greater stability across different learning rates and batch sizes.",ICLR.cc/2025/Conference,5.0,False,0.8232,traditional contrastive learning treats data discrete points ignoring underlying manifold structure experiments single cell rna sequencing and shape analysis improvement clustering metrics and robustness noise,contrastive learning has emerged powerful deep learning excelling learning effective representations contrasting samples from different distributions this first theoretically the effect large learning rates contrastive losses that solely rely the cosine similarity and derive theoretical bound mitigate this collapse extensive experiments real and synthetic datasets that clop enhances providing greater stability across different learning rates and batch sizes,2025-08-26T00:59:30.191890
50,"*""Hyperbolic Prototypical Networks with Learnable Curvature""*","Hierarchical few-shot learning requires flexible geometric representations that standard Euclidean spaces cannot provide. We develop hyperbolic prototypical networks with dynamic curvature adaptation, where both embeddings and space geometry are learned end-to-end. Our architecture employs a novel curvature attention mechanism that adapts local geometry to data density while maintaining global hierarchical structure. Mathematical analysis shows improved separation bounds for few-shot classification in learned hyperbolic spaces. Empirical evaluation on biological taxonomies and product hierarchies demonstrates 20-35% accuracy gains over fixed-curvature approaches. The learned hyperbolic embeddings provide interpretable visualizations of hierarchical relationships at multiple scales.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,3887,Geometry-aware Distance Measure for Diverse Hierarchical Structures in Hyperbolic Spaces,"Learning in hyperbolic spaces has gained increasing attention due to the superior capability of modeling hierarchical structures. Existing hyperbolic learning methods use a fixed distance measure that assumes a uniform hierarchical structure across all data points. However, this assumption does not always hold in real-world scenarios, considering the diversity of the hierarchical structures of data. This work proposes to learn geometry aware distance measures that dynamically adjust to accommodate diverse hierarchical structures in hyperbolic spaces. We derive geometry aware distance measures by generating projections and curvatures for each pair of samples, which maps each pair to a suitable hyperbolic space. We introduce a revised low-rank decomposition scheme and a hard-pair mining mechanism to reduce the computational cost incurred by the pairwise generation without compromising accuracy. Moreover, we derive an upper bound of the low-rank approximation error via Talagrand concentration inequality to guarantee the effectiveness of our low-rank decomposition scheme. Theoretical analysis and experiments on standard image classification and few-shot learning tasks affirm the effectiveness of our method in refining hyperbolic learning through our geometry aware distance measures.",ICLR.cc/2025/Conference,4.75,nan,0.8784,hierarchical few shot learning requires flexible geometric representations that standard euclidean spaces cannot provide our employs curvature attention mechanism that adapts local geometry data density while maintaining global hierarchical structure mathematical analysis shows improved separation bounds for few shot classification learned hyperbolic spaces,learning hyperbolic spaces has gained increasing attention due the superior capability modeling hierarchical structures existing hyperbolic learning methods use fixed distance measure that assumes uniform hierarchical structure across all data points revised low rank decomposition scheme and hard pair mining mechanism reduce the computational cost incurred the pairwise generation compromising theoretical analysis and experiments standard image classification and few shot learning tasks affirm the effectiveness our refining hyperbolic learning our geometry aware distance measures,2025-08-26T00:59:30.191892
51,"*""Neural Differential Forms for Equivariant Representation Learning""*","Traditional equivariant networks require explicit symmetry specifications, limiting their applicability. We propose learning representations through neural differential forms - learnable operators that automatically capture data symmetries via their transformation properties. Our framework combines exterior calculus with deep learning to construct provably equivariant architectures without group representations. Theoretical contributions include universality proofs and stability analysis under symmetry perturbations. Applications in computational physics and robotics show superior generalization to novel symmetries (30-50% improvements) compared to traditional equivariant networks. The approach successfully discovers known physical symmetries in validation studies while remaining computationally efficient.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,10955,Discovering Group Structures via Unitary Representation Learning,"Discovering group structures within data poses a fundamental challenge across diverse scientific domains. A key obstacle is the non-differentiable nature of group axioms, hindering their integration into deep learning frameworks. To address this, we introduce a novel differentiable approach leveraging the representation theory of finite groups. Our method features a unique network architecture that models interactions between group elements via matrix multiplication of their representations, along with a regularizer promoting the unitarity of these representations. The interplay between the network architecture and the unitarity condition implicitly encourages the emergence of valid group structures. Evaluations demonstrate our method's ability to accurately recover group operations and their unitary representations from partial observations, achieving significant improvements in sample efficiency and a $\times 1000$ speedup over the state of the art. This work lays the foundation for a promising new paradigm in automated algebraic structure discovery, with potential applications across various domains, including automatic symmetry discovery for geometric deep learning.",ICLR.cc/2025/Conference,5.666666666666667,True,0.8426,learning representations neural differential forms learnable operators that automatically capture data symmetries their transformation properties our combines exterior calculus deep learning construct provably equivariant architectures group representations,key obstacle the non differentiable nature group axioms hindering their integration into deep learning frameworks address this differentiable leveraging the representation theory finite groups our features unique network that models interactions between group elements matrix multiplication their representations along regularizer promoting the unitarity these representations the interplay between the network and the unitarity condition implicitly encourages the emergence valid group structures this lays the foundation for promising paradigm automated algebraic structure discovery potential applications across various domains including automatic symmetry discovery for geometric deep learning,2025-08-26T00:59:30.191899
52,"*""Temporal Disentanglement via Latent Process Separation""*","Sequential data often contains interacting processes operating at different timescales, posing challenges for representation learning. We introduce a temporal disentanglement framework using coupled neural ODE systems with process-specific stiffness parameters. Our method separates latent factors by their characteristic dynamics through a novel spectral mixing penalty. Theoretical analysis establishes identifiability conditions under mild assumptions about temporal separability. Experiments on physiological monitoring and financial forecasting demonstrate superior factor separation (40% improvement in factor purity scores) compared to variational approaches. The learned dynamical models enable accurate long-term prediction and interpretable analysis of interacting processes.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,59,Neural ODE with Differentiable Hidden State for Irregular Time Series,"Capturing the continuous underlying dynamics of irregular time series is essential for accurately reflecting the ongoing evolution and intricate correlations within the data. The discrete nature of current models, including RNN-based models and transformer variants, poses challenges when it comes to generalizing to the continuous-time data paradigms, which is necessary for capturing ongoing dynamics of irregular time series. 
Neural Ordinary Differential Equations (NODEs) assume a continuous latent dynamic and provide an elegant framework for irregular time series analysis. However, integrating new information while maintaining the continuity of latent dynamics remains challenging. 
To tackle this problem, we introduce Differentiable Hidden State (DHS) enhanced neural ODE, a data-dependent framework that is capable of effectively capturing temporal dependencies and ensuring the continuity of the hidden process. We leverage the theory of generalized inverses to innovatively compute attention mechanism in reverse and obtain a continuous representation. To capture more accurate temporal relationships, we introduce Hoyer metric and maximize the sparsity of it. Experimental results on both synthetic and real-world datasets demonstrate the effectiveness of our model.",ICLR.cc/2025/Conference,2.0,nan,0.8527,sequential data often contains interacting processes operating different timescales posing challenges for representation learning temporal disentanglement coupled neural ode systems process specific stiffness parameters the learned dynamical models enable accurate long term prediction and interpretable analysis interacting processes,the discrete nature current models including rnn based models and transformer variants poses challenges when comes generalizing the continuous time data paradigms which necessary for capturing ongoing dynamics irregular time series neural ordinary differential equations nodes assume continuous latent dynamic and provide elegant for irregular time series analysis tackle this problem differentiable hidden state dhs enhanced neural ode data dependent that capable capturing temporal dependencies and ensuring the continuity the hidden process leverage the theory generalized inverses innovatively compute attention mechanism reverse and obtain continuous representation,2025-08-26T00:59:30.191902
53,"*""Geometric Self-Supervised Learning with Neural Riemannian Metrics""*",Standard self-supervised methods often ignore the intrinsic geometry of data manifolds. We develop a framework that learns Riemannian metric tensors directly from unlabeled data through neural estimation of geodesic distances. Our approach introduces two key innovations: differentiable exponential map layers and curvature-regularized contrastive objectives. Theoretical contributions include convergence guarantees for metric learning and stability bounds under noise. Applications in molecular property prediction and robotic manipulation demonstrate 25-40% improvements in sample efficiency compared to Euclidean approaches. The learned geometric structure enables accurate interpolation and novel sample generation while respecting physical constraints.,ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,5052,Score-based pullback Riemannian geometry,"Data-driven Riemannian geometry has emerged as a powerful tool for interpretable representation learning, offering improved efficiency in downstream tasks. Moving forward, it is crucial to balance cheap manifold mappings with efficient training algorithms. In this work, we integrate concepts from pullback Riemannian geometry and generative models to propose a framework for data-driven Riemannian geometry that is scalable in both geometry and learning: score-based pullback Riemannian geometry. Focusing on unimodal distributions as a first step, we propose a score-based Riemannian structure with closed-form geodesics that pass through the data probability density. With this structure, we construct a Riemannian autoencoder (RAE) with error bounds for discovering the correct data manifold dimension. This framework can naturally be used with anisotropic normalizing flows by adopting isometry regularization during training. Through numerical experiments on various datasets, we demonstrate that our framework not only produces high-quality geodesics through the data support, but also reliably estimates the intrinsic dimension of the data manifold and provides a global chart of the manifold, even in high-dimensional ambient spaces.",ICLR.cc/2025/Conference,5.25,False,0.8557,that learns riemannian tensors directly from unlabeled data neural estimation geodesic distances theoretical contributions include convergence guarantees for learning and stability bounds under noise applications molecular property prediction and robotic manipulation improvements sample efficiency compared euclidean approaches the learned geometric structure enables accurate interpolation and sample generation while respecting physical constraints,data driven riemannian geometry has emerged powerful tool for interpretable representation learning offering improved efficiency downstream tasks,2025-08-26T00:59:30.191903
54,"*""Sparse Neural Coding with Bayesian Variational Sparsity""*","Current sparse coding methods rely on fixed sparsity budgets that may not match data complexity. We propose Bayesian variational sparse coding, where both representation sparsity and dictionary structure are learned probabilistically. Our framework employs hierarchical spike-and-slab priors with learned conditional dependencies among dictionary elements. Theoretical analysis shows improved approximation properties compared to traditional sparse coding approaches. Experiments on image processing and neuroscientific data demonstrate 30-50% reductions in reconstruction error with comparable sparsity levels. The method automatically adapts to varying complexity across different input regions while maintaining interpretable feature representations.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,2131,Efficient Bayesian DNN Compression through Sparse Quantized Sub-distributions,"This paper presents a novel method that simultaneously achieves model pruning and low-bit quantization through Bayesian variational inference to effectively compress deep neural networks (DNNs) while suffering minimal performance degradation. 
Unlike previous approaches that treat pruning and quantization as separate, sequential tasks, our method explores a unified optimization space, enabling more efficient compression. 
By leveraging a spike-and-slab prior combined with Gaussian Mixture Models (GMM), we can achieve both network sparsity and low-bit representation. Experiments on CIFAR-10, CIFAR-100, and SQuAD datasets demonstrate that our approach achieves compression rates of up to 32x with less than a $1.3\\%$ accuracy loss on the CIFAR datasets and a 1.66 point decrease in F1 score on SQuAD. Additionally, we show that the Bayesian model average of neural networks can further mitigate the impact of quantization noise, leading to more robust compressed models. Our method outperforms existing techniques in both compression efficiency and accuracy retention, offering a promising solution for compressing DNNs.",ICLR.cc/2025/Conference,5.75,False,0.8061,bayesian variational sparse coding where both representation sparsity and dictionary structure are learned probabilistically experiments image processing and neuroscientific data reductions reconstruction error comparable sparsity levels the automatically adapts varying complexity across different input regions while maintaining interpretable feature representations,this presents that simultaneously achieves pruning and low bit quantization bayesian variational inference compress deep neural networks dnns while suffering minimal degradation unlike previous approaches that treat pruning and quantization separate sequential tasks our explores unified optimization space enabling more efficient compression leveraging spike and slab prior combined gaussian mixture models gmm can achieve both network sparsity and low bit representation additionally that the bayesian average neural networks can further mitigate the impact quantization noise leading more robust compressed models,2025-08-26T00:59:30.191906
55,"*""Contrastive Learning with Dynamical System Embeddings""*","Traditional contrastive learning treats samples individually, ignoring dynamical relationships in sequential data. We present a framework that learns embeddings of dynamical systems directly from time series observations. Our method combines contrastive learning with neural system identification to construct vector fields in latent space while preserving topological invariants. Key innovations include trajectory-sensitive augmentation and stability-preserving regularizers. Applications to sensor networks and robotics demonstrate 25-35% improvements in long-term prediction and anomaly detection compared to standard approaches. The framework enables novel capabilities including controlled system interpolation and stability analysis directly from learned embeddings.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,8041,GRADIENT-OPTIMIZED CONTRASTIVE LEARNING,"Contrastive learning is a crucial technique in representation learning, producing robust embeddings by distinguishing between similar and dissimilar pairs. In this paper, we introduce a novel framework, Gradient-Optimized Contrastive Learning (GOAL), which enhances network training by optimizing gradient updates during backpropagation as a bilevel optimization problem. Our approach offers three key insights that set it apart from existing methods: (1) Contrastive learning can be seen as an approximation of a one-class support vector machine (OC-SVM) using multiple neural tangent kernels (NTKs) in the network’s parameter space; (2) Hard triplet samples are vital for defining support vectors and outliers in OC-SVMs within NTK spaces, with their difficulty measured using Lagrangian multipliers; (3) Contrastive losses like InfoNCE provide efficient yet dense approximations of sparse Lagrangian multipliers by implicitly leveraging gradients. To address the computational complexity of GOAL, we propose a novel contrastive loss function, Sparse InfoNCE (SINCE), which improves the Lagrangian multiplier approximation by incorporating hard triplet sampling into InfoNCE. Our experimental results demonstrate the effectiveness and efficiency of SINCE in tasks such as image classification and point cloud completion. Demo code is attached in the supplementary file.",ICLR.cc/2025/Conference,5.8,False,0.8612,traditional contrastive learning treats samples individually ignoring dynamical relationships sequential data our combines contrastive learning neural identification construct vector fields latent space while preserving topological invariants applications sensor networks and robotics improvements long term prediction and anomaly detection compared standard approaches,contrastive learning crucial representation learning producing robust embeddings distinguishing between similar and dissimilar pairs this gradient optimized contrastive learning goal which enhances network training optimizing gradient updates during backpropagation bilevel optimization problem our offers three key insights that set apart from existing methods contrastive learning can seen approximation one class support vector machine svm multiple neural tangent kernels ntks the network parameter space hard triplet samples are vital for defining support vectors and outliers svms within ntk spaces their difficulty measured lagrangian multipliers contrastive losses like infonce provide efficient yet dense approximations sparse lagrangian multipliers implicitly leveraging gradients our experimental the effectiveness and efficiency since tasks such image classification and point cloud completion,2025-08-26T00:59:30.191908
56,"*""Differentiable Causal Discovery for Robust Representation Learning""*","Modern representation learning often relies on correlations rather than causal relationships, leading to brittle models. We propose a novel framework that integrates differentiable causal discovery with representation learning to identify stable causal features. Our approach jointly learns a causal graph and corresponding representations through an end-to-end variational objective that maximizes interventional stability. Theoretical analysis shows our method recovers identifiable causal factors under more relaxed conditions than existing disentanglement approaches. Experiments on medical imaging and autonomous driving benchmarks demonstrate 25-40% higher robustness to distribution shifts compared to invariance-based methods. The learned causal graph provides interpretable insights into feature relationships while maintaining state-of-the-art predictive performance. This work bridges causal inference with deep representation learning, offering a practical path toward trustworthy AI systems.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,6796,Unifying Causal Representation Learning with the Invariance Principle,"Causal representation learning (CRL) aims at recovering latent causal variables from high-dimensional observations to solve causal downstream tasks, such as predicting the effect of new interventions or more robust classification. 
  A plethora of methods have been developed, each tackling carefully crafted problem settings that lead to different types of identifiability. 
  These different settings are widely assumed to be important because they are often linked to different rungs of Pearl's causal hierarchy, even though this correspondence is not always exact.
    This work shows that instead of strictly conforming to this hierarchical mapping, *many causal representation learning approaches methodologically align their representations with inherent data symmetries.*
  Identification of causal variables is guided by invariance principles that are not necessarily causal. 
  This result allows us to unify many existing approaches in a single method that can mix and match different assumptions, including non-causal ones, based on the invariance relevant to the problem at hand. 
  It also significantly benefits applicability, which we demonstrate by improving treatment effect estimation on real-world high-dimensional ecological data. Overall, this paper clarifies the role of causal assumptions in the discovery of causal variables and shifts the focus to preserving data symmetries.",ICLR.cc/2025/Conference,7.0,True,0.8815,modern representation learning often relies correlations rather than causal relationships leading brittle models that integrates differentiable causal discovery representation learning identify stable causal features experiments medical imaging and autonomous driving benchmarks higher robustness distribution shifts compared invariance based methods the learned causal graph provides interpretable insights into feature relationships while maintaining state the art predictive this bridges causal inference deep representation learning offering practical path toward trustworthy systems,causal representation learning crl aims recovering latent causal variables from high dimensional observations solve causal downstream tasks such predicting the effect interventions more robust classification this shows that instead strictly conforming this hierarchical mapping many causal representation learning approaches methodologically align their representations inherent data symmetries,2025-08-26T00:59:30.191909
57,"*""Topological Self-Supervised Learning via Persistent Homology Contrast""*","Contrastive learning typically operates on point-wise embeddings, ignoring the underlying topological structure of data. We introduce a topological contrastive framework that preserves essential connectivity patterns through persistent homology regularization. Our method constructs a Vietoris-Rips complex on the embedding space and optimizes for topological similarity between augmented views using a novel differentiable topological loss. Theoretical guarantees ensure preservation of manifold structure under projection while maintaining computational tractability. Evaluation on single-cell RNA sequencing and material science datasets shows 20-35% improvement in clustering metrics and robustness to noise compared to standard approaches. The framework automatically captures hierarchical relationships without explicit supervision, demonstrating strong performance on scientific discovery tasks.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,8041,GRADIENT-OPTIMIZED CONTRASTIVE LEARNING,"Contrastive learning is a crucial technique in representation learning, producing robust embeddings by distinguishing between similar and dissimilar pairs. In this paper, we introduce a novel framework, Gradient-Optimized Contrastive Learning (GOAL), which enhances network training by optimizing gradient updates during backpropagation as a bilevel optimization problem. Our approach offers three key insights that set it apart from existing methods: (1) Contrastive learning can be seen as an approximation of a one-class support vector machine (OC-SVM) using multiple neural tangent kernels (NTKs) in the network’s parameter space; (2) Hard triplet samples are vital for defining support vectors and outliers in OC-SVMs within NTK spaces, with their difficulty measured using Lagrangian multipliers; (3) Contrastive losses like InfoNCE provide efficient yet dense approximations of sparse Lagrangian multipliers by implicitly leveraging gradients. To address the computational complexity of GOAL, we propose a novel contrastive loss function, Sparse InfoNCE (SINCE), which improves the Lagrangian multiplier approximation by incorporating hard triplet sampling into InfoNCE. Our experimental results demonstrate the effectiveness and efficiency of SINCE in tasks such as image classification and point cloud completion. Demo code is attached in the supplementary file.",ICLR.cc/2025/Conference,5.8,False,0.8601,contrastive learning operates point wise embeddings ignoring the underlying topological structure data our constructs vietoris rips complex the embedding space and optimizes for topological similarity between augmented views differentiable topological loss evaluation single cell rna sequencing and material science datasets shows improvement clustering metrics and robustness noise compared standard approaches,contrastive learning crucial representation learning producing robust embeddings distinguishing between similar and dissimilar pairs this gradient optimized contrastive learning goal which enhances network training optimizing gradient updates during backpropagation bilevel optimization problem our offers three key insights that set apart from existing methods contrastive learning can seen approximation one class support vector machine svm multiple neural tangent kernels ntks the network parameter space hard triplet samples are vital for defining support vectors and outliers svms within ntk spaces their difficulty measured lagrangian multipliers contrastive losses like infonce provide efficient yet dense approximations sparse lagrangian multipliers implicitly leveraging gradients our experimental the effectiveness and efficiency since tasks such image classification and point cloud completion,2025-08-26T00:59:30.191911
58,"*""Dynamic-Curvature Hyperbolic Networks for Hierarchical Learning""*","Fixed-curvature hyperbolic embeddings cannot adapt to varying hierarchical density in real-world data. We propose hyperbolic neural networks with learnable local curvature, where both embeddings and space geometry adapt to data structure. Our architecture features curvature attention mechanisms that dynamically adjust metric tensors while maintaining global consistency. Mathematical analysis demonstrates improved separation bounds for hierarchical classification in learned hyperbolic spaces. Extensive experiments on biological taxonomies and e-commerce hierarchies show 25-45% accuracy gains over fixed-curvature approaches. The dynamic curvature formulation provides new insights into learned geometric representations while enabling interpretable visualization of complex hierarchies.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,3887,Geometry-aware Distance Measure for Diverse Hierarchical Structures in Hyperbolic Spaces,"Learning in hyperbolic spaces has gained increasing attention due to the superior capability of modeling hierarchical structures. Existing hyperbolic learning methods use a fixed distance measure that assumes a uniform hierarchical structure across all data points. However, this assumption does not always hold in real-world scenarios, considering the diversity of the hierarchical structures of data. This work proposes to learn geometry aware distance measures that dynamically adjust to accommodate diverse hierarchical structures in hyperbolic spaces. We derive geometry aware distance measures by generating projections and curvatures for each pair of samples, which maps each pair to a suitable hyperbolic space. We introduce a revised low-rank decomposition scheme and a hard-pair mining mechanism to reduce the computational cost incurred by the pairwise generation without compromising accuracy. Moreover, we derive an upper bound of the low-rank approximation error via Talagrand concentration inequality to guarantee the effectiveness of our low-rank decomposition scheme. Theoretical analysis and experiments on standard image classification and few-shot learning tasks affirm the effectiveness of our method in refining hyperbolic learning through our geometry aware distance measures.",ICLR.cc/2025/Conference,4.75,nan,0.8805,hyperbolic neural networks learnable local curvature where both embeddings and space geometry adapt data structure our features curvature attention mechanisms that dynamically adjust tensors while maintaining global consistency mathematical analysis demonstrates improved separation bounds for hierarchical classification learned hyperbolic spaces,learning hyperbolic spaces has gained increasing attention due the superior capability modeling hierarchical structures existing hyperbolic learning methods use fixed distance measure that assumes uniform hierarchical structure across all data points revised low rank decomposition scheme and hard pair mining mechanism reduce the computational cost incurred the pairwise generation compromising theoretical analysis and experiments standard image classification and few shot learning tasks affirm the effectiveness our refining hyperbolic learning our geometry aware distance measures,2025-08-26T00:59:30.191912
59,"*""Neural Exterior Calculus for Equivariant Representation Learning""*",Traditional approaches to equivariant representation learning require explicit symmetry specifications. We introduce neural exterior calculus - a framework for automatically learning equivariant representations through differential forms. Our method constructs provably equivariant architectures by learning bundle-valued differential operators defined on the data manifold. Theoretical contributions include universality proofs and stability analysis under symmetry-breaking perturbations. Applications in computational chemistry and robotics demonstrate 35-50% improvements in generalization to novel symmetries compared to conventional equivariant networks. Validation studies confirm the approach successfully rediscovers known physical symmetries while remaining computationally efficient.,ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,10314,Improving Equivariant Networks with Probabilistic Symmetry Breaking,"Equivariance encodes known symmetries into neural networks, often enhancing generalization. However, equivariant networks cannot *break* symmetries: the output of an equivariant network must, by definition, have at least the same self-symmetries as its input. This poses an important problem, both (1) for prediction tasks on domains where self-symmetries are common, and (2) for generative models, which must break symmetries in order to reconstruct from highly symmetric latent spaces. This fundamental limitation can in fact be addressed by considering *equivariant conditional distributions*, instead of equivariant functions. We therefore present novel theoretical results that establish necessary and sufficient conditions for representing such distributions. Concretely, this representation provides a practical framework for breaking symmetries in any equivariant network via randomized canonicalization. Our method, SymPE (Symmetry-breaking Positional Encodings), admits a simple interpretation in terms of positional encodings. This approach expands the representational power of equivariant networks while retaining the inductive bias of symmetry, which we justify through generalization bounds. Experimental results demonstrate that SymPE significantly improves performance of group-equivariant and graph neural networks across diffusion models for graphs, graph autoencoders, and lattice spin system modeling.",ICLR.cc/2025/Conference,7.0,True,0.8239,traditional approaches equivariant representation learning require explicit symmetry specifications neural exterior calculus for automatically learning equivariant representations differential forms our constructs provably equivariant architectures learning bundle valued differential operators defined the data manifold,equivariance encodes known symmetries into neural networks often enhancing generalization however equivariant networks cannot break symmetries the output equivariant network must definition have least the same self symmetries its input this poses important problem both for prediction tasks domains where self symmetries are common and for generative models which must break symmetries order reconstruct from highly symmetric latent spaces concretely this representation provides practical for breaking symmetries any equivariant network randomized canonicalization experimental that sympe improves group equivariant and graph neural networks across diffusion models for graphs graph autoencoders and lattice spin modeling,2025-08-26T00:59:30.191918
60,"*""Multi-Timescale Disentanglement via Coupled Oscillator Networks""*","Temporal data often contains interacting processes operating at different frequencies, challenging traditional representation learning methods. We present a disentanglement framework using networks of coupled neural oscillators with learnable natural frequencies. Our approach introduces a novel spectral orthogonalization loss that enforces timescale separation while preserving process interactions. Theoretical analysis establishes identifiability conditions for oscillatory factor models. Experiments on physiological signals and financial time-series demonstrate superior separation (40-55% improvement in factor purity) compared to variational approaches while maintaining predictive performance. The oscillator-based formulation enables accurate long-term forecasting and interpretable analysis of complex dynamical systems.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,10652,Dynamical modeling for real-time inference of nonlinear latent factors in multiscale neural activity,"Continuous real-time decoding of target variables from time-series data is needed for many applications across various domains including neuroscience. Further, these variables can be encoded across multiple time-series modalities such as discrete spiking activity and continuous field potentials that can have different timescales (i.e., sampling rates) and different probabilistic distributions, or can even be missing at some time-steps.  Existing nonlinear models of multimodal neural activity do not support real-time decoding and do not address the different timescales or missing samples across modalities. Here, we develop a learning framework that can nonlinearly aggregate information across multiple time-series modalities with such distinct characteristics, while also enabling real-time decoding. This framework consists of 1) a multiscale encoder that nonlinearly fuses information after learning within-modality dynamics to handle different timescales and missing samples,  2) a multiscale dynamical backbone that extracts multimodal temporal dynamics and enables real-time decoding, and 3) modality-specific decoders to account for different probabilistic distributions across modalities. We further introduce smoothness regularization objectives on the learned dynamics to better decode smooth target variables such as behavioral variables and employ a dropout technique to increase the robustness for missing samples. We show that our model can aggregate information across modalities to improve target variable decoding in simulations and in a real multiscale brain dataset. Further, our method outperforms prior linear and nonlinear multimodal models.",ICLR.cc/2025/Conference,4.25,False,0.8099,temporal data often contains interacting processes operating different frequencies challenging traditional representation learning methods disentanglement networks coupled neural oscillators learnable natural frequencies,existing nonlinear models multimodal neural activity not support real time decoding and not address the different timescales missing samples across modalities here learning that can nonlinearly aggregate information across multiple time series modalities such distinct characteristics while also enabling real time decoding this consists multiscale encoder that nonlinearly fuses information after learning within modality dynamics handle different timescales and missing samples multiscale dynamical backbone that extracts multimodal temporal dynamics and enables real time decoding and modality specific decoders account for different probabilistic distributions across modalities further smoothness regularization objectives the learned dynamics better decode smooth target variables such behavioral variables and employ dropout increase the robustness for missing samples,2025-08-26T00:59:30.191922
61,"*""Geometric Contrastive Learning with Neural Riemannian Metrics""*","Standard contrastive learning operates in Euclidean space, ignoring the intrinsic geometry of data manifolds. We develop a Riemannian contrastive framework that learns local metric tensors through neural estimation of geodesic distances. Our approach introduces curvature-adaptive negative sampling and geometrically consistent augmentation strategies. Theoretical contributions include convergence guarantees for metric learning and stability bounds under noise. Applications in drug discovery and robotic manipulation show 30-45% improvements in sample efficiency and out-of-distribution generalization compared to Euclidean approaches. The learned geometric structure enables accurate interpolation and physically plausible sample generation while respecting domain constraints.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,8041,GRADIENT-OPTIMIZED CONTRASTIVE LEARNING,"Contrastive learning is a crucial technique in representation learning, producing robust embeddings by distinguishing between similar and dissimilar pairs. In this paper, we introduce a novel framework, Gradient-Optimized Contrastive Learning (GOAL), which enhances network training by optimizing gradient updates during backpropagation as a bilevel optimization problem. Our approach offers three key insights that set it apart from existing methods: (1) Contrastive learning can be seen as an approximation of a one-class support vector machine (OC-SVM) using multiple neural tangent kernels (NTKs) in the network’s parameter space; (2) Hard triplet samples are vital for defining support vectors and outliers in OC-SVMs within NTK spaces, with their difficulty measured using Lagrangian multipliers; (3) Contrastive losses like InfoNCE provide efficient yet dense approximations of sparse Lagrangian multipliers by implicitly leveraging gradients. To address the computational complexity of GOAL, we propose a novel contrastive loss function, Sparse InfoNCE (SINCE), which improves the Lagrangian multiplier approximation by incorporating hard triplet sampling into InfoNCE. Our experimental results demonstrate the effectiveness and efficiency of SINCE in tasks such as image classification and point cloud completion. Demo code is attached in the supplementary file.",ICLR.cc/2025/Conference,5.8,False,0.8522,standard contrastive learning operates euclidean space ignoring the intrinsic geometry data manifolds riemannian contrastive that learns local tensors neural estimation geodesic distances theoretical contributions include convergence guarantees for learning and stability bounds under noise the learned geometric structure enables accurate interpolation and physically plausible sample generation while respecting domain constraints,contrastive learning crucial representation learning producing robust embeddings distinguishing between similar and dissimilar pairs this gradient optimized contrastive learning goal which enhances network training optimizing gradient updates during backpropagation bilevel optimization problem our offers three key insights that set apart from existing methods contrastive learning can seen approximation one class support vector machine svm multiple neural tangent kernels ntks the network parameter space hard triplet samples are vital for defining support vectors and outliers svms within ntk spaces their difficulty measured lagrangian multipliers contrastive losses like infonce provide efficient yet dense approximations sparse lagrangian multipliers implicitly leveraging gradients our experimental the effectiveness and efficiency since tasks such image classification and point cloud completion,2025-08-26T00:59:30.191924
62,"*""Bayesian Sparse Coding with Hierarchical Spike-and-Slab Priors""*",Traditional sparse coding relies on fixed sparsity budgets that may mismatch data complexity. We propose Bayesian sparse coding with learned hierarchical priors that adapt sparsity patterns to local data structure. Our framework employs nested spike-and-slab distributions with learned conditional dependencies among dictionary elements. Theoretical analysis demonstrates improved approximation properties compared to lasso-based approaches. Extensive experiments on medical imaging and neuroscience data show 35-50% reductions in reconstruction error with comparable sparsity levels. The method automatically adapts to varying complexity across input regions while maintaining interpretable representations.,ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,False,,Neural Electrostatics: A 3D Physics-Informed Boundary Element Poisson Equation Solver,"Electrostatics solvers relate an imposed voltage to a
corresponding charge density. Current classical methods require fine
discretization and scale poorly due to the construction of a large linear system
of equations. We recast the problem using neural networks and introduce
neural electrostatics, a hybrid 3D boundary element method (BEM). By using the
boundary element form, we are able to overcome many shortcomings of previous
neural solvers, such as learning trivial solutions and balancing loss terms
between the domain and boundary, at the cost of introducing a large integral
containing a singular kernel. We handle this singularity by locally
transforming the integral into polar coordinates and applying a numerical
quadrature. We also show that previous neural solver sampling methods are unable
to minimize the PDE residual, and propose a variational adaptive sampling
method. This technique is able to reduce mean absolute error by 5 times, while
keeping training time constant. Extensive scaling and ablation studies are
performed to justify our method. Results show that our method learns a charge
distribution within 1.2 $pC/m^2$ of mean absolute error from a classical BEM
solver, while using 25 times fewer rectangular elements.",ICLR.cc/2025/Conference,4.0,False,0.0000,,recast the problem neural networks and neural electrostatics hybrid boundary element bem the boundary element form are able overcome many shortcomings previous neural solvers such learning trivial solutions and balancing loss terms between the domain and boundary the cost introducing large integral containing singular kernel also that previous neural solver sampling methods are unable minimize the pde residual and variational adaptive sampling,2025-08-26T00:59:30.191926
63,"*""Trajectory-Aware Contrastive Learning for Dynamical Systems""*","Existing contrastive methods treat time-series samples as independent points, ignoring their temporal relationships. We introduce trajectory contrastive learning that preserves dynamical invariants through phase-space embeddings of entire trajectories. Our framework incorporates dynamical systems theory through stability-preserving regularizers and trajectory-sensitive augmentation. Applications to sensor networks and robotics demonstrate 25-40% improvements in long-term prediction and anomaly detection compared to point-based approaches. The method enables novel capabilities including controlled system interpolation and stability analysis directly from learned embeddings, bridging representation learning with dynamical systems theory.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,2630,C$^{2}$INet: Realizing Incremental Trajectory Prediction with Prior-Aware Continual Causal Intervention,"Trajectory prediction for multi-agents in complex scenarios is crucial for applications like autonomous driving. However, existing methods often overlook environmental biases, which leads to poor generalization. Additionally, hardware constraints limit the use of large-scale data across environments, and continual learning settings exacerbate the challenge of catastrophic forgetting. To address these issues, we propose the Continual Causal Intervention (C$^{2}$INet) method for generalizable multi-agent trajectory prediction within a continual learning framework. Using variational inference, we align environment-related prior with the posterior estimator of confounding factors in the latent space, thereby intervening in causal correlations that affect trajectory representation. Furthermore, we store optimal variational priors across various scenarios using a memory queue, ensuring continuous debiasing during incremental task training. The proposed C$^{2}$INet enhances adaptability to diverse tasks while preserving previous task information to prevent catastrophic forgetting. It also incorporates pruning strategies to mitigate overfitting.
Comparative evaluations on three real and synthetic complex datasets against state-of-the-art methods demonstrate that our proposed method consistently achieves reliable prediction performance, effectively mitigating confounding factors unique to different scenarios. This highlights the practical value of our method for real-world applications.",ICLR.cc/2025/Conference,4.666666666666667,False,0.8754,trajectory contrastive learning that preserves dynamical invariants phase space embeddings entire trajectories applications sensor networks and robotics improvements long term prediction and anomaly detection compared point based approaches the enables capabilities including controlled interpolation and stability analysis directly from learned embeddings bridging representation learning dynamical systems theory,trajectory prediction for multi agents complex scenarios crucial for applications like autonomous driving additionally hardware constraints limit the use large scale data across environments and continual learning settings exacerbate the challenge catastrophic forgetting address these issues the continual causal intervention inet for generalizable multi agent trajectory prediction within continual learning variational inference align environment related prior the posterior estimator confounding factors the latent space thereby intervening causal correlations that affect trajectory representation comparative evaluations three real and synthetic complex datasets against state the art methods that our proposed consistently achieves reliable prediction mitigating confounding factors unique different scenarios,2025-08-26T00:59:30.191933
64,"*""Learning Compositional Representations through Emergent Symbol Binding""*",Existing representation learning methods struggle to exhibit human-like compositional generalization due to their reliance on statistical patterns rather than symbolic reasoning. We introduce a neural architecture that learns true compositional representations by dynamically binding features to emergent symbols during learning. Our approach combines neural network capabilities with symbolic operations through differentiable binding matrices that evolve during training. Theoretical analysis demonstrates provable compositional generalization properties absent in conventional networks. Experiments on visual reasoning and language tasks show 35-50% improvement in out-of-distribution generalization compared to transformer baselines. The learned symbolic structure enables human-interpretable reasoning paths while maintaining end-to-end differentiability.,ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,6601,Unsupervised Learning of Categorical Structure,"Humans are known to reason using logic and abstract categories, and yet most state of the art neural models use continuous distributed representations. These representations offer impressive gradient-based learning capabilities, but it is often difficult to know what symbolic algorithm the network might implicitly be implementing, if any. We find that there are representational geometries that naturally suggest a symbolic structure, which can be expressed in terms of binary components. We show that we can recover this structure by fitting the geometry of this binary embedding to the representational geometry of the original objects. After establishing general facts and providing some intuitions, we present two algorithms that work on low-rank or full-rank data, respectively. We assess their reliability on simulated data, and then use them to interpret neural word embeddings, in which we expect a compositional structure.",ICLR.cc/2025/Conference,5.6,False,0.8572,existing representation learning methods struggle exhibit human like compositional generalization due their reliance statistical patterns rather than symbolic reasoning neural that learns true compositional representations dynamically binding features emergent symbols during learning our combines neural network capabilities symbolic operations differentiable binding matrices that evolve during training experiments visual reasoning and language tasks improvement out distribution generalization compared transformer baselines the learned symbolic structure enables human interpretable reasoning paths while maintaining end end differentiability,humans are known reason logic and categories and yet most state the art neural models use continuous distributed representations these representations offer impressive gradient based learning capabilities but often difficult know what symbolic the network might implicitly implementing any that can recover this structure fitting the geometry this binary embedding the representational geometry the original objects assess their reliability simulated data and then use them interpret neural word embeddings which expect compositional structure,2025-08-26T00:59:30.191937
65,"*""Equivariant Representation Learning with Learned Gauge Transformations""*","Current equivariant architectures require predefined symmetry groups, limiting their applicability. We present a gauge-theoretic framework that automatically learns both representations and their transformation rules directly from data. Our method constructs representations as sections of a learned fiber bundle, with gauge transformations modeled as parallel transport operators. Theoretical contributions include identifiability conditions for learned symmetries and convergence guarantees. Applications to particle physics and crystallography demonstrate the model rediscovers known physical symmetries while generalizing 25-40% better to novel transformations than traditional equivariant networks. This work establishes gauge theory as a foundational framework for flexible equivariant learning.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,10430,Incorporating gauge-invariance in equivariant networks,"Gauge theories, which describe fundamental forces in nature, arise from the principle of locality in physical interactions. These theories are characterized by their invariance under local symmetry transformations and the presence of a gauge field that mediates interactions. While recent works have introduced gauge equivariant neural networks, these models often focus on specific cases like tangent bundles or quotient spaces, limiting their applicability to the diverse gauge theories in physics. We propose a novel architecture for learning general gauge invariant quantities by explicitly modeling the gauge field in the context of graph neural networks. Our framework fills a critical gap in the existing literature by providing a general recipe for gauge invariance without restrictions on the fiber spaces. This approach allows for the modeling of more complex gauge theories, such as those with $SU(N)$ gauge groups, which are prevalent in particle physics. We evaluate our method on classical physical systems, including the XY model on various curved geometries, demonstrating its ability to capture gauge invariant properties in settings where existing equivariant architectures fall short. Our work takes a significant step towards bridging the gap between gauge theories in physics and equivariant neural network architectures, opening new avenues for applying machine learning to fundamental physical problems.",ICLR.cc/2025/Conference,4.25,False,0.8295,this establishes gauge theory foundational for flexible equivariant learning,while recent works have introduced gauge equivariant neural networks these models often focus specific cases like tangent bundles quotient spaces limiting their applicability the diverse gauge theories physics for learning general gauge invariant quantities explicitly modeling the gauge field the context graph neural networks our takes significant step towards bridging the gap between gauge theories physics and equivariant neural network architectures opening avenues for applying machine learning fundamental physical problems,2025-08-26T00:59:30.191940
66,"*""Neural Sheaf Diffusion for Heterogeneous Graph Representation""*","Traditional graph representation methods struggle with heterogeneous structures containing different node/edge types. We develop sheaf diffusion networks that model information flow using learned vector bundles over graphs. Our approach generalizes graph diffusion by incorporating type-aware linear transformations at each edge, dynamically adjusting message passing based on local structure. Theoretical analysis shows our framework universally approximates any continuous graph operator while maintaining linear complexity. Experiments on biomedical knowledge graphs and social networks demonstrate 20-30% improvements in node classification and link prediction, particularly for rare node types. The learned sheaf structure provides interpretable insights into heterogeneous relational patterns.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,2274,Explanations of GNN on Evolving Graphs via Axiomatic  Layer edges,"Graphs are ubiquitous in social networks, chemical molecules, and financial data, where Graph Neural Networks (GNNs) achieve superior predictive accuracy. Graphs can be
evolving, while understanding how GNN predictions respond to the evolution provides significant insight and trust. 
We explore the problem of explaining evolving GNN predictions due to continuously changing edge weights.
We introduce a layer edge-based explanation to balance
explanation fidelity and interpretability.
We propose a novel framework to address the challenges of axiomatic attribution and the entanglement of multiple computational graph paths due to continuous change of edge weights. We first design an axiomatic attribution of the evolution of the model prediction to message flows, then develop Shapley value to fairly map message flow contributions to layer edges.
We formulate a novel optimization problem to find the critical layer edges based on KL-divergence minimization. Extensive experiments on eight datasets for node classification, link prediction, and graph classification tasks with evolving graphs demonstrate the better fidelity and interpretability of the proposed method over the baseline methods. The code is available at https://github.com/yazhengliu/Axiomatic-Layer-Edges/tree/main.",ICLR.cc/2025/Conference,6.0,True,0.8337,traditional graph representation methods struggle heterogeneous structures containing different node edge types experiments biomedical knowledge graphs and social networks improvements node classification and link prediction for rare node types,graphs are ubiquitous social networks chemical molecules and financial data where graph neural networks gnns achieve superior predictive layer edge based explanation balance explanation fidelity and interpretability first axiomatic attribution the evolution the prediction message flows then shapley value fairly map message flow contributions layer edges formulate optimization problem find the critical layer edges divergence minimization extensive experiments eight datasets for node classification link prediction and graph classification tasks evolving graphs the better fidelity and interpretability the proposed over the methods,2025-08-26T00:59:30.191944
67,"*""Causal Representation Meta-Learning""*",Standard meta-learning often fails when task distributions differ due to confounding variables. We introduce causal meta-learning that identifies invariant mechanisms across tasks through interventional objectives. Our framework combines gradient-based meta-optimization with causal structure learning to discover representations that adapt rapidly to novel causal relationships. Theoretical analysis provides sample complexity bounds for causal mechanism reuse. Applications to healthcare and robotics show 40-60% faster adaptation to new environments compared to conventional meta-learning approaches while maintaining robustness to distribution shifts. The method automatically identifies transferable causal factors without explicit supervision.,ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,7971,ConML: A Universal Meta-Learning Framework with Task-Level Contrastive Learning,"Meta-learning enables learning systems to adapt quickly to new tasks, similar to humans. To emulate this human-like rapid learning and enhance alignment and discrimination abilities, we propose ConML, a universal meta-learning framework that can be applied to various meta-learning algorithms without relying on specific model architectures nor target models. The core of ConML is task-level contrastive learning, which extends contrastive learning from the representation space in unsupervised learning to the model space in meta-learning. By leveraging task identity as an additional supervision signal during meta-training, we contrast the outputs of the meta-learner in the model space, minimizing inner-task distance (between models trained on different subsets of the same task) and maximizing inter-task distance (between models from different tasks). We demonstrate that ConML integrates seamlessly with optimization-based, metric-based, and amortization-based meta-learning algorithms, as well as in-context learning, resulting in performance improvements across diverse few-shot learning tasks.",ICLR.cc/2025/Conference,4.0,False,0.8531,our combines gradient based meta optimization causal structure learning discover representations that adapt rapidly causal relationships applications healthcare and robotics faster adaptation environments compared conventional meta learning approaches while maintaining robustness distribution shifts,meta learning enables learning systems adapt quickly tasks similar humans emulate this human like rapid learning and enhance alignment and discrimination abilities conml universal meta learning that can applied various meta learning algorithms relying specific architectures nor target models the core conml task level contrastive learning which extends contrastive learning from the representation space unsupervised learning the space meta learning that conml integrates seamlessly optimization based metric based and amortization based meta learning algorithms well context learning resulting improvements across diverse few shot learning tasks,2025-08-26T00:59:30.191948
68,"*""Geometric Self-Supervised Learning with Neural Connection Forms""*","Current self-supervised methods often ignore the differential geometric structure of data manifolds. We propose learning representations through neural connection forms that model parallel transport on learned manifolds. Our approach builds on principal bundle theory, with representations defined by holonomy groups of learned connections. Theoretical contributions include stability guarantees and universality proofs. Experiments on dynamical systems and shape analysis show 25-40% improvements in geometric tasks while maintaining competitive performance on standard benchmarks. The framework enables novel capabilities like torsion estimation and curvature-aware interpolation directly from raw data.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,7604,Disentangled Representation Learning with the Gromov-Monge Gap,"Learning disentangled representations from unlabelled data is a fundamental challenge in machine learning. Solving it may unlock other problems, such as generalization, interpretability, or fairness. Although remarkably challenging to solve in theory, disentanglement is often achieved in practice through prior matching. Furthermore, recent works have shown that prior matching approaches can be enhanced by leveraging geometrical considerations, e.g., by learning representations that preserve geometric features of the data, such as distances or angles between points. However, matching the prior while preserving geometric features is challenging, as a mapping that *fully* preserves these features while aligning the data distribution with the prior does not exist in general. To address these challenges, we introduce a novel approach to disentangled representation learning based on quadratic optimal transport. We formulate the problem using Gromov-Monge maps that transport one distribution onto another with minimal distortion of predefined geometric features, preserving them *as much as can be achieved*. To compute such maps, we propose the Gromov-Monge-Gap (GMG), a regularizer quantifying whether a map moves a reference distribution with minimal geometry distortion. We demonstrate the effectiveness of our approach for disentanglement across four standard benchmarks, outperforming other methods leveraging geometric considerations.",ICLR.cc/2025/Conference,5.5,True,0.8115,learning representations neural connection forms that parallel transport learned manifolds,learning disentangled representations from unlabelled data fundamental challenge machine learning solving may unlock other problems such generalization interpretability fairness learning representations that preserve geometric features the data such distances angles between points address these challenges disentangled representation learning quadratic optimal transport,2025-08-26T00:59:30.191949
69,"*""Differentiable Topological Persistence for Robust Representation""*",Traditional neural networks are vulnerable to small perturbations that can alter topological features critical for downstream tasks. We develop a persistence-driven learning framework that explicitly maintains topological invariants through differentiable persistent homology computations. Our method introduces a novel filtration-adaptive pooling layer and topological regularization loss. Theoretical analysis bounds the sensitivity of topological features to input perturbations. Applications in medical imaging and material science demonstrate 30-50% improvements in robustness to adversarial attacks while preserving topological accuracy. The approach provides certified stability guarantees for critical topological features.,ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,2786,GOttack: Universal Adversarial Attacks on Graph Neural Networks via Graph Orbits Learning,"Graph Neural Networks (GNNs) have demonstrated superior performance in node classification tasks across diverse applications. However, their vulnerability to adversarial attacks, where minor perturbations can mislead model predictions, poses significant challenges. This study introduces GOttack, a novel adversarial attack framework that exploits the topological structure of graphs to undermine the integrity of GNN predictions systematically. 

By defining a topology-aware method to manipulate graph orbits, our approach generates adversarial modifications that are both subtle and effective, posing a severe test to the robustness of GNNs. We evaluate the efficacy of GOttack across multiple prominent GNN architectures using standard benchmark datasets. Our results show that GOttack outperforms existing state-of-the-art adversarial techniques and completes training in approximately 55% of the time required by the fastest competing model, achieving the highest average misclassification rate in 155 tasks. 
This work not only sheds light on the susceptibility of GNNs to structured adversarial attacks 
but also shows that certain topological patterns may play a significant role in the underlying robustness of the GNNs. Our Python implementation is shared at https://github.com/cakcora/GOttack.",ICLR.cc/2025/Conference,6.5,True,0.8325,traditional neural networks are vulnerable small perturbations that can alter topological features critical for downstream tasks persistence driven learning that explicitly maintains topological invariants differentiable persistent homology computations applications medical imaging and material science improvements robustness adversarial attacks while preserving topological,graph neural networks gnns have demonstrated superior node classification tasks across diverse applications defining topology aware manipulate graph orbits our generates adversarial modifications that are both subtle and effective posing severe the robustness gnns this not only sheds light the susceptibility gnns structured adversarial attacks but also shows that certain topological patterns may play significant role the underlying robustness the gnns,2025-08-26T00:59:30.191953
70,"*""Dynamical Optimal Transport for Temporal Representation Learning""*","Existing temporal representations often fail to capture underlying dynamical structure in sequential data. We propose learning representations through dynamic optimal transport, where sequences are mapped to paths in Wasserstein space. Our framework combines Sinkhorn iterations with neural ODEs to compute efficient approximations of continuous-time transport plans. Theoretical contributions include computational complexity bounds and approximation guarantees. Experiments on motion capture and climate modeling show superior performance (25-35% improvements) in forecasting and anomaly detection compared to traditional sequence models. The transport-based formulation enables physically meaningful interpolation between dynamical regimes.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,641,Improving Neural Optimal Transport via Displacement Interpolation,"Optimal Transport (OT) theory investigates the cost-minimizing transport map that moves a source distribution to a target distribution. Recently, several approaches have emerged for learning the optimal transport map for a given cost function using neural networks. We refer to these approaches as the OT Map. OT Map provides a powerful tool for diverse machine learning tasks, such as generative modeling and unpaired image-to-image translation. However, existing methods that utilize max-min optimization often experience training instability and sensitivity to hyperparameters. In this paper, we propose a novel method to improve stability and achieve a better approximation of the OT Map by exploiting displacement interpolation, dubbed Displacement Interpolation Optimal Transport Model (DIOTM). We derive the dual formulation of displacement interpolation at specific time $t$ and prove how these dual problems are related across time. This result allows us to utilize the entire trajectory of displacement interpolation in learning the OT Map. Our method improves the training stability and achieves superior results in estimating optimal transport maps. We demonstrate that DIOTM outperforms existing OT-based models on image-to-image translation tasks.",ICLR.cc/2025/Conference,6.5,True,0.8176,learning representations dynamic optimal transport where sequences are mapped paths wasserstein space our combines sinkhorn iterations neural odes compute efficient approximations continuous time transport plans experiments motion capture and climate modeling superior improvements forecasting and anomaly detection compared traditional sequence models,recently several approaches have emerged for learning the optimal transport map for given cost function neural networks map provides powerful tool for diverse machine learning tasks such generative modeling and unpaired image image translation however existing methods that utilize max min optimization often experience training instability and sensitivity hyperparameters this allows utilize the entire trajectory displacement interpolation learning the map,2025-08-26T00:59:30.191955
71,"*""Lie-Algebraic Representation Learning for Physical Systems""*",Physical systems obey conservation laws often unnoticed by standard representation learning methods. We introduce Lie-algebraic networks that explicitly model physical invariants through learned symmetry operators. Our approach decomposes representations into Lie algebra elements that generate physically meaningful transformations. Theoretical analysis demonstrates exact conservation of specified invariants while learning additional symmetries from data. Applications in fluid dynamics and quantum chemistry show 40-60% improvement in prediction accuracy while maintaining exact conservation of physical quantities like energy and momentum. The learned operators correspond to known physical symmetries in validation studies.,ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,False,,A Framework of SO(3)-equivariant Non-linear Representation Learning and its Application to Electronic-Structure Hamiltonian Prediction,"We propose both a theoretical and a methodological framework to address a critical challenge in applying deep learning to physical systems: the reconciliation of non-linear expressiveness with SO(3)-equivariance in predictions of SO(3)-equivariant quantities, such as the electronic-structure Hamiltonians. Inspired by covariant theory in physics, we present a solution by  exploring the mathematical relationships between SO(3)-invariant and SO(3)-equivariant quantities and their representations. We first construct theoretical SO(3)-invariant quantities derived from the SO(3)-equivariant regression targets, and use these invariant quantities as supervisory labels to guide the learning of high-quality SO(3)-invariant features. Given that SO(3)-invariance is preserved under non-linear operations, the encoding process for invariant features can extensively utilize non-linear mappings, thereby fully capturing the non-linear patterns inherent in physical systems. Building on this, we propose a gradient-based mechanism to induce SO(3)-equivariant encodings of various degrees from the learned SO(3)-invariant features. This mechanism can incorporate non-linear expressive capabilities into SO(3)-equivariant representations, while theoretically preserving their equivariant properties as we prove, establishing a strong foundation for regressing complex SO(3)-equivariant targets. We apply our theory and method to the electronic-structure Hamiltonian prediction tasks, experimental results on eight benchmark databases covering multiple types of systems and challenging scenarios show substantial improvements on the state-of-the-art prediction accuracy of deep learning paradigm. Our method boosts Hamiltonian prediction accuracy by up to 40\% and enhances downstream physical quantities, such as occupied orbital energy, by a maximum of 76\%. Our method also significantly promotes the acceleration performance for the convergence of traditional Density Functional Theory methods.",ICLR.cc/2025/Conference,6.0,False,0.7748,physical systems obey conservation laws often unnoticed standard representation learning methods theoretical analysis demonstrates exact conservation specified invariants while learning additional symmetries from data applications fluid dynamics and quantum chemistry improvement prediction while maintaining exact conservation physical quantities like energy and momentum,both theoretical and methodological address critical challenge applying deep learning physical systems the reconciliation non linear expressiveness equivariance predictions equivariant quantities such the electronic structure hamiltonians first construct theoretical invariant quantities derived from the equivariant regression targets and use these invariant quantities supervisory labels guide the learning high quality invariant features apply our theory and the electronic structure hamiltonian prediction tasks experimental eight databases covering multiple types systems and challenging scenarios substantial improvements the state the art prediction deep learning paradigm our boosts hamiltonian prediction and enhances downstream physical quantities such occupied orbital energy maximum,2025-08-26T00:59:30.191959
72,"""Learning Disentangled Causal Factors via Counterfactual Latent Interventions""","Learning representations that reflect the true causal structure of data remains a fundamental challenge in machine learning. We propose a novel framework that learns disentangled causal factors through systematic counterfactual interventions in latent space. Our approach leverages a causally-constrained variational autoencoder architecture where interventions on individual latent dimensions enforce independence between inferred causal factors. Theoretical analysis shows our method identifies causal factors under weaker assumptions than existing disentanglement approaches. Experiments on synthetic and real-world datasets demonstrate 25-40% improvement in disentanglement metrics compared to state-of-the-art baselines, with learned representations that enable precise counterfactual generation. This work bridges causal representation learning with deep generative models, offering interpretable and controllable representations for reliable decision-making.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,6476,Turning Challenges into Opportunities: How Distribution Shifts Enhance Identifiability in Causal Representation Learning,"Causal representation learning seeks to uncover latent causal variables and their relationships from observed, unstructured data, a task complicated by identifiability challenges. While distribution shifts, viewed as natural interventions on latent causal variables, often present difficulties in traditional machine learning tasks, they also create valuable opportunities for identifiability by introducing variability in latent variables. In this paper, we study a non-parametric condition characterizing the types of distribution shifts that contribute to identifiability within the context of latent additive noise models. We also present partial identifiability results when only a portion of distribution shifts meets the condition. Furthermore, we extend our findings to latent post-nonlinear causal models. Building on our theoretical results, we propose a practical algorithm facilitating the acquisition of reliable latent causal representations. Our algorithm, guided by our underlying theory, has demonstrated outstanding performance across a diverse range of synthetic and real-world datasets. The empirical observations closely align with the theoretical findings, affirming the robustness and effectiveness of our proposed approach.",ICLR.cc/2025/Conference,5.25,False,0.8494,learning representations that reflect the true causal structure data remains fundamental challenge machine learning experiments synthetic and real world datasets improvement disentanglement metrics compared state the art baselines learned representations that enable precise counterfactual generation this bridges causal representation learning deep generative models offering interpretable and controllable representations for reliable decision making,causal representation learning seeks uncover latent causal variables and their relationships from observed unstructured data task complicated identifiability challenges while distribution shifts viewed natural interventions latent causal variables often difficulties traditional machine learning tasks they also create valuable opportunities for identifiability introducing variability latent variables the empirical observations closely align the theoretical affirming the robustness and effectiveness our proposed,2025-08-26T00:59:30.191961
73,"""Hyperbolic Prototypical Networks for Few-Shot Hierarchical Classification""","Few-shot learning algorithms often struggle when data exhibits rich hierarchical structure, as standard Euclidean embeddings fail to capture taxonomic relationships. We introduce hyperbolic prototypical networks that leverage the exponential representational capacity of hyperbolic space to model hierarchical class relationships. Our approach incorporates a novel curvature-adaptation mechanism that automatically learns the optimal hyperbolic geometry for few-shot classification. Theoretical analysis demonstrates improved sample complexity bounds in hyperbolic space compared to Euclidean counterparts. Experiments on biological taxonomies and product hierarchies show 30-50% accuracy gains for few-shot classification, particularly for deep hierarchical structures. The learned hyperbolic embeddings provide interpretable visualization of hierarchical relationships at different levels of abstraction.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,3887,Geometry-aware Distance Measure for Diverse Hierarchical Structures in Hyperbolic Spaces,"Learning in hyperbolic spaces has gained increasing attention due to the superior capability of modeling hierarchical structures. Existing hyperbolic learning methods use a fixed distance measure that assumes a uniform hierarchical structure across all data points. However, this assumption does not always hold in real-world scenarios, considering the diversity of the hierarchical structures of data. This work proposes to learn geometry aware distance measures that dynamically adjust to accommodate diverse hierarchical structures in hyperbolic spaces. We derive geometry aware distance measures by generating projections and curvatures for each pair of samples, which maps each pair to a suitable hyperbolic space. We introduce a revised low-rank decomposition scheme and a hard-pair mining mechanism to reduce the computational cost incurred by the pairwise generation without compromising accuracy. Moreover, we derive an upper bound of the low-rank approximation error via Talagrand concentration inequality to guarantee the effectiveness of our low-rank decomposition scheme. Theoretical analysis and experiments on standard image classification and few-shot learning tasks affirm the effectiveness of our method in refining hyperbolic learning through our geometry aware distance measures.",ICLR.cc/2025/Conference,4.75,nan,0.8392,few shot learning algorithms often struggle when data exhibits rich hierarchical structure standard euclidean embeddings fail capture taxonomic relationships our incorporates curvature adaptation mechanism that automatically learns the optimal hyperbolic geometry for few shot classification experiments biological taxonomies and product hierarchies gains for few shot classification for deep hierarchical structures,learning hyperbolic spaces has gained increasing attention due the superior capability modeling hierarchical structures existing hyperbolic learning methods use fixed distance measure that assumes uniform hierarchical structure across all data points revised low rank decomposition scheme and hard pair mining mechanism reduce the computational cost incurred the pairwise generation compromising theoretical analysis and experiments standard image classification and few shot learning tasks affirm the effectiveness our refining hyperbolic learning our geometry aware distance measures,2025-08-26T00:59:30.191962
74,"""Neural Differential Geometry for Equivariant Representation Learning""","Traditional approaches to equivariant representation learning rely on explicit symmetry specifications through group representations. We propose a fundamentally different approach based on neural differential geometry, where equivariance emerges naturally from learned geometric structure. Our framework constructs neural connections and frame bundles that implicitly capture data symmetries through their transformation properties. Theoretical contributions include identifiability results for symmetry groups and universality proofs. Applications to molecular property prediction and particle physics demonstrate 25-40% improvement in generalization to novel symmetries compared to conventional equivariant networks. The approach automatically rediscovers known physical symmetries in validation studies while maintaining computational efficiency.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,10314,Improving Equivariant Networks with Probabilistic Symmetry Breaking,"Equivariance encodes known symmetries into neural networks, often enhancing generalization. However, equivariant networks cannot *break* symmetries: the output of an equivariant network must, by definition, have at least the same self-symmetries as its input. This poses an important problem, both (1) for prediction tasks on domains where self-symmetries are common, and (2) for generative models, which must break symmetries in order to reconstruct from highly symmetric latent spaces. This fundamental limitation can in fact be addressed by considering *equivariant conditional distributions*, instead of equivariant functions. We therefore present novel theoretical results that establish necessary and sufficient conditions for representing such distributions. Concretely, this representation provides a practical framework for breaking symmetries in any equivariant network via randomized canonicalization. Our method, SymPE (Symmetry-breaking Positional Encodings), admits a simple interpretation in terms of positional encodings. This approach expands the representational power of equivariant networks while retaining the inductive bias of symmetry, which we justify through generalization bounds. Experimental results demonstrate that SymPE significantly improves performance of group-equivariant and graph neural networks across diffusion models for graphs, graph autoencoders, and lattice spin system modeling.",ICLR.cc/2025/Conference,7.0,True,0.8846,traditional approaches equivariant representation learning rely explicit symmetry specifications group representations fundamentally different neural differential geometry where equivariance emerges naturally from learned geometric structure our constructs neural connections and frame bundles that implicitly capture data symmetries their transformation properties applications molecular property prediction and particle physics improvement generalization symmetries compared conventional equivariant networks,equivariance encodes known symmetries into neural networks often enhancing generalization however equivariant networks cannot break symmetries the output equivariant network must definition have least the same self symmetries its input this poses important problem both for prediction tasks domains where self symmetries are common and for generative models which must break symmetries order reconstruct from highly symmetric latent spaces concretely this representation provides practical for breaking symmetries any equivariant network randomized canonicalization experimental that sympe improves group equivariant and graph neural networks across diffusion models for graphs graph autoencoders and lattice spin modeling,2025-08-26T00:59:30.191964
75,"""Dynamic Topological Representation Learning via Persistent Homology""",Existing representation learning methods often ignore the evolving topological structure of streaming data. We introduce a framework that dynamically updates representations based on persistent homology features computed over sliding windows. Our approach incorporates topological signatures through a novel differentiable persistent homology layer and adaptive learning mechanisms. Theoretical analysis provides stability guarantees for topological features under distribution shift. Experiments on time-series medical data and sensor networks demonstrate 20-35% improvement in detecting meaningful patterns and anomalies compared to conventional approaches. The framework maintains an interpretable topological signature that evolves with changing data distributions.,ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,4452,ToRL: Topology-preserving Representation Learning Of Object Deformations From Images,"Representation learning of object deformations from images has been a long-standing challenge in various image or video analysis tasks. Existing deep neural networks typically focus on visual features (e.g., intensity and texture), but they often fail to capture the underlying geometric and topological structures of objects. This limitation becomes especially critical in areas, such as medical imaging and 3D modeling, where maintaining the structural integrity of objects is essential for accuracy and generalization across diverse datasets. In this paper, we introduce ToRL, a novel *Topology-preserving Representation Learning* model that, for the first time, offers an explicit mechanism for modeling intricate object topology in the latent feature space. We develop a comprehensive learning framework that captures object deformations via learned transformation groups in the latent space. Each layer of our network's decoder is carefully designed with an integrated smooth composition module, ensuring that topological properties are preserved throughout the learning process. Moreover, in contrast to a few related works that rely on a reference image to predict object deformations during inference, our approach eliminates this impractical requirement. To validate ToRL's effectiveness, we conduct extensive multi-class classification experiments across a wide range of datasets, including synthetic 2D images, real 3D brain magnetic resonance imaging (MRI) scans, real 3D adrenal computed tomography (CT) shapes, and \textcolor{blue}{real 2D facial expression images}. Experimental results demonstrate that ToRL outperforms state-of-the-art methods, setting a new way to enforce topological consistency in representation learning. Our code is available at - https://anonymous.4open.science/r/ToRL-44BF/",ICLR.cc/2025/Conference,5.5,False,0.8361,existing representation learning methods often ignore the evolving topological structure streaming data our incorporates topological signatures differentiable persistent homology layer and adaptive learning mechanisms,representation learning object deformations from images has been long standing challenge various image video analysis tasks existing deep neural networks focus visual features this torl topology preserving representation learning that for the first time offers explicit mechanism for modeling intricate object topology the latent feature space comprehensive learning that captures object deformations learned transformation groups the latent space each layer our network decoder carefully designed integrated smooth composition module ensuring that topological properties are preserved throughout the learning process torl effectiveness conduct extensive multi class classification experiments across wide range datasets including synthetic images real brain magnetic resonance imaging mri scans real adrenal computed tomography shapes and textcolor blue real facial expression images experimental that torl outperforms state the art methods setting way enforce topological consistency representation learning,2025-08-26T00:59:30.191965
76,"""Information-Geometric Representation Learning with Neural Mixture Families""","Traditional representation learning often employs Euclidean embeddings that fail to capture rich statistical structures. We develop a framework that learns representations as points in statistical manifolds defined by neural mixture families. Our approach combines exponential family distributions with deep learning through diffeomorphic flow transformations. Theoretical contributions include generalization bounds based on information geometry and computational tractability guarantees. Applications to text and genomics data show 15-30% improvement in downstream task performance compared to Euclidean embeddings, with learned representations respecting fundamental information-theoretic constraints. The framework enables principled interpolation and generation in statistically meaningful spaces.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,533,The Mutual Information Matrix in Hyperbolic Embedding and a Generalization Error Bound,"Representation learning is a crucial task of deep learning, which aims to project texts and other symbolic inputs into mathematical embedding. Traditional representation learning encodes symbolic data into an Euclidean space. However, the high dimensionality of the Euclidean space used for embedding words presents considerable computational and storage challenges. Hyperbolic space has emerged as a promising alternative for word embedding, which demonstrates strong representation and generalization capacities, particularly for latent hierarchies of language data. In this paper, we analyze the Skip-Gram Negative-sampling representation learning method in hyperbolic spaces, and explore the potential relationship between the mutual information and hyperbolic embedding. Furthermore, we establish generalization error bounds for hyperbolic embedding. These bounds demonstrate the dimensional parsimony of hyperbolic space and its relationship between the generalization error and the sample size. Finally, we conduct two experiments on the Wordnet dataset and the THUNews dataset, whose results further validate our theoretical properties.",ICLR.cc/2025/Conference,3.5,False,0.8479,traditional representation learning often employs euclidean embeddings that fail capture rich statistical structures that learns representations points statistical manifolds defined neural mixture families our combines exponential family distributions deep learning diffeomorphic flow transformations the enables principled interpolation and generation statistically meaningful spaces,representation learning crucial task deep learning which aims project texts and other symbolic inputs into mathematical embedding traditional representation learning encodes symbolic data into euclidean space however the high dimensionality the euclidean space used for embedding words presents considerable computational and storage challenges hyperbolic space has emerged promising alternative for word embedding which demonstrates strong representation and generalization capacities for latent hierarchies language data this the skip gram negative sampling representation learning hyperbolic spaces and the potential relationship between the mutual information and hyperbolic embedding furthermore establish generalization error bounds for hyperbolic embedding,2025-08-26T00:59:30.191969
77,"""Compressive Representation Learning via Differentiable Sparsity Gates""","Current representation learning methods often produce dense embeddings that are inefficient and lack interpretability. We propose a framework that learns compressed representations through differentiable sparsity gates that dynamically prune uninformative features. Our approach combines ℓ0-inspired stochastic gates with a novel gradient estimation technique for efficient end-to-end training. Theoretical analysis demonstrates that our method achieves near-optimal rate-distortion tradeoffs while maintaining differentiability. Experiments on image and text data show our method learns representations with 50-70% sparsity while matching or exceeding performance of dense baselines on downstream tasks. The sparse structure enables efficient storage and computation, with applications to resource-constrained settings. Moreover, the learned gate patterns provide interpretable insights into feature importance.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,6965,Optimal Causal Representations and the Causal Information Bottleneck,"To effectively study complex causal systems, it is often useful to construct representations that simplify parts of the system by discarding irrelevant details while preserving key features.
The Information Bottleneck (IB) method is a widely used approach in representation learning that compresses random variables while retaining information about a target variable.
Traditional methods like IB are purely statistical and ignore underlying causal structures, making them ill-suited for causal tasks.
We propose the Causal Information Bottleneck (CIB), a causal extension of the IB, which compresses a set of chosen variables while maintaining causal control over a target variable.
This method produces representations which are causally interpretable, and which can be used when reasoning about interventions.
We present experimental results demonstrating that the learned representations accurately capture causality as intended.",ICLR.cc/2025/Conference,6.0,False,0.8133,current representation learning methods often produce dense embeddings that are inefficient and lack interpretability moreover the learned gate patterns provide interpretable insights into feature importance,the information bottleneck used representation learning that compresses random variables while retaining information about target variable this produces representations which are causally interpretable and which can used when reasoning about interventions,2025-08-26T00:59:30.191971
78,"""Geometric Attention Networks for Point Cloud Processing""","Standard point cloud processing methods often struggle to capture complex geometric relationships between points. We introduce geometric attention networks that explicitly model local and global geometric structures through learned attention patterns. Our approach develops novel geometric-aware attention mechanisms incorporating both Euclidean and geodesic distances, curvature information, and local surface orientation. Theoretical contributions include stability guarantees for the attention operators under geometric perturbations. Experiments on 3D shape classification and segmentation demonstrate 15-25% improvement over state-of-the-art methods while using 30% fewer parameters. The geometric attention patterns provide interpretable visualization of how the network attends to structural information, offering insights into the learned geometric reasoning.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,4891,SAMBLE: Learning Shape-Specific Sampling Strategies for Point Cloud Shapes with Sparse Attention Map and Adaptive Bin Partitioning,"Point cloud sampling plays a pivotal role in facilitating efficient analysis of large-scale point clouds. Recently, learning-to-sample methods have garnered growing interest from the community, particularly for their ability to be jointly trained with downstream tasks. However, previous learning-based sampling methods either lead to unrecognizable sampling patterns by generating a new point cloud or biased sampled results by focusing excessively on shape details. Moreover, they all fail to take the natural point distribution variations over different shapes into consideration and learn a similar sampling strategy for all point clouds. In this paper, we propose a Sparse Attention Map and Bin-based Learning method (termed SAMBLE) to learn shape-specific sampling strategies for point cloud shapes, striking a superior balance between the overall shape outline and intricate local details for the sampling process. In particular, we first propose sparse attention map by integrating both local and global information. Based on this, multiple point-wise sampling score computation methods are proposed and explored by leveraging heatmaps as a guiding tool. Subsequently, we introduce a binning strategy that partitions points within each point cloud based on these scores. Finally, additional learnable tokens are introduced during the attention computation phase to acquire sampling weights for each bin, thereby enabling the development of shape-specific sampling strategies for an optimized sampling process. Extensive experiments demonstrate that our method adeptly strikes a refined balance between sampling edge points for local details and preserving uniformity in the global shape, leading to superior performance across common point cloud downstream tasks and even in scenarios involving few-point cloud sampling.",ICLR.cc/2025/Conference,5.0,nan,0.8093,standard point cloud processing methods often struggle capture complex geometric relationships between points geometric attention networks that explicitly local and global geometric structures learned attention patterns our develops geometric aware attention mechanisms incorporating both euclidean and geodesic distances curvature information and local surface orientation theoretical contributions include stability guarantees for the attention operators under geometric perturbations experiments shape classification and segmentation improvement over state the art methods while fewer parameters the geometric attention patterns provide interpretable visualization how the network attends structural information offering insights into the learned geometric reasoning,this sparse attention map and bin based learning termed samble learn shape specific sampling strategies for point cloud shapes striking superior balance between the overall shape outline and intricate local details for the sampling process particular first sparse attention map integrating both local and global information finally additional learnable tokens are introduced during the attention computation phase acquire sampling weights for each bin thereby enabling the development shape specific sampling strategies for optimized sampling process,2025-08-26T00:59:30.191974
79,"""Self-Supervised Representation Learning via Temporal Context Prediction""","Temporal structure in sequential data provides rich supervisory signal that current self-supervised approaches underutilize. We present a framework for learning representations through multi-scale temporal context prediction across different time horizons. Our architecture combines a hierarchical attention mechanism with causal convolutions to capture both short-term dynamics and long-term dependencies. Theoretical analysis shows our objective maximizes mutual information between past and future states under autoregressive assumptions. Experiments on videos, sensor data, and financial time series demonstrate 20-35% improvements in downstream forecasting and classification tasks compared to standard contrastive approaches. The learned representations capture semantically meaningful temporal concepts at multiple timescales, enabling applications in video understanding and behavioral analysis.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,3332,MATEY: multiscale adaptive foundation models for spatiotemporal physical systems,"Accurate representation of the multiscale features in spatiotemporal physical systems using vision transformer (ViT) architectures requires extremely long, computationally prohibitive token sequences. To address this issue, we propose an adaptive tokenization scheme which dynamically adjusts the token sizes based on local features. 
Moreover, we present a set of spatiotemporal attention schemes, where the temporal or axial spatial dimensions are decoupled, and evaluate their computational and data efficiencies.
We assess the performance of the proposed multiscale adaptive model, MATEY, in a sequence of experiments. 
The results show that adaptive tokenization achieves improved accuracy without significantly increasing token sequence length, but the improvement deteriorates in more complex data configurations. 
Compared to a full spatiotemporal attention scheme or a scheme that decouples only the temporal dimension, we find that fully decoupled axial attention is less efficient and expressive, requiring more training time and model weights to achieve the same accuracy. 
Finally, we demonstrate in two fine-tuning tasks featuring different physics that models pretrained on PDEBench data outperform the ones trained from scratch, especially in the low data regime with frozen attention.",ICLR.cc/2025/Conference,3.5,nan,0.8338,for learning representations multi scale temporal context prediction across different time horizons our combines hierarchical attention mechanism causal convolutions capture both short term dynamics and long term dependencies experiments videos sensor data and financial time series improvements downstream forecasting and classification tasks compared standard contrastive approaches,accurate representation the multiscale features spatiotemporal physical systems vision transformer vit architectures requires extremely long computationally prohibitive token sequences moreover set spatiotemporal attention schemes where the temporal axial spatial dimensions are decoupled and their computational and data efficiencies compared full spatiotemporal attention scheme scheme that decouples only the temporal dimension find that fully decoupled axial attention less efficient and expressive requiring more training time and weights achieve the same finally two fine tuning tasks featuring different physics that models pretrained pdebench data outperform the ones trained from scratch the low data regime frozen attention,2025-08-26T00:59:30.191980
80,"""Dynamic Bottleneck Transformers for Efficient Representation Learning""","Transformer architectures have revolutionized representation learning, but their quadratic complexity remains prohibitive for many applications. We introduce Dynamic Bottleneck Transformers that automatically learn to compress sequential inputs into compact, information-dense bottleneck tokens. Our approach combines differentiable top-k selection with hierarchical attention to preserve long-range dependencies while reducing computational complexity to linear. Theoretical analysis demonstrates our method maintains approximation properties of full attention while being provably more efficient. Experiments on language modeling, protein sequences, and time-series forecasting show comparable performance to standard transformers with 30-50% fewer computations. The bottleneck mechanism provides interpretable insight into which input features are most salient for the task at hand.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,942,Higher Order Transformers: Efficient Attention Mechanism for Tensor Structured Data,"Transformers are now ubiquitous for sequence modeling tasks, but their extension to multi-dimensional data remains a challenge due to the quadratic cost of the attention mechanism.  In this paper, we propose Higher-Order Transformers (HOT), a novel architecture designed to efficiently process data with more than two axes, i.e. higher-order tensors. 
To address the computational challenges associated with high-order tensor attention, we introduce a novel Kronecker factorized attention mechanism that reduces the attention cost to quadratic in each axis' dimension, rather than quadratic in the total size of the input tensor. To further enhance efficiency, HOT leverages kernelized attention, reducing the complexity to linear. This strategy maintains the model's expressiveness while enabling scalable attention computation.
We validate the effectiveness of HOT on two high-dimensional tasks, including multivariate time series forecasting, and 3D medical image classification. Experimental results demonstrate that HOT achieves competitive performance while significantly improving computational efficiency, showcasing its potential for tackling a wide range of complex, multi-dimensional data.",ICLR.cc/2025/Conference,3.75,False,0.8845,transformer architectures have revolutionized representation learning but their quadratic complexity remains prohibitive for many applications our combines differentiable top selection hierarchical attention preserve long range dependencies while reducing computational complexity linear theoretical analysis demonstrates our maintains approximation properties full attention while being provably more efficient experiments language modeling protein sequences and time series forecasting comparable standard transformers fewer computations,transformers are now ubiquitous for sequence modeling tasks but their extension multi dimensional data remains challenge due the quadratic cost the attention mechanism address the computational challenges associated high order tensor attention kronecker factorized attention mechanism that reduces the attention cost quadratic each axis dimension rather than quadratic the total size the input tensor this strategy maintains the model expressiveness while enabling scalable attention computation the effectiveness hot two high dimensional tasks including multivariate time series forecasting and medical image classification,2025-08-26T00:59:30.191984
81,"""Topologically-Guided Contrastive Learning on Manifolds""",Traditional contrastive learning operates on individual data points without regard for global manifold structure. We present a framework that incorporates persistent homology signatures directly into contrastive learning objectives to preserve topological features. Our method constructs a differentiable mapper complex over the embedding space and optimizes topological similarity between augmented views. Theoretical guarantees demonstrate preservation of manifold topology under projection. Experiments on single-cell genomics and cosmological data show 15-25% improvement in clustering quality and robustness to noise. The approach enables discovery of higher-order connectivity patterns that standard methods miss.,ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,8041,GRADIENT-OPTIMIZED CONTRASTIVE LEARNING,"Contrastive learning is a crucial technique in representation learning, producing robust embeddings by distinguishing between similar and dissimilar pairs. In this paper, we introduce a novel framework, Gradient-Optimized Contrastive Learning (GOAL), which enhances network training by optimizing gradient updates during backpropagation as a bilevel optimization problem. Our approach offers three key insights that set it apart from existing methods: (1) Contrastive learning can be seen as an approximation of a one-class support vector machine (OC-SVM) using multiple neural tangent kernels (NTKs) in the network’s parameter space; (2) Hard triplet samples are vital for defining support vectors and outliers in OC-SVMs within NTK spaces, with their difficulty measured using Lagrangian multipliers; (3) Contrastive losses like InfoNCE provide efficient yet dense approximations of sparse Lagrangian multipliers by implicitly leveraging gradients. To address the computational complexity of GOAL, we propose a novel contrastive loss function, Sparse InfoNCE (SINCE), which improves the Lagrangian multiplier approximation by incorporating hard triplet sampling into InfoNCE. Our experimental results demonstrate the effectiveness and efficiency of SINCE in tasks such as image classification and point cloud completion. Demo code is attached in the supplementary file.",ICLR.cc/2025/Conference,5.8,False,0.8626,traditional contrastive learning operates individual data points regard for global manifold structure that incorporates persistent homology signatures directly into contrastive learning objectives preserve topological features our constructs differentiable mapper complex over the embedding space and optimizes topological similarity between augmented views experiments single cell genomics and cosmological data improvement clustering quality and robustness noise,contrastive learning crucial representation learning producing robust embeddings distinguishing between similar and dissimilar pairs this gradient optimized contrastive learning goal which enhances network training optimizing gradient updates during backpropagation bilevel optimization problem our offers three key insights that set apart from existing methods contrastive learning can seen approximation one class support vector machine svm multiple neural tangent kernels ntks the network parameter space hard triplet samples are vital for defining support vectors and outliers svms within ntk spaces their difficulty measured lagrangian multipliers contrastive losses like infonce provide efficient yet dense approximations sparse lagrangian multipliers implicitly leveraging gradients our experimental the effectiveness and efficiency since tasks such image classification and point cloud completion,2025-08-26T00:59:30.191985
82,"""Hyperbolic Word Embeddings with Learnable Curvature""","Most word embedding methods use Euclidean space, ignoring linguistic hierarchies that hyperbolic geometry captures better. We develop hyperbolic embeddings where the curvature is learned optimally for each semantic relation type. Our architecture employs type-specific hyperbolic transformations and attention mechanisms to model complex hierarchical relationships. Theoretical analysis shows improved metric properties for asymmetric relations compared to standard embeddings. Evaluation on downstream NLP tasks demonstrates 20-30% gains in recognizing hypernym relationships while maintaining strong performance on standard benchmarks. Learned curvature values correlate with linguistic properties like ontological depth.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,533,The Mutual Information Matrix in Hyperbolic Embedding and a Generalization Error Bound,"Representation learning is a crucial task of deep learning, which aims to project texts and other symbolic inputs into mathematical embedding. Traditional representation learning encodes symbolic data into an Euclidean space. However, the high dimensionality of the Euclidean space used for embedding words presents considerable computational and storage challenges. Hyperbolic space has emerged as a promising alternative for word embedding, which demonstrates strong representation and generalization capacities, particularly for latent hierarchies of language data. In this paper, we analyze the Skip-Gram Negative-sampling representation learning method in hyperbolic spaces, and explore the potential relationship between the mutual information and hyperbolic embedding. Furthermore, we establish generalization error bounds for hyperbolic embedding. These bounds demonstrate the dimensional parsimony of hyperbolic space and its relationship between the generalization error and the sample size. Finally, we conduct two experiments on the Wordnet dataset and the THUNews dataset, whose results further validate our theoretical properties.",ICLR.cc/2025/Conference,3.5,False,0.8557,most word embedding methods use euclidean space ignoring linguistic hierarchies that hyperbolic geometry captures better hyperbolic embeddings where the curvature learned optimally for each semantic relation type our employs type specific hyperbolic transformations and attention mechanisms complex hierarchical relationships,representation learning crucial task deep learning which aims project texts and other symbolic inputs into mathematical embedding traditional representation learning encodes symbolic data into euclidean space however the high dimensionality the euclidean space used for embedding words presents considerable computational and storage challenges hyperbolic space has emerged promising alternative for word embedding which demonstrates strong representation and generalization capacities for latent hierarchies language data this the skip gram negative sampling representation learning hyperbolic spaces and the potential relationship between the mutual information and hyperbolic embedding furthermore establish generalization error bounds for hyperbolic embedding,2025-08-26T00:59:30.191987
83,"""Neural Optimal Transport for Representation Alignment""",Domains often differ not just in marginal distributions but in their underlying feature geometries. We propose aligning representations through learned optimal transport maps that preserve intrinsic geometric structure. Our approach combines neural Kantorovich potentials with regularized transport plans to handle high-dimensional spaces efficiently. Theoretical contributions include stability guarantees and generalization bounds for transport-based alignment. Applications to cross-domain image retrieval and multilingual NLP show 25-40% improvement over adversarial and moment matching approaches. The transport maps provide interpretable visualization of domain relationships.,ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,False,,Topological Schrödinger Bridge Matching,"Given two boundary distributions, the \emph{Schrödinger Bridge} (SB) problem seeks the “most likely” random evolution between them with respect to a reference process. It has revealed rich connections to recent machine learning methods for generative modeling and distribution matching. While these methods perform well in Euclidean domains, they are not directly applicable to topological domains such as graphs and simplicial complexes, which are crucial for data defined over network entities, such as node signals and edge flows. In this work, we propose the \emph{Topological Schrödinger Bridge problem} ($\mathcal{T}$SBP) for matching signal distributions on a topological domain. We set the reference process to follow some linear tractable \emph{topology-aware} stochastic dynamics such as topological heat diffusion. For the case of Gaussian boundary distributions, we derive a \emph{closed-form} topological SB ($\mathcal{T}$SB) in terms of its time-marginal and stochastic differential. In the general case, leveraging the well-known result, we show that the optimal process follows the forward-backward topological dynamics governed by some unknowns. Building on these results, we develop $\mathcal{T}$SB-based models for matching topological signals by parameterizing the unknowns in the optimal process as \emph{(topological) neural networks} and learning them through \emph{likelihood training}. We validate the theoretical results and demonstrate the practical applications of $\mathcal{T}$SB-based models on both synthetic and real-world networks, emphasizing the role of topology. Additionally, we discuss the connections of $\mathcal{T}$SB-based models to other emerging models, and outline future directions for topological signal matching.",ICLR.cc/2025/Conference,7.5,True,0.7928,domains often differ not just marginal distributions but their underlying feature geometries our combines neural kantorovich potentials regularized transport plans handle high dimensional spaces the transport maps provide interpretable visualization domain relationships,has revealed rich connections recent machine learning methods for generative modeling and distribution matching while these methods perform well euclidean domains they are not directly applicable topological domains such graphs and simplicial complexes which are crucial for data defined over network entities such node signals and edge flows this the emph topological schrödinger bridge problem mathcal sbp for matching signal distributions topological domain building these mathcal based models for matching topological signals parameterizing the unknowns the optimal process emph topological neural networks and learning them emph likelihood training,2025-08-26T00:59:30.191991
84,"""Disentangled Representation Learning via Differentiable Sparsity""",Current disentanglement methods rely on statistical independence assumptions that may not hold in practice. We present an alternative approach based on structured sparsity patterns in learned representations. Our framework induces sparsity through learned pruning masks that explicitly separate factors of variation. Theoretical analysis demonstrates identifiability under weaker conditions than independence-based methods. Experiments on complex 3D scenes and medical imaging show superior factor separation (30-50% improvement) while requiring no changes to base architectures. The sparse representations enable precise manipulation of individual factors.,ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,False,,Neural Electrostatics: A 3D Physics-Informed Boundary Element Poisson Equation Solver,"Electrostatics solvers relate an imposed voltage to a
corresponding charge density. Current classical methods require fine
discretization and scale poorly due to the construction of a large linear system
of equations. We recast the problem using neural networks and introduce
neural electrostatics, a hybrid 3D boundary element method (BEM). By using the
boundary element form, we are able to overcome many shortcomings of previous
neural solvers, such as learning trivial solutions and balancing loss terms
between the domain and boundary, at the cost of introducing a large integral
containing a singular kernel. We handle this singularity by locally
transforming the integral into polar coordinates and applying a numerical
quadrature. We also show that previous neural solver sampling methods are unable
to minimize the PDE residual, and propose a variational adaptive sampling
method. This technique is able to reduce mean absolute error by 5 times, while
keeping training time constant. Extensive scaling and ablation studies are
performed to justify our method. Results show that our method learns a charge
distribution within 1.2 $pC/m^2$ of mean absolute error from a classical BEM
solver, while using 25 times fewer rectangular elements.",ICLR.cc/2025/Conference,4.0,False,0.0000,,recast the problem neural networks and neural electrostatics hybrid boundary element bem the boundary element form are able overcome many shortcomings previous neural solvers such learning trivial solutions and balancing loss terms between the domain and boundary the cost introducing large integral containing singular kernel also that previous neural solver sampling methods are unable minimize the pde residual and variational adaptive sampling,2025-08-26T00:59:30.191992
85,"""Lie Group Representation Networks for Physical Systems""","Many physical systems exhibit Lie group symmetries that standard neural networks ignore. We develop architectures that embed inputs in learned Lie group representation spaces, with dynamics governed by group-equivariant transformations. Theoretical contributions include universality proofs and stability guarantees for our parameterization. Applications to molecular dynamics and robotics demonstrate 20-35% improvements in prediction accuracy while exactly conserving physical quantities like momentum and energy. The group structure enables generation of physically plausible novel system states.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,8735,Lie Algebra Canonicalization: Equivariant Neural Operators under arbitrary Lie Groups,"The quest for robust and generalizable machine learning models has driven recent interest in exploiting symmetries through equivariant neural networks. In the context of PDE solvers, recent works have shown that Lie point symmetries can be a useful inductive bias for Physics-Informed Neural Networks (PINNs) through data and loss augmentation. Despite this, directly enforcing equivariance within the model architecture for these problems remains elusive. This is because many PDEs admit non-compact symmetry groups, oftentimes not studied beyond their infinitesimal generators, making them incompatible with most existing equivariant architectures. In this work, we propose Lie aLgebrA Canonicalization (LieLAC), a novel approach that exploits only the action of infinitesimal generators of the symmetry group, circumventing the need for knowledge of the full group structure. To achieve this, we address existing theoretical issues in the canonicalization literature, establishing connections with frame averaging in the case of continuous non-compact groups. Operating within the framework of canonicalization, LieLAC can easily be integrated with unconstrained pre-trained models, transforming inputs to a canonical form before feeding them into the existing model, effectively aligning the input for model inference according to allowed symmetries. LieLAC utilizes standard Lie group descent schemes, achieving equivariance in pre-trained models. Finally, we showcase LieLAC's efficacy on tasks of invariant image classification and Lie point symmetry equivariant neural PDE solvers using pre-trained models.",ICLR.cc/2025/Conference,6.5,True,0.8367,many physical systems exhibit lie group symmetries that standard neural networks ignore architectures that embed inputs learned lie group representation spaces dynamics governed group equivariant transformations applications molecular dynamics and robotics improvements prediction while exactly conserving physical quantities like momentum and energy the group structure enables generation physically plausible states,the quest for robust and generalizable machine learning models has driven recent interest exploiting symmetries equivariant neural networks the context pde solvers recent works have shown that lie point symmetries can useful inductive bias for physics informed neural networks pinns data and loss augmentation this lie algebra canonicalization lielac that exploits only the action infinitesimal generators the symmetry group circumventing the need for knowledge the full group structure finally showcase lielac efficacy tasks invariant image classification and lie point symmetry equivariant neural pde solvers pre trained models,2025-08-26T00:59:30.191993
86,"""Progressive Concept Formation for Lifelong Representation Learning""","Current representation learning assumes stationary data distributions, limiting applicability to lifelong learning scenarios. We propose a framework where concepts form incrementally through competitive learning and hierarchical composition. Our architecture combines predictive coding with dynamic memory expansion to accommodate novel concepts while avoiding catastrophic forgetting. Theoretical analysis shows improved stability-plasticity tradeoffs compared to regularization-based approaches. Experiments on continual learning benchmarks demonstrate 15-20% higher accuracy over time with near-zero forgetting. The learned concepts organize hierarchically based on statistical structure.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,5816,DESIRE: Dynamic Knowledge Consolidation for Rehearsal-Free Continual Learning,"Continual learning aims to equip models with the ability to retain previously learned knowledge like a human. Recent work incorporating Parameter-Efficient Fine-Tuning has revitalized the field by introducing lightweight extension modules. However, existing methods usually overlook the issue of information leakage caused by the fact that the experiment data have been used in pre-trained models. Once these duplicate data are removed in the pre-training phase, their performance can be severely affected. In this paper, we propose a new LoRA-based rehearsal-free method named $\textbf{DESIRE}$. Our method avoids imposing additional constraints during training to mitigate catastrophic forgetting, thereby maximizing the learning of new classes. To integrate knowledge from old and new tasks, we propose two efficient post-processing modules. On the one hand, we retain only two sets of LoRA parameters for merging and propose dynamic representation consolidation to calibrate the merged feature representation. On the other hand, we propose decision boundary refinement to address classifier bias when training solely on new class data. Extensive experiments demonstrate that our method achieves state-of-the-art performance on multiple datasets and strikes an effective balance between stability and plasticity. Our code will be publicly available.",ICLR.cc/2025/Conference,4.25,nan,0.8427,current representation learning assumes stationary data distributions limiting applicability lifelong learning scenarios where concepts form incrementally competitive learning and hierarchical composition experiments continual learning benchmarks higher over time near zero forgetting,continual learning aims equip models the ability retain previously learned knowledge like human our avoids imposing additional constraints during training mitigate catastrophic forgetting thereby maximizing the learning classes integrate knowledge from old and tasks two efficient post processing modules the one hand retain only two sets lora parameters for merging and dynamic representation consolidation calibrate the merged feature representation,2025-08-26T00:59:30.192003
87,"""Self-Supervised Learning via Differentiable Rendering""",Existing self-supervised methods rely heavily on predefined augmentation strategies. We instead learn representations by predicting how latent factors affect renderings of data under various transformations. Our framework employs a differentiable renderer trained jointly with an inverse graphics encoder. Theoretical analysis connects this approach to inference in generative models. Experiments comparing to contrastive methods show superior sample efficiency (2x+ improvements in low-data regimes) and better preservation of 3D structure in learned representations. The framework enables controllable generation and editing of learned factors.,ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,False,,FairGen: controlling fair generations in diffusion models via adaptive latent guidance,"Diffusion models have shown remarkable proficiency in generating photorealistic images, but their outputs often exhibit biases toward specific social groups, raising ethical concerns and limiting their wider adoption. This paper tackles the challenge of mitigating generative bias in diffusion models while maintaining image quality. We propose FairGen, an adaptive latent guidance mechanism enhanced by an auxiliary memory module, which operates during inference to control the generation distribution at a desired level. The latent guidance module dynamically adjusts the direction in the latent space to influence specific attributes, while the memory module tracks prior generation statistics and steers the scalar direction to align with the target distribution. To evaluate FairGen comprehensively, we introduce a bias evaluation benchmark tailored for diffusion models, spanning diverse domains such as employment, education, finance, and healthcare, along with complex user-generated prompts. Extensive empirical evaluations demonstrate that FairGen outperforms existing bias mitigation approaches, achieving substantial bias reduction while preserving generation quality. Furthermore, FairGen offers precise and flexible control over various target distributions, enabling nuanced adjustments to the generative process.",ICLR.cc/2025/Conference,4.0,False,0.7815,the enables controllable generation and editing learned factors,fairgen adaptive latent guidance mechanism enhanced auxiliary memory module which operates during inference control the generation distribution desired level the latent guidance module dynamically adjusts the direction the latent space influence specific attributes while the memory module tracks prior generation statistics and steers the scalar direction align the target distribution extensive empirical evaluations that fairgen outperforms existing bias mitigation approaches achieving substantial bias reduction while preserving generation quality,2025-08-26T00:59:30.192009
88,"""Symmetry-Aware Representation Learning via Differentiable Group Discovery""","Modern representation learning often ignores underlying symmetries in data, resulting in inefficient models prone to overfitting. We present a framework that simultaneously discovers symmetry groups and learns corresponding equivariant representations in an end-to-end manner. Our approach constructs a learnable group space where candidate transformations are evaluated through their effect on representation utility. Theoretical analysis shows our method recovers known symmetry groups in tractable cases while scaling to complex real-world scenarios. Experiments on molecular property prediction and physics simulations demonstrate 20-30% improvements in sample efficiency compared to fixed-symmetry baselines. The discovered symmetries align well with domain knowledge, providing interpretable insights into data structure. This work bridges geometric deep learning with automated symmetry discovery, offering a principled approach for building efficient, physics-aware models.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,6839,Symmetric Space Learning for Combinatorial Generalization,"Symmetries on representations within generative models have shown essential roles in predicting unobserved combinations of semantic changes, known as combinatorial generalization tasks. However, these efforts have primarily focused on learning symmetries from only training data, and thus, the extension of trained symmetries to unseen samples remains uncontrolled. A potential approach for generalizing the symmetries is leveraging geometric information on manifolds that contain functional semantic structures for unseen data, but it still falls short of supporting symmetry learning. In this paper, we address this $\textit{symmetry generalization}$ by forcing $\textit{symmetric space}$ on latent space for utilizing semantic structures from symmetry and manifold perspectives. We clarify an equivariance-based constraint that restricts symmetry generalization, and prove that: 1) enforcing the homogeneous space property of symmetric space onto the data manifold eliminates this constraint, 2) a homogeneous latent manifold induces the data manifold through diffeomorphic data-to-latent mapping, and 3) the isometry property of symmetric space extends neighbor symmetries of a point to another within the space. For practical implementation, we propose a method to align sampled points from symmetric space with their explicitly trained geodesic. We verify the method in a detailed analysis on a toy dataset and enhance combinatorial generalization on common benchmarks. This work represents the first effective effort to align symmetries with manifolds for combinatorial generalization.",ICLR.cc/2025/Conference,4.75,False,0.8844,modern representation learning often ignores underlying symmetries data resulting inefficient models prone overfitting our constructs learnable group space where candidate transformations are evaluated their effect representation utility experiments molecular property prediction and physics simulations improvements sample efficiency compared fixed symmetry baselines the discovered symmetries align well domain knowledge providing interpretable insights into data structure this bridges geometric deep learning automated symmetry discovery offering principled for building efficient physics aware models,symmetries representations within generative models have shown essential roles predicting unobserved combinations semantic changes known combinatorial generalization tasks however these efforts have primarily focused learning symmetries from only training data and thus the extension trained symmetries unseen samples remains uncontrolled potential for generalizing the symmetries leveraging geometric information manifolds that contain functional semantic structures for unseen data but still falls short supporting symmetry learning this address this textit symmetry generalization forcing textit symmetric space latent space for utilizing semantic structures from symmetry and manifold perspectives,2025-08-26T00:59:30.192011
89,"""Hyperbolic Memory Networks for Few-Shot Hierarchical Learning""","Few-shot learning methods struggle when data exhibits rich hierarchical structure, as Euclidean embeddings fail to capture taxonomic relationships efficiently. We introduce hyperbolic memory networks that leverage the exponential representational capacity of hyperbolic space for hierarchical few-shot classification. Our architecture combines three key innovations: curvature-adaptive memory updating, hyperbolic attention mechanisms, and geodesic decision boundaries. Theoretical analysis demonstrates improved margin guarantees in hyperbolic space compared to Euclidean counterparts. Extensive evaluation on biological taxonomies and product hierarchies shows 25-40% accuracy gains over conventional approaches, particularly for deep hierarchies. The hyperbolic embeddings provide intuitive visualization of learned relationships while maintaining high empirical performance.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,3887,Geometry-aware Distance Measure for Diverse Hierarchical Structures in Hyperbolic Spaces,"Learning in hyperbolic spaces has gained increasing attention due to the superior capability of modeling hierarchical structures. Existing hyperbolic learning methods use a fixed distance measure that assumes a uniform hierarchical structure across all data points. However, this assumption does not always hold in real-world scenarios, considering the diversity of the hierarchical structures of data. This work proposes to learn geometry aware distance measures that dynamically adjust to accommodate diverse hierarchical structures in hyperbolic spaces. We derive geometry aware distance measures by generating projections and curvatures for each pair of samples, which maps each pair to a suitable hyperbolic space. We introduce a revised low-rank decomposition scheme and a hard-pair mining mechanism to reduce the computational cost incurred by the pairwise generation without compromising accuracy. Moreover, we derive an upper bound of the low-rank approximation error via Talagrand concentration inequality to guarantee the effectiveness of our low-rank decomposition scheme. Theoretical analysis and experiments on standard image classification and few-shot learning tasks affirm the effectiveness of our method in refining hyperbolic learning through our geometry aware distance measures.",ICLR.cc/2025/Conference,4.75,nan,0.8586,few shot learning methods struggle when data exhibits rich hierarchical structure euclidean embeddings fail capture taxonomic relationships hyperbolic memory networks that leverage the exponential representational capacity hyperbolic space for hierarchical few shot classification our combines three key innovations curvature adaptive memory updating hyperbolic attention mechanisms and geodesic decision boundaries extensive evaluation biological taxonomies and product hierarchies shows gains over conventional approaches for deep hierarchies,learning hyperbolic spaces has gained increasing attention due the superior capability modeling hierarchical structures existing hyperbolic learning methods use fixed distance measure that assumes uniform hierarchical structure across all data points revised low rank decomposition scheme and hard pair mining mechanism reduce the computational cost incurred the pairwise generation compromising theoretical analysis and experiments standard image classification and few shot learning tasks affirm the effectiveness our refining hyperbolic learning our geometry aware distance measures,2025-08-26T00:59:30.192012
90,"""Topological Contrastive Learning with Persistent Homology""","Current contrastive learning treats data points independently, ignoring their underlying topological structure. We propose integrating persistent homology computations directly into contrastive objectives through differentiable topological signatures. Our method constructs Vietoris-Rips complexes over embedding spaces and optimizes topological similarity between differently augmented views. Theoretical contributions include stability guarantees for topological features under projection and noise. Experiments on biomedical imaging and material science datasets demonstrate 15-25% improvement in clustering and robustness metrics compared to standard approaches. The framework preserves connectivity patterns critical for downstream scientific analysis while maintaining computational tractability.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,8041,GRADIENT-OPTIMIZED CONTRASTIVE LEARNING,"Contrastive learning is a crucial technique in representation learning, producing robust embeddings by distinguishing between similar and dissimilar pairs. In this paper, we introduce a novel framework, Gradient-Optimized Contrastive Learning (GOAL), which enhances network training by optimizing gradient updates during backpropagation as a bilevel optimization problem. Our approach offers three key insights that set it apart from existing methods: (1) Contrastive learning can be seen as an approximation of a one-class support vector machine (OC-SVM) using multiple neural tangent kernels (NTKs) in the network’s parameter space; (2) Hard triplet samples are vital for defining support vectors and outliers in OC-SVMs within NTK spaces, with their difficulty measured using Lagrangian multipliers; (3) Contrastive losses like InfoNCE provide efficient yet dense approximations of sparse Lagrangian multipliers by implicitly leveraging gradients. To address the computational complexity of GOAL, we propose a novel contrastive loss function, Sparse InfoNCE (SINCE), which improves the Lagrangian multiplier approximation by incorporating hard triplet sampling into InfoNCE. Our experimental results demonstrate the effectiveness and efficiency of SINCE in tasks such as image classification and point cloud completion. Demo code is attached in the supplementary file.",ICLR.cc/2025/Conference,5.8,False,0.8614,current contrastive learning treats data points independently ignoring their underlying topological structure our constructs vietoris rips complexes over embedding spaces and optimizes topological similarity between differently augmented views experiments biomedical imaging and material science datasets improvement clustering and robustness metrics compared standard approaches,contrastive learning crucial representation learning producing robust embeddings distinguishing between similar and dissimilar pairs this gradient optimized contrastive learning goal which enhances network training optimizing gradient updates during backpropagation bilevel optimization problem our offers three key insights that set apart from existing methods contrastive learning can seen approximation one class support vector machine svm multiple neural tangent kernels ntks the network parameter space hard triplet samples are vital for defining support vectors and outliers svms within ntk spaces their difficulty measured lagrangian multipliers contrastive losses like infonce provide efficient yet dense approximations sparse lagrangian multipliers implicitly leveraging gradients our experimental the effectiveness and efficiency since tasks such image classification and point cloud completion,2025-08-26T00:59:30.192013
91,"""Neural Exterior Calculus for Equivariant Representation Learning""","Existing equivariant architectures require explicit symmetry specifications, limiting their flexibility. We develop neural exterior calculus - a framework where equivariance emerges naturally from learned differential geometric structure. Our approach constructs equivariant operators through neural differential forms and Hodge theory operations, with constraints enforced via Cartan's magic formula. Theoretical analysis provides universality proofs and stability bounds under symmetry-breaking perturbations. Applications to fluid dynamics and quantum chemistry demonstrate 30-50% improvements in generalization to novel symmetries while maintaining physical consistency. The automatically discovered differential operators correspond to known physical laws in validation studies.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,False,,Incorporating gauge-invariance in equivariant networks,"Gauge theories, which describe fundamental forces in nature, arise from the principle of locality in physical interactions. These theories are characterized by their invariance under local symmetry transformations and the presence of a gauge field that mediates interactions. While recent works have introduced gauge equivariant neural networks, these models often focus on specific cases like tangent bundles or quotient spaces, limiting their applicability to the diverse gauge theories in physics. We propose a novel architecture for learning general gauge invariant quantities by explicitly modeling the gauge field in the context of graph neural networks. Our framework fills a critical gap in the existing literature by providing a general recipe for gauge invariance without restrictions on the fiber spaces. This approach allows for the modeling of more complex gauge theories, such as those with $SU(N)$ gauge groups, which are prevalent in particle physics. We evaluate our method on classical physical systems, including the XY model on various curved geometries, demonstrating its ability to capture gauge invariant properties in settings where existing equivariant architectures fall short. Our work takes a significant step towards bridging the gap between gauge theories in physics and equivariant neural network architectures, opening new avenues for applying machine learning to fundamental physical problems.",ICLR.cc/2025/Conference,4.25,False,0.7893,neural exterior calculus where equivariance emerges naturally from learned differential geometric structure our constructs equivariant operators neural differential forms and hodge theory operations constraints enforced cartan magic formula,while recent works have introduced gauge equivariant neural networks these models often focus specific cases like tangent bundles quotient spaces limiting their applicability the diverse gauge theories physics for learning general gauge invariant quantities explicitly modeling the gauge field the context graph neural networks our takes significant step towards bridging the gap between gauge theories physics and equivariant neural network architectures opening avenues for applying machine learning fundamental physical problems,2025-08-26T00:59:30.192015
92,"""Dynamical Sparse Coding with Adaptive Manifold Learning""","Traditional sparse coding employs static dictionaries that cannot adapt to evolving data distributions. We introduce a framework where dictionary elements evolve according to learned manifold geometry, preserving local structure under non-stationarity. Our method combines alternating optimization between neural manifold embedding and sparse coding with provable convergence guarantees. Applications to video processing and sensor networks show 25-40% improvements in reconstruction fidelity compared to static methods while maintaining efficiency. The learned manifolds provide interpretable insights into distribution shifts, suggesting applications in anomaly detection.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,3911,MCNC: Manifold-Constrained Reparameterization for Neural Compression,"The outstanding performance of large foundational models across diverse tasks,
from computer vision to speech and natural language processing, has significantly
increased their demand. However, storing and transmitting these models poses
significant challenges due to their massive size (e.g., 750GB for Llama 3.1 405B).
Recent literature has focused on compressing the original weights or reducing the
number of parameters required for fine-tuning these models. These compression
methods generally constrain the parameter space, for example, through low-rank
reparametrization (e.g., LoRA), pruning, or quantization (e.g., QLoRA) during
or after the model training. In this paper, we present a novel model compres-
sion method, which we term Manifold-Constrained Neural Compression (MCNC).
This method constrains the parameter space to low-dimensional pre-defined and
frozen nonlinear manifolds, which effectively cover this space. Given the preva-
lence of good solutions in over-parameterized deep neural networks, we show that
by constraining the parameter space to our proposed manifold, we can identify
high-quality solutions while achieving unprecedented compression rates across
a wide variety of tasks and architectures. Through extensive experiments in
computer vision and natural language processing tasks, we demonstrate that our
method significantly outperforms state-of-the-art baselines in terms of compres-
sion, accuracy, and/or model reconstruction time. Our code is publicly available at
https://github.com/mint-vu/MCNC.",ICLR.cc/2025/Conference,6.0,True,0.8302,our combines alternating optimization between neural manifold embedding and sparse coding provable convergence guarantees applications video processing and sensor networks improvements reconstruction fidelity compared static methods while maintaining efficiency the learned manifolds provide interpretable insights into distribution shifts suggesting applications anomaly detection,the outstanding large foundational models across diverse tasks from computer vision speech and natural language processing has increased their demand this compres sion which term manifold constrained neural compression mcnc given the preva lence good solutions over parameterized deep neural networks that constraining the parameter space our proposed manifold can identify high quality solutions while achieving unprecedented compression rates across wide variety tasks and architectures extensive experiments computer vision and natural language processing tasks that our outperforms state the art baselines terms compres sion and reconstruction time,2025-08-26T00:59:30.192018
93,"""Temporal Disentanglement via Coupled Oscillatory Networks""","Sequential data often contains multiple interacting processes with different timescales, confounding traditional representation learning. We present a framework employing independent neural oscillators with learned natural frequencies to separate temporal factors. Our architecture introduces phase coupling penalties that enforce separability while preserving essential interactions. Theoretical guarantees establish identifiability conditions in weakly coupled oscillator systems. Evaluation on physiological signals demonstrates superior factor separation (40-55% purity gains) compared to variational approaches. The oscillatory dynamics enable accurate long-term forecasting while maintaining interpretability.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,59,Neural ODE with Differentiable Hidden State for Irregular Time Series,"Capturing the continuous underlying dynamics of irregular time series is essential for accurately reflecting the ongoing evolution and intricate correlations within the data. The discrete nature of current models, including RNN-based models and transformer variants, poses challenges when it comes to generalizing to the continuous-time data paradigms, which is necessary for capturing ongoing dynamics of irregular time series. 
Neural Ordinary Differential Equations (NODEs) assume a continuous latent dynamic and provide an elegant framework for irregular time series analysis. However, integrating new information while maintaining the continuity of latent dynamics remains challenging. 
To tackle this problem, we introduce Differentiable Hidden State (DHS) enhanced neural ODE, a data-dependent framework that is capable of effectively capturing temporal dependencies and ensuring the continuity of the hidden process. We leverage the theory of generalized inverses to innovatively compute attention mechanism in reverse and obtain a continuous representation. To capture more accurate temporal relationships, we introduce Hoyer metric and maximize the sparsity of it. Experimental results on both synthetic and real-world datasets demonstrate the effectiveness of our model.",ICLR.cc/2025/Conference,2.0,nan,0.8289,sequential data often contains multiple interacting processes different timescales confounding traditional representation learning employing independent neural oscillators learned natural frequencies separate temporal factors the oscillatory dynamics enable accurate long term forecasting while maintaining interpretability,the discrete nature current models including rnn based models and transformer variants poses challenges when comes generalizing the continuous time data paradigms which necessary for capturing ongoing dynamics irregular time series neural ordinary differential equations nodes assume continuous latent dynamic and provide elegant for irregular time series analysis tackle this problem differentiable hidden state dhs enhanced neural ode data dependent that capable capturing temporal dependencies and ensuring the continuity the hidden process leverage the theory generalized inverses innovatively compute attention mechanism reverse and obtain continuous representation,2025-08-26T00:59:30.192020
94,"""Geometric Self-Supervised Learning with Neural Riemannian Metrics""",Standard self-supervised methods often ignore the intrinsic geometric structure of data manifolds. We propose learning representations that respect underlying Riemannian geometry through learned metric tensors. Our approach constructs geodesic-aware contrastive objectives with curvature-dependent negative sampling strategies. Theoretical contributions include convergence guarantees for neural metric learning and stability bounds under noise. Applications to molecular property prediction show 20-35% improvements in sample efficiency while respecting physical constraints. The framework enables geometrically consistent interpolation and generation of novel samples.,ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,5052,Score-based pullback Riemannian geometry,"Data-driven Riemannian geometry has emerged as a powerful tool for interpretable representation learning, offering improved efficiency in downstream tasks. Moving forward, it is crucial to balance cheap manifold mappings with efficient training algorithms. In this work, we integrate concepts from pullback Riemannian geometry and generative models to propose a framework for data-driven Riemannian geometry that is scalable in both geometry and learning: score-based pullback Riemannian geometry. Focusing on unimodal distributions as a first step, we propose a score-based Riemannian structure with closed-form geodesics that pass through the data probability density. With this structure, we construct a Riemannian autoencoder (RAE) with error bounds for discovering the correct data manifold dimension. This framework can naturally be used with anisotropic normalizing flows by adopting isometry regularization during training. Through numerical experiments on various datasets, we demonstrate that our framework not only produces high-quality geodesics through the data support, but also reliably estimates the intrinsic dimension of the data manifold and provides a global chart of the manifold, even in high-dimensional ambient spaces.",ICLR.cc/2025/Conference,5.25,False,0.8704,learning representations that respect underlying riemannian geometry learned tensors theoretical contributions include convergence guarantees for neural learning and stability bounds under noise applications molecular property prediction improvements sample efficiency while respecting physical constraints the enables geometrically consistent interpolation and generation samples,data driven riemannian geometry has emerged powerful tool for interpretable representation learning offering improved efficiency downstream tasks,2025-08-26T00:59:30.192022
95,"""Bayesian Sparse Coding with Hierarchical Spike-and-Slab Processes""",Traditional sparse coding relies on fixed sparsity budgets that may mismatch local data complexity. We introduce hierarchical spike-and-slab processes where both representation sparsity and dictionary structure adapt to data characteristics. Our framework employs nested beta-Bernoulli processes to model dependencies among dictionary elements with provable approximation guarantees. Experiments on medical imaging and neuroscience data demonstrate 30-50% reductions in reconstruction error compared to lasso-based approaches. The method automatically identifies regions of varying complexity without sacrificing interpretability.,ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,False,,Improving the Sparse Structure Learning of Spiking Neural Networks from the View of Compression Efficiency,"The human brain utilizes spikes for information transmission and dynamically reorganizes its network structure to boost energy efficiency and cognitive capabilities throughout its lifespan. Drawing inspiration from this spike-based computation, Spiking Neural Networks (SNNs) have been developed to construct event-driven models that emulate this efficiency. Despite these advances, deep SNNs continue to suffer from over-parameterization during training and inference, a stark contrast to the brain’s ability to self-organize. Furthermore, existing sparse SNNs are challenged by maintaining optimal pruning levels due to a static pruning ratio, resulting in either under or over-pruning.
In this paper, we propose a novel two-stage dynamic structure learning approach for deep SNNs, aimed at maintaining effective sparse training from scratch while optimizing compression efficiency. 
The first stage evaluates the compressibility of existing sparse subnetworks within SNNs using the PQ index, which facilitates an adaptive determination of the rewiring ratio for synaptic connections based on data compression insights. In the second stage, this rewiring ratio critically informs the dynamic synaptic connection rewiring process, including both pruning and regrowth. This approach significantly improves the exploration of sparse structures training in deep SNNs, adapting sparsity dynamically from the point view of compression efficiency.
Our experiments demonstrate that this sparse training approach not only aligns with the performance of current deep SNNs models but also significantly improves the efficiency of compressing sparse SNNs. Crucially, it preserves the advantages of initiating training with sparse models and offers a promising solution for implementing Edge AI on neuromorphic hardware.",ICLR.cc/2025/Conference,5.75,True,0.7863,hierarchical spike and slab processes where both representation sparsity and dictionary structure adapt data characteristics the automatically identifies regions varying complexity sacrificing interpretability,the human brain utilizes spikes for information transmission and dynamically reorganizes its network structure boost energy efficiency and cognitive capabilities throughout its lifespan drawing inspiration from this spike based computation spiking neural networks snns have been developed construct event driven models that emulate this efficiency despite these advances deep snns continue suffer from over parameterization during training and inference stark contrast the brain ability self organize this two stage dynamic structure learning for deep snns aimed maintaining effective sparse training from scratch while optimizing compression efficiency this improves the exploration sparse structures training deep snns adapting sparsity dynamically from the point view compression efficiency our experiments that this sparse training not only aligns the current deep snns models but also improves the efficiency compressing sparse snns,2025-08-26T00:59:30.192026
96,"*""Disentangling Latent Causal Mechanisms via Intervention-Centric Representation Learning""*","Current disentanglement approaches often fail to recover true causal factors due to reliance on statistical patterns. We propose an intervention-centric framework that identifies causal mechanisms through active perturbation learning. Our method employs a causal discovery module that identifies candidate interventions, coupled with a contrastive objective that maximizes sensitivity to meaningful perturbations. Theoretical analysis shows identifiability under weaker conditions than existing methods (e.g., no support overlap requirement). Experiments on molecular property prediction and robotics tasks demonstrate 25-40% improvement in intervention generalization while achieving state-of-the-art disentanglement scores. Notably, the learned representations enable precise control of individual causal factors, with applications in interpretable AI and scientific discovery. This work bridges causal inference with self-supervised learning through principled intervention design.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,8,Adaptive Causal Experimental Design: Amortizing Sequential Bayesian Experimental Design for Causal Models,"Interventions are essential for causal discovery and causal reasoning. Acquiring interventional data, however, is often costly, especially in real-world systems.
A careful experimental design can therefore bring substantial savings. 
In the sequential experimental design setting, 
most existing approaches seek the best 
interventions in a greedy (myopic) manner that does not account for the synergy from the yet-to-come future experiments. We propose Adaptive Causal Experimental Design (ACED),
a novel Bayesian sequential design framework for learning a design policy capable of generating non-myopic interventions that incorporate the effect on future experiments.
In particular, ACED maximizes the Expected Information Gain (EIG) on flexible choices of causal quantities of interest (e.g., causal structure, specific causal effects) directly, bypassing the need for computing intermediate posteriors in the experimental sequence.
Leveraging a variational lower bound estimator for the EIG, ACED trains an amortized policy network that can be executed rapidly during deployment. 
We present numerical results demonstrating ACED's effectiveness on synthetic datasets with both linear and nonlinear structural causal models, as well as on in-silico single-cell gene expression datasets.",ICLR.cc/2025/Conference,5.0,False,0.8349,intervention centric that identifies causal mechanisms active perturbation learning experiments molecular property prediction and robotics tasks improvement intervention generalization while achieving state the art disentanglement scores this bridges causal inference self supervised learning principled intervention,interventions are essential for causal discovery and causal reasoning adaptive causal experimental aced bayesian sequential for learning policy capable generating non myopic interventions that incorporate the effect future experiments leveraging variational lower bound estimator for the eig aced trains amortized policy network that can executed rapidly during deployment,2025-08-26T00:59:30.192029
97,"*""Neural Sheaf Diffusion for Heterogeneous Graph Representation""*","Existing graph representation methods struggle with complex heterogeneous relations common in real-world networks. We introduce neural sheaf diffusion, a framework that models relations as vector bundles (sheaves) over graphs. Our approach learns edge-specific linear transformations (restriction maps) that respect the semantic type of each connection while maintaining efficient message passing. Theoretical contributions include universal approximation guarantees and spectral stability bounds. Evaluation on biomedical knowledge graphs and social networks shows 20-30% improvement in link prediction and node classification for rare relation types compared to conventional graph networks. The learned sheaf structure provides interpretable visualization of how different relation types transform information flow, offering new insights into complex network phenomena.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,2274,Explanations of GNN on Evolving Graphs via Axiomatic  Layer edges,"Graphs are ubiquitous in social networks, chemical molecules, and financial data, where Graph Neural Networks (GNNs) achieve superior predictive accuracy. Graphs can be
evolving, while understanding how GNN predictions respond to the evolution provides significant insight and trust. 
We explore the problem of explaining evolving GNN predictions due to continuously changing edge weights.
We introduce a layer edge-based explanation to balance
explanation fidelity and interpretability.
We propose a novel framework to address the challenges of axiomatic attribution and the entanglement of multiple computational graph paths due to continuous change of edge weights. We first design an axiomatic attribution of the evolution of the model prediction to message flows, then develop Shapley value to fairly map message flow contributions to layer edges.
We formulate a novel optimization problem to find the critical layer edges based on KL-divergence minimization. Extensive experiments on eight datasets for node classification, link prediction, and graph classification tasks with evolving graphs demonstrate the better fidelity and interpretability of the proposed method over the baseline methods. The code is available at https://github.com/yazhengliu/Axiomatic-Layer-Edges/tree/main.",ICLR.cc/2025/Conference,6.0,True,0.8442,existing graph representation methods struggle complex heterogeneous relations common real world networks neural sheaf diffusion that models relations vector bundles sheaves over graphs our learns edge specific linear transformations restriction maps that respect the semantic type each connection while maintaining efficient message passing evaluation biomedical knowledge graphs and social networks shows improvement link prediction and node classification for rare relation types compared conventional graph networks the learned sheaf structure provides interpretable visualization how different relation types transform information flow offering insights into complex network phenomena,graphs are ubiquitous social networks chemical molecules and financial data where graph neural networks gnns achieve superior predictive layer edge based explanation balance explanation fidelity and interpretability first axiomatic attribution the evolution the prediction message flows then shapley value fairly map message flow contributions layer edges formulate optimization problem find the critical layer edges divergence minimization extensive experiments eight datasets for node classification link prediction and graph classification tasks evolving graphs the better fidelity and interpretability the proposed over the methods,2025-08-26T00:59:30.192030
98,"*""Dynamic-Curvature Manifold Learning with Neural Cartan Geometry""*","Most manifold learning assumes static curvature, limiting applicability to real-world data with varying local geometry. We develop a neural Cartan geometry framework that learns position-dependent curvature through local connection forms. Our architecture combines moving frame methods with parallel transport learning, enabling exact reconstruction of the underlying metric tensor. Theoretical analysis demonstrates consistency guarantees for curvature estimation from noisy samples. Applications in single-cell genomics and cosmology show superior density estimation (30-50% higher likelihood) compared to constant-curvature approaches while maintaining computational tractability. The framework enables curvature-aware interpolation and generation that respects learned geometric constraints, with applications in scientific simulation.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,1005,Optimizing Learning for Robust Hyperbolic Deep Learning in Computer Vision,"Hyperbolic deep learning has become a growing research direction in computer vision for the unique properties afforded by the alternate embedding space. The negative curvature and exponentially growing distance metric provide a natural framework for capturing hierarchical relationships between datapoints and allowing for finer separability between their embeddings. However, these methods are still computationally expensive and prone to instability, especially when attempting to learn the negative curvature that best suits the task and the  data. Current Riemannian optimizers do not account for changes in the manifold which greatly harms performance and forces lower learning rates to minimize projection errors. Our paper focuses on improving stability for curvature learning by introducing an improved schema for popular learning algorithms and providing a novel normalization approach to constrain embeddings within the variable representative radius of the manifold. Additionally, we introduce a novel formulation for Riemannian AdamW, and alternative hybrid encoder techniques and foundational formulations for current convolutional hyperbolic operations, greatly reducing the computational penalty of the hyperbolic embedding space. Our approach demonstrates consistent performance improvements across direct classification, generation, and hierarchical metric learning tasks while allowing for larger hyperbolic models.",ICLR.cc/2025/Conference,4.4,False,0.8152,most manifold learning assumes static curvature limiting applicability real world data varying local geometry neural cartan geometry that learns position dependent curvature local connection forms the enables curvature aware interpolation and generation that respects learned geometric constraints applications scientific simulation,hyperbolic deep learning has become growing direction computer vision for the unique properties afforded the alternate embedding space current riemannian optimizers not account for changes the manifold which greatly harms and forces lower learning rates minimize projection errors our focuses improving stability for curvature learning introducing improved schema for popular learning algorithms and providing normalization constrain embeddings within the variable representative radius the manifold additionally formulation for riemannian adamw and alternative hybrid encoder techniques and foundational formulations for current convolutional hyperbolic operations greatly reducing the computational penalty the hyperbolic embedding space our demonstrates consistent improvements across direct classification generation and hierarchical learning tasks while allowing for larger hyperbolic models,2025-08-26T00:59:30.192031
99,"*""Bayesian Topological Learning for Robust Representation""*","Traditional representation learning often ignores topological features critical for generalization. We propose Bayesian topological learning, where representations are optimized to preserve probabilistically defined topological signatures. Our approach combines persistent homology with variational inference, learning distributions over embedding spaces that maintain desired connectivity patterns. Theoretical contributions include topological generalization bounds and efficient approximation schemes for differentiable topological loss computation. Experiments on medical imaging and sensor networks demonstrate 25-40% higher robustness to adversarial perturbations compared to standard approaches while maintaining performance on clean data. The framework provides calibrated uncertainty estimates about topological features, enabling reliable deployment in safety-critical applications. This work establishes topology as a first-class citizen in probabilistic representation learning.",ICLR,representation learning,deepseek-ai/DeepSeek-V3-0324,True,4452,ToRL: Topology-preserving Representation Learning Of Object Deformations From Images,"Representation learning of object deformations from images has been a long-standing challenge in various image or video analysis tasks. Existing deep neural networks typically focus on visual features (e.g., intensity and texture), but they often fail to capture the underlying geometric and topological structures of objects. This limitation becomes especially critical in areas, such as medical imaging and 3D modeling, where maintaining the structural integrity of objects is essential for accuracy and generalization across diverse datasets. In this paper, we introduce ToRL, a novel *Topology-preserving Representation Learning* model that, for the first time, offers an explicit mechanism for modeling intricate object topology in the latent feature space. We develop a comprehensive learning framework that captures object deformations via learned transformation groups in the latent space. Each layer of our network's decoder is carefully designed with an integrated smooth composition module, ensuring that topological properties are preserved throughout the learning process. Moreover, in contrast to a few related works that rely on a reference image to predict object deformations during inference, our approach eliminates this impractical requirement. To validate ToRL's effectiveness, we conduct extensive multi-class classification experiments across a wide range of datasets, including synthetic 2D images, real 3D brain magnetic resonance imaging (MRI) scans, real 3D adrenal computed tomography (CT) shapes, and \textcolor{blue}{real 2D facial expression images}. Experimental results demonstrate that ToRL outperforms state-of-the-art methods, setting a new way to enforce topological consistency in representation learning. Our code is available at - https://anonymous.4open.science/r/ToRL-44BF/",ICLR.cc/2025/Conference,5.5,False,0.8643,traditional representation learning often ignores topological features critical for generalization our combines persistent homology variational inference learning distributions over embedding spaces that maintain desired connectivity patterns experiments medical imaging and sensor networks higher robustness adversarial perturbations compared standard approaches while maintaining clean data this establishes topology first class citizen probabilistic representation learning,representation learning object deformations from images has been long standing challenge various image video analysis tasks existing deep neural networks focus visual features this torl topology preserving representation learning that for the first time offers explicit mechanism for modeling intricate object topology the latent feature space comprehensive learning that captures object deformations learned transformation groups the latent space each layer our network decoder carefully designed integrated smooth composition module ensuring that topological properties are preserved throughout the learning process torl effectiveness conduct extensive multi class classification experiments across wide range datasets including synthetic images real brain magnetic resonance imaging mri scans real adrenal computed tomography shapes and textcolor blue real facial expression images experimental that torl outperforms state the art methods setting way enforce topological consistency representation learning,2025-08-26T00:59:30.192033
